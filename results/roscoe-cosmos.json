{"Meta-Llama-3-8B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.01649770767249263, "spearman": 0.01653134963233391, "kendall": 0.014975151083533951}, "p_value": {"pearson": 0.8189370224033173, "spearman": 0.818574174676694, "kendall": 0.817893582107345}, "kappa_score": 0.00012739259212068976, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.2650552270201977, "spearman": 0.26269675088308714, "kendall": 0.2432933250611708}, "p_value": {"pearson": 0.00018061063626423316, "spearman": 0.0002071355770386427, "kendall": 0.00025325830299377565}, "kappa_score": 0.03214890016920491, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.26616017681406556, "spearman": 0.2661601768140665, "kendall": 0.2661601768140665}, "p_value": {"pearson": 0.0001693059358850281, "spearman": 0.00016930593588501908, "kendall": 0.00020957809351413362}, "kappa_score": 0.13230950974601297, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.2 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.73449126625316, "spearman": 0.7298211656202812, "kendall": 0.6569980974805114}, "p_value": {"pearson": 2.479966336948416e-34, "spearman": 1.0349482602616552e-33, "kendall": 2.5474581243744315e-24}, "kappa_score": 0.28676936062460445, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.39373234922495376, "spearman": 0.39540596861030286, "kendall": 0.3628080436871158}, "p_value": {"pearson": 1.2371590807313334e-08, "spearman": 1.059580774590171e-08, "kendall": 4.173258902681076e-08}, "kappa_score": 0.24399284253578735, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.15840013085306948, "spearman": 0.15840013085306934, "kendall": 0.15840013085306937}, "p_value": {"pearson": 0.02698750427632365, "spearman": 0.026987504276323824, "kendall": 0.027365903534352493}, "kappa_score": 0.15666558546869924, "total_responses": 195, "valid_responses": 174, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.3163187181152588, "spearman": 0.31631871811525863, "kendall": 0.3163187181152586}, "p_value": {"pearson": 6.638295207730543e-06, "spearman": 6.638295207730561e-06, "kendall": 1.0538934792170152e-05}, "kappa_score": 0.257781949006726, "total_responses": 195, "valid_responses": 192, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.1074888511093028, "spearman": 0.10225670431538007, "kendall": 0.09126146405908284}, "p_value": {"pearson": 0.13473535402055728, "spearman": 0.15488459091846463, "kendall": 0.14990852189294643}, "kappa_score": 0.03513112320633349, "total_responses": 195, "valid_responses": 188, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.1641975896718836, "spearman": 0.15397551287409175, "kendall": 0.13824555451278445}, "p_value": {"pearson": 0.021805244573606677, "spearman": 0.0316217004530082, "kendall": 0.032488246931217095}, "kappa_score": 0.04128657741973696, "total_responses": 195, "valid_responses": 192, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.043901992749071625, "spearman": 0.04390199274907167, "kendall": 0.04390199274907167}, "p_value": {"pearson": 0.5422524519953514, "spearman": 0.5422524519953502, "kendall": 0.5408792068055606}, "kappa_score": 0.02842907385697535, "total_responses": 195, "valid_responses": 158, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.033013846793582824, "spearman": 0.033013846793582824, "kendall": 0.03301384679358282}, "p_value": {"pearson": 0.6468272624680358, "spearman": 0.6468272624680355, "kendall": 0.645638480072384}, "kappa_score": 0.027379815345431435, "total_responses": 195, "valid_responses": 33, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5905491179227125, "spearman": 0.6023429771240759, "kendall": 0.5209861510681599}, "p_value": {"pearson": 1.0234023827908447e-19, "spearman": 1.2201589402720042e-20, "kendall": 1.2741436180861277e-17}, "kappa_score": 0.20913533459658917, "total_responses": 195, "valid_responses": 194, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3712709919322456, "spearman": 0.36630090948485894, "kendall": 0.31497476762072435}, "p_value": {"pearson": 9.121477702792243e-08, "spearman": 1.3910763064334178e-07, "kendall": 5.363783756459339e-07}, "kappa_score": 0.05122555769760406, "total_responses": 195, "valid_responses": 191, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.0068251435956000195, "spearman": 0.006825143595600033, "kendall": 0.006825143595600034}, "p_value": {"pearson": 0.9245560670092506, "spearman": 0.9245560670092485, "kendall": 0.9242645880524719}, "kappa_score": 0.002295223066991814, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.05333536519547213, "spearman": -0.05333536519547222, "kendall": -0.05333536519547223}, "p_value": {"pearson": 0.4589804596535495, "spearman": 0.45898045965354883, "kendall": 0.4575569538176032}, "kappa_score": -0.0199714693295292, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3-70B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6357962207365826, "spearman": 0.6299385789020002, "kendall": 0.5458067415346783}, "p_value": {"pearson": 1.764675130616448e-23, "spearman": 5.873887693725848e-23, "kendall": 8.379033075270657e-20}, "kappa_score": 0.20148906468124717, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.38373437014154677, "spearman": 0.40044836580378934, "kendall": 0.34713894526307176}, "p_value": {"pearson": 3.06689137840712e-08, "spearman": 6.6087679995444314e-09, "kendall": 1.2567291001319276e-08}, "kappa_score": 0.19134671873380094, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.12256094435546383, "spearman": 0.12256094435546362, "kendall": 0.12256094435546361}, "p_value": {"pearson": 0.08783915328589509, "spearman": 0.08783915328589537, "kendall": 0.08780784913956034}, "kappa_score": 0.07912923289564622, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.2908138297306183, "spearman": 0.2908138297306185, "kendall": 0.2908138297306184}, "p_value": {"pearson": 3.7173434069923544e-05, "spearman": 3.717343406992249e-05, "kendall": 5.109347254825463e-05}, "kappa_score": 0.2072059442030001, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.10440352666539308, "spearman": 0.0775067320678742, "kendall": 0.0696232383580657}, "p_value": {"pearson": 0.14635843280006322, "spearman": 0.28148693805579994, "kendall": 0.27872232954767084}, "kappa_score": 0.013759306380171532, "total_responses": 195, "valid_responses": 191, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.1498353830852504, "spearman": 0.17448389148048654, "kendall": 0.15497447177195442}, "p_value": {"pearson": 0.036554752842995024, "spearman": 0.01470296935658679, "kendall": 0.014470101483159976}, "kappa_score": 0.08663106286114519, "total_responses": 195, "valid_responses": 178, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.042562775007688104, "spearman": -0.04256277500768807, "kendall": -0.04256277500768807}, "p_value": {"pearson": 0.5546521807852769, "spearman": 0.5546521807852756, "kendall": 0.553294355178477}, "kappa_score": -0.042125117887456875, "total_responses": 195, "valid_responses": 160, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.04585111693332718, "spearman": -0.04585111693332713, "kendall": -0.04585111693332713}, "p_value": {"pearson": 0.5244542411890082, "spearman": 0.5244542411890079, "kendall": 0.5230622550629729}, "kappa_score": -0.03577871316897174, "total_responses": 195, "valid_responses": 165, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6909849491460673, "spearman": 0.6865109673417613, "kendall": 0.5979700953838191}, "p_value": {"pearson": 5.190932737708795e-29, "spearman": 1.6195684861358152e-28, "kendall": 2.1803115467526643e-23}, "kappa_score": 0.2651875330163761, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.4200524546559989, "spearman": 0.446188888954243, "kendall": 0.39766751113331666}, "p_value": {"pearson": 9.768719483130034e-10, "spearman": 6.2611194321225e-11, "kendall": 4.019545197020865e-10}, "kappa_score": 0.06671336018210472, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.07999288983689688, "spearman": 0.07999288983689659, "kendall": 0.07999288983689659}, "p_value": {"pearson": 0.26629271456460224, "spearman": 0.266292714564603, "kendall": 0.26520539259150755}, "kappa_score": 0.01271635464500176, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.29414311068789656, "spearman": 0.2941431106878968, "kendall": 0.2941431106878967}, "p_value": {"pearson": 2.9957884517870902e-05, "spearman": 2.9957884517870773e-05, "kendall": 4.1864834079191806e-05}, "kappa_score": 0.25872340425531914, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6850211038493614, "spearman": 0.699109070141407, "kendall": 0.5987301149351115}, "p_value": {"pearson": 2.3549805423815507e-28, "spearman": 6.231370658234482e-30, "kendall": 3.2403737292744787e-24}, "kappa_score": 0.16002314517165994, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.39885826591000584, "spearman": 0.4339287146605083, "kendall": 0.3710359688535261}, "p_value": {"pearson": 7.676104624933552e-09, "spearman": 2.338989721413337e-10, "kendall": 8.284916910540362e-10}, "kappa_score": 0.18831731936591622, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.26588026605804627, "spearman": 0.26588026605804627, "kendall": 0.26588026605804627}, "p_value": {"pearson": 0.00017210551077579322, "spearman": 0.0001721055107757953, "kendall": 0.00021282674851752932}, "kappa_score": 0.2637540453074434, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.06604883758217173, "spearman": 0.06604883758217178, "kendall": 0.06604883758217178}, "p_value": {"pearson": 0.3589361069526465, "spearman": 0.35893610695264555, "kendall": 0.3575968738004821}, "kappa_score": 0.06514382402707275, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6558310157399654, "spearman": 0.694114002139439, "kendall": 0.606058788592328}, "p_value": {"pearson": 2.357334435053744e-25, "spearman": 2.3134999781338993e-29, "kendall": 9.758155356895183e-24}, "kappa_score": 0.21118214324412177, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.39495871334383525, "spearman": 0.4414254181853633, "kendall": 0.377065033815778}, "p_value": {"pearson": 1.104469096570072e-08, "spearman": 1.0513691356621829e-10, "kendall": 7.076246227131719e-10}, "kappa_score": 0.1511439562664506, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.189978705814295, "spearman": 0.18997870581429532, "kendall": 0.18997870581429527}, "p_value": {"pearson": 0.007811225972010439, "spearman": 0.00781122597201027, "kendall": 0.008142642054837095}, "kappa_score": 0.10742221449678435, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.30217916726754634, "spearman": 0.30217916726754646, "kendall": 0.30217916726754646}, "p_value": {"pearson": 1.759799403948379e-05, "spearman": 1.7597994039483608e-05, "kendall": 2.5665238614382955e-05}, "kappa_score": 0.21038100496962997, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6839581085498314, "spearman": 0.6803256796839753, "kendall": 0.591124413518487}, "p_value": {"pearson": 3.0718421896030794e-28, "spearman": 7.552686156897367e-28, "kendall": 7.616947213694982e-22}, "kappa_score": 0.17820953797527195, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3822004242163266, "spearman": 0.3861867797008531, "kendall": 0.33533755732046544}, "p_value": {"pearson": 3.515875882234236e-08, "spearman": 2.461506139937692e-08, "kendall": 7.493087221792019e-08}, "kappa_score": 0.1737600726364772, "total_responses": 195, "valid_responses": 194, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.26165034241679463, "spearman": 0.26165034241679413, "kendall": 0.2616503424167941}, "p_value": {"pearson": 0.00022003023329856796, "spearman": 0.0002200302332985748, "kendall": 0.0002680501184456294}, "kappa_score": 0.22057084951866235, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.1569700739803705, "spearman": 0.1569700739803706, "kendall": 0.1569700739803706}, "p_value": {"pearson": 0.028417180312496758, "spearman": 0.0284171803124967, "kendall": 0.02879072963440624}, "kappa_score": 0.15375077495350287, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6272318743517984, "spearman": 0.6269212615303179, "kendall": 0.5281239778308284}, "p_value": {"pearson": 1.0151121387428979e-22, "spearman": 1.0805130996645009e-22, "kendall": 2.826991035986406e-19}, "kappa_score": 0.23132643778848427, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.39774719622115207, "spearman": 0.3981731514616081, "kendall": 0.3479443098731373}, "p_value": {"pearson": 8.518645742115803e-09, "spearman": 8.185596951122508e-09, "kendall": 1.0954015494551879e-08}, "kappa_score": 0.2312465778426721, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.06227943530985016, "spearman": -0.0622794353098503, "kendall": -0.06227943530985031}, "p_value": {"pearson": 0.38707524589852654, "spearman": 0.38707524589852516, "kendall": 0.38569431501344553}, "kappa_score": -0.025596072931276304, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.28482613755117714, "spearman": 0.2848261375511779, "kendall": 0.28482613755117786}, "p_value": {"pearson": 5.443482921428551e-05, "spearman": 5.4434829214282316e-05, "kendall": 7.273140953177699e-05}, "kappa_score": 0.20901932712956328, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4985507412252552, "spearman": 0.5038358263037803, "kendall": 0.41751336770987557}, "p_value": {"pearson": 1.1983856555090276e-13, "spearman": 5.99354254768375e-14, "kendall": 1.798225065354865e-12}, "kappa_score": 0.1419278721979529, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.17280857369730424, "spearman": 0.14738726449208273, "kendall": 0.1334044430936378}, "p_value": {"pearson": 0.01569942892110914, "spearman": 0.03976693242640714, "kendall": 0.038375178960669734}, "kappa_score": 0.05074914009211218, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.04618877564378561, "spearman": -0.046188775643785596, "kendall": -0.046188775643785596}, "p_value": {"pearson": 0.521401406754885, "spearman": 0.5214014067548843, "kendall": 0.5200066197828697}, "kappa_score": -0.03083700440528636, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.05333536519547202, "spearman": -0.05333536519547222, "kendall": -0.05333536519547223}, "p_value": {"pearson": 0.4589804596535502, "spearman": 0.45898045965354883, "kendall": 0.4575569538176032}, "kappa_score": -0.0199714693295292, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}