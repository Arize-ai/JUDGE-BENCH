{"Meta-Llama-3-8B-Instruct (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.5108282008269984, "spearman": 0.5108282008269931, "kendall": 0.5108282008269931}, "p_value": {"pearson": 2.1368772073878196e-70, "spearman": 2.1368772073960428e-70, "kendall": 4.3620767983080665e-61}, "kappa_score": 0.49010461899476043, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mistral-7B-Instruct-v0.2 (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.37513693835002104, "spearman": 0.3751369383500162, "kendall": 0.37513693835001616}, "p_value": {"pearson": 3.40013272985598e-36, "spearman": 3.400132729863667e-36, "kendall": 9.414649649327899e-34}, "kappa_score": 0.35222420619517114, "total_responses": 1043, "valid_responses": 783, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.4614640821108973, "spearman": 0.46146408211089607, "kendall": 0.461464082110896}, "p_value": {"pearson": 3.9528917132039964e-56, "spearman": 3.9528917132073597e-56, "kendall": 3.4953311703877482e-50}, "kappa_score": 0.45492772033639395, "total_responses": 1043, "valid_responses": 885, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Meta-Llama-3-70B-Instruct (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.585699486423002, "spearman": 0.5856994864230005, "kendall": 0.5856994864230005}, "p_value": {"pearson": 4.490716878319711e-97, "spearman": 4.490716878325144e-97, "kendall": 1.0103397818272651e-79}, "kappa_score": 0.5561425110219644, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.049022979618969564, "spearman": 0.049022979618970085, "kendall": 0.049022979618970085}, "p_value": {"pearson": 0.11358679065341669, "spearman": 0.11358679065340954, "kendall": 0.11354391316300363}, "kappa_score": 0.006762593015832152, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "OLMo-7B-Instruct (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.0899079101168942, "spearman": 0.08990791011689409, "kendall": 0.08990791011689407}, "p_value": {"pearson": 0.003660497554856638, "spearman": 0.0036604975548567096, "kendall": 0.003705169111565361}, "kappa_score": 0.08445890421192614, "total_responses": 1043, "valid_responses": 611, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.5454833528929087, "spearman": 0.5454833528929038, "kendall": 0.545483352892904}, "p_value": {"pearson": 6.576636526766338e-82, "spearman": 6.576636526791646e-82, "kendall": 2.1305427437293342e-69}, "kappa_score": 0.5191970967699099, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gpt-4o (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.4231189518534575, "spearman": 0.42311895185345405, "kendall": 0.42311895185345405}, "p_value": {"pearson": 1.4866514197339686e-46, "spearman": 1.4866514197366277e-46, "kendall": 1.80164304184509e-42}, "kappa_score": 0.3405346404837255, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.5124961029736279, "spearman": 0.5124961029736264, "kendall": 0.5124961029736264}, "p_value": {"pearson": 6.393224796626198e-71, "spearman": 6.39322479663314e-71, "kendall": 1.7868721139413494e-61}, "kappa_score": 0.4462224178342259, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.5523177587754771, "spearman": 0.5523177587754702, "kendall": 0.5523177587754701}, "p_value": {"pearson": 2.4277809566970186e-84, "spearman": 2.427780956710955e-84, "kendall": 4.221562910238072e-71}, "kappa_score": 0.5513526670401635, "total_responses": 1043, "valid_responses": 1025, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.5779528976988542, "spearman": 0.5779528976988538, "kendall": 0.5779528976988537}, "p_value": {"pearson": 5.478950630306071e-94, "spearman": 5.478950630307596e-94, "kendall": 1.121678028545913e-77}, "kappa_score": 0.5425669105886788, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"grammaticality": {"corr_coeff": {"pearson": 0.23504520267842532, "spearman": 0.2350452026784226, "kendall": 0.2350452026784226}, "p_value": {"pearson": 1.4738497501589187e-14, "spearman": 1.4738497501599492e-14, "kendall": 3.267285228434348e-14}, "kappa_score": 0.12262148462073774, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}}