{"Meta-Llama-3-8B-Instruct (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.6125701782721988, "spearman": 0.5881677261939957, "kendall": 0.49232975900095677}, "p_value": {"pearson": 1.2617620063680849e-11, "spearman": 1.239013999528272e-10, "kendall": 9.302776483073013e-10}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Mistral-7B-Instruct-v0.2 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.5007990777120019, "spearman": 0.36255577362673985, "kendall": 0.2940138419529836}, "p_value": {"pearson": 1.11870357019057e-07, "spearman": 0.00020978763977837352, "kendall": 0.00038282630738479623}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 98, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.09703353360742861, "spearman": 0.08672831026865299, "kendall": 0.07110587241446893}, "p_value": {"pearson": 0.33685166242400144, "spearman": 0.39089388052562335, "kendall": 0.3937083887111027}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 89, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.3101210984177676, "spearman": 0.2274680989808735, "kendall": 0.18148350985263093}, "p_value": {"pearson": 0.001689368832419831, "spearman": 0.0228456533100383, "kendall": 0.02311253197539315}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 69, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "OLMo-7B-Instruct (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.10731308179412609, "spearman": 0.035556885521278114, "kendall": 0.024970490614938674}, "p_value": {"pearson": 0.28791290359122074, "spearman": 0.725431134912913, "kendall": 0.7517623630006403}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 89, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Meta-Llama-3-70B-Instruct (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.7828574799343888, "spearman": 0.600465927073997, "kendall": 0.5049539865176539}, "p_value": {"pearson": 6.517000427272176e-22, "spearman": 4.013743645938586e-11, "kendall": 3.9229636434267743e-10}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "gpt-4o (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.8723812975284289, "spearman": 0.6863686102381712, "kendall": 0.5906018147509685}, "p_value": {"pearson": 3.16433070149511e-32, "spearman": 3.229554319574093e-15, "kendall": 1.2235846197962332e-12}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.7719847936620992, "spearman": 0.6338536857345637, "kendall": 0.5321785912467695}, "p_value": {"pearson": 5.3638863349909445e-21, "spearman": 1.4571597445731203e-12, "kendall": 6.1709420997195e-11}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 99, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.6857114338104306, "spearman": 0.5714397418713019, "kendall": 0.45903195340157743}, "p_value": {"pearson": 3.513914223693594e-15, "spearman": 5.331824579848224e-10, "kendall": 5.151007001445067e-09}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.7303545051435052, "spearman": 0.625731741983424, "kendall": 0.5201543175064787}, "p_value": {"pearson": 6.5380640590715745e-18, "spearman": 3.3859700081106816e-12, "kendall": 5.325319710515413e-10}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.6694182346757287, "spearman": 0.551249916121172, "kendall": 0.4678608881368862}, "p_value": {"pearson": 2.6587870969447548e-14, "spearman": 2.7928980417213547e-09, "kendall": 3.4920845573255606e-08}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.6524532861642337, "spearman": 0.5246124350374416, "kendall": 0.4484363076105307}, "p_value": {"pearson": 1.9185310601372804e-13, "spearman": 2.1123072656167317e-08, "kendall": 6.048944753897342e-08}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}}