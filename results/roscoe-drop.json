{"Meta-Llama-3-8B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.31675963822010167, "spearman": 0.29285275746225964, "kendall": 0.26671935015302917}, "p_value": {"pearson": 2.812397563784024e-06, "spearman": 1.607216473893342e-05, "kendall": 2.298538297806664e-05}, "kappa_score": 0.047945205479452024, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.16039341217731187, "spearman": 0.14376419429594658, "kendall": 0.1386416838289037}, "p_value": {"pearson": 0.02004392976637351, "spearman": 0.03736691598213337, "kendall": 0.037674847565082936}, "kappa_score": 0.005475802871096613, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.035568308532810296, "spearman": -0.03556830853281036, "kendall": -0.03556830853281036}, "p_value": {"pearson": 0.6082874893312519, "spearman": 0.6082874893312511, "kendall": 0.6071086224185095}, "kappa_score": -0.008759536592257477, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.042915959963135006, "spearman": 0.04291595996313489, "kendall": 0.042915959963134895}, "p_value": {"pearson": 0.53625611062722, "spearman": 0.5362561106272188, "kendall": 0.5349754926382675}, "kappa_score": 0.030563514804202385, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.2 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5051765658270176, "spearman": 0.47129830120505917, "kendall": 0.4243940608962677}, "p_value": {"pearson": 5.309135574531418e-15, "spearman": 5.210923507423877e-13, "kendall": 8.936834446854843e-12}, "kappa_score": 0.1777777777777778, "total_responses": 210, "valid_responses": 206, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.2566453774585658, "spearman": 0.25073397029014916, "kendall": 0.23888881272039378}, "p_value": {"pearson": 0.0001698307334011646, "spearman": 0.00024197986900013704, "kendall": 0.00030253565754876244}, "kappa_score": 0.15451717196364312, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.08777340654064468, "spearman": 0.08777340654064492, "kendall": 0.08777340654064492}, "p_value": {"pearson": 0.2052225507329072, "spearman": 0.20522255073290535, "kendall": 0.20446766563615815}, "kappa_score": 0.08427430459928387, "total_responses": 210, "valid_responses": 197, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.08449079617742193, "spearman": 0.08449079617742182, "kendall": 0.08449079617742182}, "p_value": {"pearson": 0.22274503652242397, "spearman": 0.22274503652242458, "kendall": 0.2219083935425653}, "kappa_score": 0.07608695652173902, "total_responses": 210, "valid_responses": 205, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.25236225531367745, "spearman": 0.28306271203468464, "kendall": 0.2556881486905179}, "p_value": {"pearson": 0.00021968047495143176, "spearman": 3.1416980341057226e-05, "kendall": 3.861982329281644e-05}, "kappa_score": 0.007331087774915868, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.06689140527351302, "spearman": 0.04332393158131145, "kendall": 0.04087439461129198}, "p_value": {"pearson": 0.3347233250280274, "spearman": 0.5323850521128428, "kendall": 0.5295946656794969}, "kappa_score": 0.00043271311120740563, "total_responses": 210, "valid_responses": 206, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.06089970737203489, "spearman": 0.060899707372035046, "kendall": 0.060899707372035046}, "p_value": {"pearson": 0.3799066010262784, "spearman": 0.3799066010262777, "kendall": 0.3786335282792457}, "kappa_score": 0.03128020384851948, "total_responses": 210, "valid_responses": 183, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.024673188560991363, "spearman": -0.024673188560991335, "kendall": -0.024673188560991335}, "p_value": {"pearson": 0.7222386538317048, "spearman": 0.7222386538317059, "kendall": 0.7213192886523612}, "kappa_score": -0.012145748987854033, "total_responses": 210, "valid_responses": 33, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5155016564318184, "spearman": 0.4964947392188625, "kendall": 0.44876171020496364}, "p_value": {"pearson": 1.1827234255805427e-15, "spearman": 1.8055134568501844e-14, "kendall": 7.423771578950235e-13}, "kappa_score": 0.09983925701018048, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.29885741213554207, "spearman": 0.2415469320771977, "kendall": 0.23292895301212724}, "p_value": {"pearson": 1.0523708973867047e-05, "spearman": 0.0004125882857166933, "kendall": 0.000465343982520359}, "kappa_score": 0.12837236881114755, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.07658474625645978, "spearman": 0.07658474625645992, "kendall": 0.07658474625645992}, "p_value": {"pearson": 0.26923863107252805, "spearman": 0.26923863107252743, "kendall": 0.2682192108468202}, "kappa_score": 0.065254161844565, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.038447322405439716, "spearman": -0.038447322405439625, "kendall": -0.03844732240543962}, "p_value": {"pearson": 0.5795555600073027, "spearman": 0.5795555600073027, "kendall": 0.5783294731507844}, "kappa_score": -0.034782608695652195, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3-70B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6904523768944872, "spearman": 0.6217851096383303, "kendall": 0.5589881516055347}, "p_value": {"pearson": 4.4562991284527545e-31, "spearman": 7.407046216790775e-24, "kendall": 1.1369712464446474e-19}, "kappa_score": 0.20085795336608325, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3148125223172851, "spearman": 0.38375204953878383, "kendall": 0.360026075736813}, "p_value": {"pearson": 3.260143209860251e-06, "spearman": 8.947804240489957e-09, "kendall": 2.5808033704162837e-08}, "kappa_score": 0.17312818027622967, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.2577684015718319, "spearman": 0.2577684015718324, "kendall": 0.25776840157183234}, "p_value": {"pearson": 0.00015863139615628004, "spearman": 0.00015863139615627261, "kendall": 0.0001941458679579026}, "kappa_score": 0.24575738529226898, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.1288888273742811, "spearman": 0.1288888273742807, "kendall": 0.1288888273742807}, "p_value": {"pearson": 0.062263829471145705, "spearman": 0.06226382947114628, "kendall": 0.06241667270712551}, "kappa_score": 0.11296162201303395, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.10540545174462176, "spearman": 0.12156377827926951, "kendall": 0.10631747034771893}, "p_value": {"pearson": 0.12785940239556495, "spearman": 0.07880944828646858, "kendall": 0.07751222203705228}, "kappa_score": 0.022679123398048118, "total_responses": 210, "valid_responses": 189, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": -0.010042930222455174, "spearman": -0.007317131757227444, "kendall": -0.006848427053763976}, "p_value": {"pearson": 0.884970742509212, "spearman": 0.9160553809661189, "kendall": 0.9138619017070346}, "kappa_score": -0.02379953868735596, "total_responses": 210, "valid_responses": 198, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.04717469557918163, "spearman": -0.04717469557918168, "kendall": -0.04717469557918168}, "p_value": {"pearson": 0.49655222448786573, "spearman": 0.49655222448786507, "kendall": 0.49524106121649414}, "kappa_score": -0.043887147335423204, "total_responses": 210, "valid_responses": 186, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.09558255732641585, "spearman": -0.0955825573264156, "kendall": -0.09558255732641559}, "p_value": {"pearson": 0.16758139221711751, "spearman": 0.1675813922171198, "kendall": 0.16702666889347917}, "kappa_score": -0.04904632152588562, "total_responses": 210, "valid_responses": 185, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.7611001969014882, "spearman": 0.729571505774792, "kendall": 0.6402999242313578}, "p_value": {"pearson": 5.694299928356842e-41, "spearman": 3.602307299930881e-36, "kendall": 1.052146999925315e-27}, "kappa_score": 0.2897332153243142, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3852246325152667, "spearman": 0.41962919227313417, "kendall": 0.3906886562514284}, "p_value": {"pearson": 7.764786976168204e-09, "spearman": 2.3008976168898796e-10, "kendall": 1.5398025184090342e-09}, "kappa_score": 0.22628951747088177, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.3506850513677445, "spearman": 0.35068505136774514, "kendall": 0.3506850513677452}, "p_value": {"pearson": 1.8062603904796597e-07, "spearman": 1.8062603904795858e-07, "kendall": 3.9824447039986526e-07}, "kappa_score": 0.34907466496490114, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.32455194722120784, "spearman": 0.3245519472212076, "kendall": 0.32455194722120767}, "p_value": {"pearson": 1.5408496696972644e-06, "spearman": 1.5408496696972932e-06, "kendall": 2.7055629193078108e-06}, "kappa_score": 0.23113658070678123, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.45391827525572803, "spearman": 0.4378811736574787, "kendall": 0.38455002687515055}, "p_value": {"pearson": 4.5365630666307824e-12, "spearman": 3.0062515028927593e-11, "kendall": 3.4743399592873877e-10}, "kappa_score": 0.09961412033728756, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.2143138783785879, "spearman": 0.2636641674908117, "kendall": 0.2417693440977927}, "p_value": {"pearson": 0.0017868982588085103, "spearman": 0.00011031967392090293, "kendall": 0.00016651720024549228}, "kappa_score": 0.11838790931989929, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.21962877091356367, "spearman": 0.21962877091356384, "kendall": 0.21962877091356384}, "p_value": {"pearson": 0.0013603955609471853, "spearman": 0.001360395560947159, "kendall": 0.0014976613116061104}, "kappa_score": 0.17917740072843558, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.08395581319478204, "spearman": 0.08395581319478197, "kendall": 0.08395581319478197}, "p_value": {"pearson": 0.22569860953350887, "spearman": 0.22569860953350787, "kendall": 0.22484889193241597}, "kappa_score": 0.08296943231441045, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5806075142728182, "spearman": 0.5304305525780237, "kendall": 0.45113853281170524}, "p_value": {"pearson": 2.539654410785474e-20, "spearman": 1.2303410031671035e-16, "kendall": 5.411913906224925e-15}, "kappa_score": 0.1694342129098484, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3925192423612363, "spearman": 0.346136438145637, "kendall": 0.3225009125532036}, "p_value": {"pearson": 3.806567989373823e-09, "spearman": 2.660760170041663e-07, "kendall": 3.637709630276052e-07}, "kappa_score": 0.1340050919783411, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.13981512537768814, "spearman": 0.13981512537768798, "kendall": 0.13981512537768798}, "p_value": {"pearson": 0.04297297646998991, "spearman": 0.04297297646999021, "kendall": 0.043250393114973945}, "kappa_score": 0.05200789993416732, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.12309149097933317, "spearman": 0.12309149097933272, "kendall": 0.12309149097933272}, "p_value": {"pearson": 0.07509346040366535, "spearman": 0.07509346040366695, "kendall": 0.07515568862181482}, "kappa_score": 0.11764705882352944, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4125346394969716, "spearman": 0.4050506104054887, "kendall": 0.35845078723744206}, "p_value": {"pearson": 4.913910213612943e-10, "spearman": 1.073483381553783e-09, "kendall": 5.932075937622135e-09}, "kappa_score": 0.1242093556683117, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.2630642284573984, "spearman": 0.23888145663843244, "kendall": 0.22460763497725855}, "p_value": {"pearson": 0.00011451784671041358, "spearman": 0.00047987019531779777, "kendall": 0.0005569431547009249}, "kappa_score": 0.12350597609561753, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.2813005036142924, "spearman": 0.28130050361429293, "kendall": 0.28130050361429293}, "p_value": {"pearson": 3.535267346508369e-05, "spearman": 3.535267346508289e-05, "kendall": 4.7680658180538524e-05}, "kappa_score": 0.2788070492544058, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.017225834749087957, "spearman": -0.017225834749087888, "kendall": -0.017225834749087888}, "p_value": {"pearson": 0.8040148530266212, "spearman": 0.8040148530266211, "kendall": 0.8033367989254111}, "kappa_score": -0.016333938294010864, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5972101569404507, "spearman": 0.5441613828354146, "kendall": 0.48953763414681284}, "p_value": {"pearson": 1.097550824040068e-21, "spearman": 1.387613763761376e-17, "kendall": 3.5458246582581833e-15}, "kappa_score": 0.21876086503024816, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3686876823432525, "spearman": 0.3331405744602269, "kendall": 0.31650960240430615}, "p_value": {"pearson": 3.6686148482538354e-08, "spearman": 7.78376082622252e-07, "kendall": 1.3169641464603537e-06}, "kappa_score": 0.23324463147472008, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.2840359418550398, "spearman": 0.28403594185504016, "kendall": 0.28403594185504016}, "p_value": {"pearson": 2.942441673459514e-05, "spearman": 2.9424416734594412e-05, "kendall": 4.021168870432094e-05}, "kappa_score": 0.2802303262955854, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.13752311475791879, "spearman": 0.13752311475791867, "kendall": 0.13752311475791865}, "p_value": {"pearson": 0.04653900651518317, "spearman": 0.046539006515183494, "kendall": 0.046795256960786326}, "kappa_score": 0.10999408633944419, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4302812657548006, "spearman": 0.3701434961101414, "kendall": 0.31451837364000695}, "p_value": {"pearson": 7.12007236632805e-11, "spearman": 3.2109721228764675e-08, "kendall": 6.351649758339834e-08}, "kappa_score": 0.06339410939691448, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.10001714048753513, "spearman": 0.05687647813571135, "kendall": 0.05325896331392227}, "p_value": {"pearson": 0.148637957570008, "spearman": 0.4122372370142965, "kendall": 0.4031234233387183}, "kappa_score": 0.0036769066540149886, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.07404807302726604, "spearman": 0.07404807302726624, "kendall": 0.07404807302726624}, "p_value": {"pearson": 0.2854660288758281, "spearman": 0.285466028875828, "kendall": 0.28439405096943826}, "kappa_score": 0.05892270831484614, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}