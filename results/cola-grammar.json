{"Meta-Llama-3-8B-Instruct (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.10636550646990192, "spearman": 0.10636550646990087, "kendall": 0.10636550646990085}, "p_value": {"pearson": 0.0005800524361174533, "spearman": 0.0005800524361175133, "kendall": 0.0005958835587005602}, "kappa_score": 0.07370336232885921, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.37736394332559176, "spearman": 0.37736394332559303, "kendall": 0.37736394332559303}, "p_value": {"pearson": 1.2236773250464191e-36, "spearman": 1.2236773250456888e-36, "kendall": 3.909157034536861e-34}, "kappa_score": 0.35500988705053027, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.019119558472803146, "spearman": 0.019119558472803506, "kendall": 0.019119558472803503}, "p_value": {"pearson": 0.5373720293919959, "spearman": 0.5373720293919764, "kendall": 0.5371161238228914}, "kappa_score": 0.0029511905986282505, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.21621692463353542, "spearman": 0.21621692463353434, "kendall": 0.2162169246335343}, "p_value": {"pearson": 1.6877698045547496e-12, "spearman": 1.6877698045551714e-12, "kendall": 2.9625839621961924e-12}, "kappa_score": 0.14001377697991912, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.07153937147556454, "spearman": 0.07153937147556527, "kendall": 0.07153937147556526}, "p_value": {"pearson": 0.02085545379470046, "spearman": 0.02085545379469923, "kendall": 0.020927345348728376}, "kappa_score": 0.02093613399626415, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.2999172723384516, "spearman": 0.29991727233845417, "kendall": 0.2999172723384541}, "p_value": {"pearson": 4.0305686493722043e-23, "spearman": 4.0305686493685956e-23, "kendall": 3.61951227872298e-22}, "kappa_score": 0.18644056870449222, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.13022482907908242, "spearman": 0.13022482907908178, "kendall": 0.1302248290790818}, "p_value": {"pearson": 2.458127736512379e-05, "spearman": 2.458127736512654e-05, "kendall": 2.6263252599611952e-05}, "kappa_score": 0.03579172735179026, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.3848558123620818, "spearman": 0.3848558123620865, "kendall": 0.3848558123620865}, "p_value": {"pearson": 3.706904602495053e-38, "spearman": 3.7069046024869056e-38, "kendall": 1.9568872452469274e-35}, "kappa_score": 0.3162761593547939, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.4381736342769861, "spearman": 0.43817363427698675, "kendall": 0.4381736342769867}, "p_value": {"pearson": 3.6176289369762265e-50, "spearman": 3.6176289369747547e-50, "kendall": 2.026491595000394e-45}, "kappa_score": 0.36447077153280727, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.16760264106344547, "spearman": 0.16760264106344583, "kendall": 0.16760264106344586}, "p_value": {"pearson": 5.184005019448242e-08, "spearman": 5.184005019447882e-08, "kendall": 6.29482824773554e-08}, "kappa_score": 0.06635611162314081, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.22614321894482475, "spearman": 0.22614321894482645, "kendall": 0.2261432189448264}, "p_value": {"pearson": 1.4616744106356126e-13, "spearman": 1.4616744106350143e-13, "kendall": 2.879630363494439e-13}, "kappa_score": 0.11323012034755797, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.27256910973890347, "spearman": 0.27256910973890425, "kendall": 0.27256910973890425}, "p_value": {"pearson": 3.1757683169710693e-19, "spearman": 3.1757683169704266e-19, "kendall": 1.386105402822889e-18}, "kappa_score": 0.17093734551251905, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.14308334242835735, "spearman": 0.14308334242835888, "kendall": 0.1430833424283589}, "p_value": {"pearson": 3.4959352226160233e-06, "spearman": 3.4959352226152622e-06, "kendall": 3.86088713692419e-06}, "kappa_score": 0.040124228730443634, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.5215365351553918, "spearman": 0.5215365351553968, "kendall": 0.5215365351553967}, "p_value": {"pearson": 8.203329931123577e-74, "spearman": 8.20332993109312e-74, "kendall": 1.3470444563148014e-63}, "kappa_score": 0.44290139942313844, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.1486845021326647, "spearman": 0.14868450213266576, "kendall": 0.14868450213266576}, "p_value": {"pearson": 1.414751928945248e-06, "spearman": 1.414751928944936e-06, "kendall": 1.590309380567054e-06}, "kappa_score": 0.043257857384251364, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.18032918718353913, "spearman": 0.1803291871835382, "kendall": 0.1803291871835382}, "p_value": {"pearson": 4.491758014793109e-09, "spearman": 4.491758014794109e-09, "kendall": 5.848584846945657e-09}, "kappa_score": 0.0757008586075979, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.03445936405948968, "spearman": 0.03445936405948896, "kendall": 0.03445936405948896}, "p_value": {"pearson": 0.26619040184275367, "spearman": 0.26619040184275483, "kendall": 0.26598806936362507}, "kappa_score": 0.0064987939590408494, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.033581481909509936, "spearman": 0.03358148190950989, "kendall": 0.033581481909509894}, "p_value": {"pearson": 0.2785704845190748, "spearman": 0.27857048451907623, "kendall": 0.2783598913668013}, "kappa_score": 0.019451859291169993, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.3524951155204767, "spearman": 0.3524951155204769, "kendall": 0.35249511552047696}, "p_value": {"pearson": 7.099242479915263e-32, "spearman": 7.099242479915277e-32, "kendall": 5.348088507619938e-30}, "kappa_score": 0.2440348232891042, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.35297430110071437, "spearman": 0.35297430110070915, "kendall": 0.3529743011007091}, "p_value": {"pearson": 5.799030396640239e-32, "spearman": 5.799030396652867e-32, "kendall": 4.478447565176089e-30}, "kappa_score": 0.2952173586605601, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.38142810853615877, "spearman": 0.38142810853616255, "kendall": 0.3814281085361625}, "p_value": {"pearson": 1.856731348230766e-37, "spearman": 1.8567313482276131e-37, "kendall": 7.757373023889606e-35}, "kappa_score": 0.27193622996329614, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.2478723835934633, "spearman": 0.2478723835934654, "kendall": 0.2478723835934654}, "p_value": {"pearson": 4.560980016649271e-16, "spearman": 4.560980016646643e-16, "kendall": 1.2308574584320213e-15}, "kappa_score": 0.13538286634613095, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.4905778837939933, "spearman": 0.4905778837939969, "kendall": 0.4905778837939969}, "p_value": {"pearson": 2.925488868110984e-64, "spearman": 2.9254888681043093e-64, "kendall": 1.7601832547419537e-56}, "kappa_score": 0.47579406372330413, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.27279772561830845, "spearman": 0.2727977256183065, "kendall": 0.2727977256183064}, "p_value": {"pearson": 2.958324095736795e-19, "spearman": 2.958324095738718e-19, "kendall": 1.2978666629174187e-18}, "kappa_score": 0.14423480223987228, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.5274986354993609, "spearman": 0.5274986354993632, "kendall": 0.527498635499363}, "p_value": {"pearson": 9.091478815331249e-76, "spearman": 9.09147881531715e-76, "kendall": 5.120356717272274e-65}, "kappa_score": 0.44327232374878844, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.3547363922196313, "spearman": 0.35473639221963044, "kendall": 0.3547363922196305}, "p_value": {"pearson": 2.747759640290429e-32, "spearman": 2.747759640291838e-32, "kendall": 2.3271792029067288e-30}, "kappa_score": 0.2526882452780328, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.18261507452387893, "spearman": 0.1826150745238779, "kendall": 0.1826150745238779}, "p_value": {"pearson": 2.8398646483466794e-09, "spearman": 2.8398646483470896e-09, "kendall": 3.7509200660416966e-09}, "kappa_score": 0.08377449306685869, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.11975715541039124, "spearman": 0.11975715541039238, "kendall": 0.11975715541039239}, "p_value": {"pearson": 0.00010577800625845715, "spearman": 0.0001057780062584429, "kendall": 0.0001107420101650363}, "kappa_score": 0.028277995854019244, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.2546586547046741, "spearman": 0.25465865470467636, "kendall": 0.2546586547046763}, "p_value": {"pearson": 6.680332544999894e-17, "spearman": 6.68033254499556e-17, "kendall": 2.0284637704235854e-16}, "kappa_score": 0.12715898880647047, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.09886764220899846, "spearman": 0.0988676422089983, "kendall": 0.09886764220899825}, "p_value": {"pearson": 0.001388708509648573, "spearman": 0.0013887085096486145, "kendall": 0.0014156063936135539}, "kappa_score": 0.028675851400091434, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.28503221138399293, "spearman": 0.285032211383992, "kendall": 0.28503221138399204}, "p_value": {"pearson": 6.018437651489359e-21, "spearman": 6.018437651491333e-21, "kendall": 3.551397254322437e-20}, "kappa_score": 0.1798397551697023, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.11148494165387804, "spearman": 0.11148494165387925, "kendall": 0.11148494165387926}, "p_value": {"pearson": 0.00030928486485203103, "spearman": 0.00030928486485199726, "kendall": 0.00031976675739791807}, "kappa_score": 0.024552622532076906, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.18497835023275633, "spearman": 0.18497835023275508, "kendall": 0.18497835023275513}, "p_value": {"pearson": 1.7569221957842608e-09, "spearman": 1.7569221957847042e-09, "kendall": 2.3565095725888877e-09}, "kappa_score": 0.07387178231219482, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.646778661414552, "spearman": 0.6467786614145551, "kendall": 0.6467786614145551}, "p_value": {"pearson": 1.2555772163294269e-124, "spearman": 1.2555772163247027e-124, "kendall": 8.481524933768379e-97}, "kappa_score": 0.5926590322367113, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8855667415621742, "spearman": 0.8855667415621676, "kendall": 0.8855667415621677}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 9.997747309576515e-180}, "kappa_score": 0.8854950658095366, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.411853872912484, "spearman": 0.4118538729124882, "kendall": 0.4118538729124882}, "p_value": {"pearson": 5.740966649261394e-44, "spearman": 5.740966649248365e-44, "kendall": 2.486232080342861e-40}, "kappa_score": 0.3349350397959533, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.14906671166922802, "spearman": 0.14906671166922836, "kendall": 0.14906671166922839}, "p_value": {"pearson": 1.3284268913853889e-06, "spearman": 1.328426891385284e-06, "kendall": 1.4951925802059047e-06}, "kappa_score": 0.05719371601544565, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.20534011147812775, "spearman": 0.20534011147813058, "kendall": 0.20534011147813058}, "p_value": {"pearson": 2.1555484954393816e-11, "spearman": 2.1555484954380038e-11, "kendall": 3.393819233317601e-11}, "kappa_score": 0.09137927516281297, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.05334690411676188, "spearman": 0.0533469041167621, "kendall": 0.053346904116762094}, "p_value": {"pearson": 0.08506483409330197, "spearman": 0.08506483409329989, "kendall": 0.0850623838074782}, "kappa_score": 0.013161074259497973, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.13187311019911135, "spearman": 0.1318731101991109, "kendall": 0.13187311019911088}, "p_value": {"pearson": 1.9331594643621868e-05, "spearman": 1.9331594643622796e-05, "kendall": 2.073113524169357e-05}, "kappa_score": 0.05944825130240483, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.119438575584889, "spearman": 0.11943857558488996, "kendall": 0.11943857558488995}, "p_value": {"pearson": 0.00011038451932606961, "spearman": 0.00011038451932605573, "kendall": 0.00011550268888516382}, "kappa_score": 0.03324786633442878, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.09534395041054006, "spearman": 0.0953439504105404, "kendall": 0.0953439504105404}, "p_value": {"pearson": 0.0020526019620383273, "spearman": 0.00205260196203824, "kendall": 0.002086012472806001}, "kappa_score": 0.029407490995656205, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.06796281401686066, "spearman": 0.06796281401686076, "kendall": 0.06796281401686076}, "p_value": {"pearson": 0.02817795763864569, "spearman": 0.028177957638646084, "kendall": 0.02824681908614932}, "kappa_score": 0.01105124269654667, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.11393712265673421, "spearman": 0.11393712265673436, "kendall": 0.11393712265673438}, "p_value": {"pearson": 0.00022668310129252486, "spearman": 0.00022668310129250863, "kendall": 0.00023516843551899897}, "kappa_score": 0.03173660571664827, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.053135503987061475, "spearman": 0.05313550398706131, "kendall": 0.0531355039870613}, "p_value": {"pearson": 0.08630998786891197, "spearman": 0.08630998786891608, "kendall": 0.08630574507356642}, "kappa_score": 0.005630865484880121, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.28207633856184267, "spearman": 0.2820763385618407, "kendall": 0.2820763385618407}, "p_value": {"pearson": 1.5702495766369427e-20, "spearman": 1.5702495766379126e-20, "kendall": 8.592442826947341e-20}, "kappa_score": 0.18655765533810464, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.12081397712105793, "spearman": 0.12081397712106025, "kendall": 0.12081397712106026}, "p_value": {"pearson": 9.176055993979522e-05, "spearman": 9.176055993976298e-05, "kendall": 9.624110169555556e-05}, "kappa_score": 0.06929465434553739, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.0704858924631489, "spearman": 0.07048589246314971, "kendall": 0.07048589246314971}, "p_value": {"pearson": 0.022817291126221113, "spearman": 0.022817291126220902, "kendall": 0.022888757410323944}, "kappa_score": 0.02484948598836134, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.10069293184867341, "spearman": 0.10069293184867492, "kendall": 0.10069293184867494}, "p_value": {"pearson": 0.0011287070200408484, "spearman": 0.0011287070200406103, "kendall": 0.0011525481315601222}, "kappa_score": 0.031877888933684484, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.11570720470801707, "spearman": 0.11570720470801882, "kendall": 0.11570720470801882}, "p_value": {"pearson": 0.00018044620300789553, "spearman": 0.00018044620300785015, "kendall": 0.00018769174044921537}, "kappa_score": 0.030791529677943852, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.17022062292333684, "spearman": 0.17022062292333717, "kendall": 0.17022062292333723}, "p_value": {"pearson": 3.180770487479703e-08, "spearman": 3.180770487479698e-08, "kendall": 3.91317664819732e-08}, "kappa_score": 0.0563182949355816, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.06670789260120084, "spearman": 0.06670789260120182, "kendall": 0.06670789260120182}, "p_value": {"pearson": 0.031225910068468893, "spearman": 0.03122591006846662, "kendall": 0.03129256210352417}, "kappa_score": 0.011582984875367908, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.41609682255711117, "spearman": 0.4160968225571111, "kendall": 0.4160968225571111}, "p_value": {"pearson": 6.255120804452708e-45, "spearman": 6.255120804452484e-45, "kendall": 3.9470450283888923e-41}, "kappa_score": 0.30812011868172806, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.24152054335723344, "spearman": 0.24152054335723738, "kendall": 0.24152054335723733}, "p_value": {"pearson": 2.6148451588386567e-15, "spearman": 2.6148451588357474e-15, "kendall": 6.375422125438816e-15}, "kappa_score": 0.11023414833122436, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.22199901515758824, "spearman": 0.22199901515759132, "kendall": 0.22199901515759138}, "p_value": {"pearson": 4.1173183951451104e-13, "spearman": 4.1173183951422635e-13, "kendall": 7.714542887986631e-13}, "kappa_score": 0.12676199914103847, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.14389731061418506, "spearman": 0.1438973106141841, "kendall": 0.1438973106141841}, "p_value": {"pearson": 3.0716775874479664e-06, "spearman": 3.071677587448519e-06, "kendall": 3.400620368905069e-06}, "kappa_score": 0.05277924184066485, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.47485403613617805, "spearman": 0.47485403613618526, "kendall": 0.47485403613618526}, "p_value": {"pearson": 9.010815166056039e-60, "spearman": 9.010815166014551e-60, "kendall": 4.9476600854586155e-53}, "kappa_score": 0.45665919507544084, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.506760156947722, "spearman": 0.5067601569477199, "kendall": 0.50676015694772}, "p_value": {"pearson": 3.9431848776351413e-69, "spearman": 3.943184877640885e-69, "kendall": 3.8001061152649517e-60}, "kappa_score": 0.47868342620189197, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.5024782651723814, "spearman": 0.5024782651723834, "kendall": 0.5024782651723833}, "p_value": {"pearson": 8.130409077968807e-68, "spearman": 8.130409077957038e-68, "kendall": 3.641303949255213e-59}, "kappa_score": 0.481623220098904, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.5345536248290355, "spearman": 0.5345536248290426, "kendall": 0.5345536248290426}, "p_value": {"pearson": 3.9255967407036424e-78, "spearman": 3.925596740682208e-78, "kendall": 1.019059931347013e-66}, "kappa_score": 0.4763296774409497, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.09450685652222966, "spearman": 0.0945068565222299, "kendall": 0.09450685652222988}, "p_value": {"pearson": 0.002248146065508668, "spearman": 0.0022481460655085885, "kendall": 0.002283209844277623}, "kappa_score": 0.022143464430030346, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.26683356246033585, "spearman": 0.2668335624603369, "kendall": 0.2668335624603369}, "p_value": {"pearson": 1.8410692745889124e-18, "spearman": 1.84106927458824e-18, "kendall": 7.09288020993604e-18}, "kappa_score": 0.14335090715994436, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.13797127650489166, "spearman": 0.13797127650489277, "kendall": 0.13797127650489274}, "p_value": {"pearson": 7.752308151029216e-06, "spearman": 7.752308151028306e-06, "kendall": 8.439663121059879e-06}, "kappa_score": 0.05009658500931036, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mistral-7B-Instruct-v0.2 (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.010626517721091733, "spearman": 0.0106265177210919, "kendall": 0.010626517721091902}, "p_value": {"pearson": 0.7317587321496094, "spearman": 0.731758732149607, "kendall": 0.7315802128197966}, "kappa_score": 0.0026560548406774354, "total_responses": 1043, "valid_responses": 862, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.13230950354216334, "spearman": 0.13230950354216417, "kendall": 0.13230950354216417}, "p_value": {"pearson": 1.8131593154170312e-05, "spearman": 1.8131593154166893e-05, "kendall": 1.9463850956451184e-05}, "kappa_score": 0.05838597421535807, "total_responses": 1043, "valid_responses": 955, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.0746378576279481, "spearman": 0.07463785762794804, "kendall": 0.07463785762794803}, "p_value": {"pearson": 0.0159114342492149, "spearman": 0.01591143424921542, "kendall": 0.015982632732161654}, "kappa_score": 0.017503362920396115, "total_responses": 1043, "valid_responses": 926, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.07283779967976167, "spearman": 0.07283779967976102, "kendall": 0.07283779967976102}, "p_value": {"pearson": 0.018640738341236345, "spearman": 0.018640738341237126, "kendall": 0.0187126719161855}, "kappa_score": 0.01444805342504396, "total_responses": 1043, "valid_responses": 821, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.040547782835547136, "spearman": 0.04054778283554714, "kendall": 0.04054778283554715}, "p_value": {"pearson": 0.19071082406749162, "spearman": 0.19071082406749676, "kendall": 0.19057383865993238}, "kappa_score": 0.0067371592217585485, "total_responses": 1043, "valid_responses": 1012, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.1225109590111779, "spearman": 0.12251095901117792, "kendall": 0.12251095901117794}, "p_value": {"pearson": 7.285609190743551e-05, "spearman": 7.285609190743534e-05, "kendall": 7.664459494882182e-05}, "kappa_score": 0.03373888053846086, "total_responses": 1043, "valid_responses": 1013, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.05149232704623563, "spearman": 0.051492327046235145, "kendall": 0.051492327046235145}, "p_value": {"pearson": 0.09649682494960286, "spearman": 0.09649682494960822, "kendall": 0.09647797310419028}, "kappa_score": 0.010162474266268262, "total_responses": 1043, "valid_responses": 978, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.15684394913942645, "spearman": 0.1568439491394286, "kendall": 0.15684394913942856}, "p_value": {"pearson": 3.5651806484909175e-07, "spearman": 3.565180648489801e-07, "kendall": 4.128689190203704e-07}, "kappa_score": 0.05339945302274118, "total_responses": 1043, "valid_responses": 919, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.32147283626804796, "spearman": 0.3214728362680441, "kendall": 0.3214728362680441}, "p_value": {"pearson": 1.67489368845091e-26, "spearman": 1.674893688453363e-26, "kendall": 3.150360479299447e-25}, "kappa_score": 0.22029261720707471, "total_responses": 1043, "valid_responses": 910, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.0783754883956226, "spearman": 0.07837548839562254, "kendall": 0.07837548839562254}, "p_value": {"pearson": 0.01134020547772216, "spearman": 0.011340205477723034, "kendall": 0.011407465051488801}, "kappa_score": 0.01844713847377566, "total_responses": 1043, "valid_responses": 955, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.09611138731024037, "spearman": 0.09611138731024021, "kendall": 0.0961113873102402}, "p_value": {"pearson": 0.0018871500612511458, "spearman": 0.0018871500612511274, "kendall": 0.0019190783456363588}, "kappa_score": 0.02649137245831812, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.15614928463311709, "spearman": 0.15614928463311703, "kendall": 0.15614928463311706}, "p_value": {"pearson": 4.0203521716752324e-07, "spearman": 4.0203521716753156e-07, "kendall": 4.6431038773106104e-07}, "kappa_score": 0.057982395100794615, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.07541880717780786, "spearman": 0.07541880717780809, "kendall": 0.07541880717780808}, "p_value": {"pearson": 0.014840893602270857, "spearman": 0.014840893602270621, "kendall": 0.014911516014432025}, "kappa_score": 0.01131165231374709, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.21565498100863484, "spearman": 0.21565498100863606, "kendall": 0.21565498100863603}, "p_value": {"pearson": 1.931717688754895e-12, "spearman": 1.9317176887542434e-12, "kendall": 3.3703175716236304e-12}, "kappa_score": 0.09510218101851708, "total_responses": 1043, "valid_responses": 960, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.14175412140680899, "spearman": 0.14175412140680924, "kendall": 0.14175412140680924}, "p_value": {"pearson": 4.311793436719511e-06, "spearman": 4.311793436719228e-06, "kendall": 4.743434289166754e-06}, "kappa_score": 0.057111980117551475, "total_responses": 1043, "valid_responses": 1009, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.05923764595386209, "spearman": 0.059237645953862834, "kendall": 0.059237645953862834}, "p_value": {"pearson": 0.055812657125482584, "spearman": 0.055812657125480274, "kendall": 0.05585148473169221}, "kappa_score": 0.01596823506856493, "total_responses": 1043, "valid_responses": 1001, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.03014694827518657, "spearman": 0.03014694827518639, "kendall": 0.03014694827518639}, "p_value": {"pearson": 0.3307199865248662, "spearman": 0.33071998652488, "kendall": 0.330481620438161}, "kappa_score": 0.0059678878160778215, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.09389715365033369, "spearman": 0.09389715365033362, "kendall": 0.09389715365033363}, "p_value": {"pearson": 0.0024011424658247882, "spearman": 0.002401142465824636, "kendall": 0.002437432726037338}, "kappa_score": 0.02429441424923051, "total_responses": 1043, "valid_responses": 992, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.09983184018965302, "spearman": 0.09983184018965255, "kendall": 0.09983184018965255}, "p_value": {"pearson": 0.0012451874604845956, "spearman": 0.0012451874604846778, "kendall": 0.0012704422248443815}, "kappa_score": 0.026702687065783826, "total_responses": 1043, "valid_responses": 988, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.13707308705671498, "spearman": 0.13707308705671337, "kendall": 0.13707308705671334}, "p_value": {"pearson": 8.89106024270001e-06, "spearman": 8.891060242701917e-06, "kendall": 9.656626568782249e-06}, "kappa_score": 0.06007810153199167, "total_responses": 1043, "valid_responses": 858, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.2944909194453649, "spearman": 0.2944909194453664, "kendall": 0.29449091944536643}, "p_value": {"pearson": 2.5876179463097644e-22, "spearman": 2.587617946308276e-22, "kendall": 1.9780371821109175e-21}, "kappa_score": 0.1861046082716118, "total_responses": 1043, "valid_responses": 961, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.0975759954467928, "spearman": 0.09757599544679321, "kendall": 0.09757599544679323}, "p_value": {"pearson": 0.0016048755680013742, "spearman": 0.0016048755680011988, "kendall": 0.0016340712576257575}, "kappa_score": 0.03842427651728253, "total_responses": 1043, "valid_responses": 913, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.18755338321568837, "spearman": 0.18755338321569073, "kendall": 0.18755338321569073}, "p_value": {"pearson": 1.033720393341772e-09, "spearman": 1.0337203933412113e-09, "kendall": 1.4109277980335226e-09}, "kappa_score": 0.09274004683840753, "total_responses": 1043, "valid_responses": 706, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.20625899404758147, "spearman": 0.20625899404758005, "kendall": 0.20625899404758002}, "p_value": {"pearson": 1.747520744761257e-11, "spearman": 1.7475207447618048e-11, "kendall": 2.774929942547756e-11}, "kappa_score": 0.08161348146586034, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.25123218069798625, "spearman": 0.25123218069798975, "kendall": 0.25123218069798975}, "p_value": {"pearson": 1.774770609559338e-16, "spearman": 1.7747706095576979e-16, "kendall": 5.071106837543584e-16}, "kappa_score": 0.12761074698202401, "total_responses": 1043, "valid_responses": 987, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.2036890919531517, "spearman": 0.20368909195314916, "kendall": 0.2036890919531492}, "p_value": {"pearson": 3.134998485359203e-11, "spearman": 3.13499848536097e-11, "kendall": 4.8624095599199905e-11}, "kappa_score": 0.08242244891579564, "total_responses": 1043, "valid_responses": 985, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.13501691909987837, "spearman": 0.13501691909987903, "kendall": 0.13501691909987903}, "p_value": {"pearson": 1.2128779275442723e-05, "spearman": 1.2128779275442086e-05, "kendall": 1.3104699491589151e-05}, "kappa_score": 0.03580640163709736, "total_responses": 1043, "valid_responses": 820, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": -0.01744244082324385, "spearman": -0.017442440823244046, "kendall": -0.017442440823244046}, "p_value": {"pearson": 0.5736529061681208, "spearman": 0.5736529061681008, "kendall": 0.5734059972617326}, "kappa_score": -0.0021516149430478304, "total_responses": 1043, "valid_responses": 1012, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.0737542171085695, "spearman": 0.07375421710856989, "kendall": 0.07375421710856989}, "p_value": {"pearson": 0.017203985276882324, "spearman": 0.017203985276882622, "kendall": 0.01727565301376212}, "kappa_score": 0.010820508927454453, "total_responses": 1043, "valid_responses": 1016, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.022078935056410395, "spearman": 0.0220789350564107, "kendall": 0.0220789350564107}, "p_value": {"pearson": 0.47629000324887544, "spearman": 0.4762900032488556, "kendall": 0.4760261117705419}, "kappa_score": 0.0020031867956433747, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.048559279233097545, "spearman": 0.048559279233096976, "kendall": 0.04855927923309698}, "p_value": {"pearson": 0.11704673117297947, "spearman": 0.1170467311729894, "kendall": 0.1169990954236259}, "kappa_score": 0.007701380285939252, "total_responses": 1043, "valid_responses": 985, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.04602175716465778, "spearman": 0.0460217571646576, "kendall": 0.0460217571646576}, "p_value": {"pearson": 0.13746413316935346, "spearman": 0.13746413316935405, "kendall": 0.13738933216305546}, "kappa_score": 0.0069545996871188676, "total_responses": 1043, "valid_responses": 982, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.07608183785559507, "spearman": 0.0760818378555945, "kendall": 0.0760818378555945}, "p_value": {"pearson": 0.013982279586211097, "spearman": 0.013982279586211396, "kendall": 0.014052302434823092}, "kappa_score": 0.0186420112255109, "total_responses": 1043, "valid_responses": 915, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.37701895343134983, "spearman": 0.37701895343135455, "kendall": 0.37701895343135455}, "p_value": {"pearson": 1.4343261342693389e-36, "spearman": 1.4343261342663133e-36, "kendall": 4.480869113352093e-34}, "kappa_score": 0.2519852558195441, "total_responses": 1043, "valid_responses": 961, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.5023417101398582, "spearman": 0.5023417101398564, "kendall": 0.5023417101398563}, "p_value": {"pearson": 8.947862721471726e-68, "spearman": 8.947862721482848e-68, "kendall": 3.9121993390844848e-59}, "kappa_score": 0.42213516640844106, "total_responses": 1043, "valid_responses": 968, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.16125496544509088, "spearman": 0.16125496544509296, "kendall": 0.161254965445093}, "p_value": {"pearson": 1.642108931545551e-07, "spearman": 1.6421089315449656e-07, "kendall": 1.9366855289370412e-07}, "kappa_score": 0.07343713625940218, "total_responses": 1043, "valid_responses": 1014, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.07257224851962052, "spearman": 0.07257224851962084, "kendall": 0.07257224851962082}, "p_value": {"pearson": 0.01907619144438978, "spearman": 0.01907619144438873, "kendall": 0.0191481575814841}, "kappa_score": 0.014361967267591647, "total_responses": 1043, "valid_responses": 971, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.04347114340626089, "spearman": 0.04347114340626171, "kendall": 0.04347114340626171}, "p_value": {"pearson": 0.16064591936366793, "spearman": 0.1606459193636643, "kendall": 0.1605424256492759}, "kappa_score": 0.005301272761575437, "total_responses": 1043, "valid_responses": 1017, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.036214159537035065, "spearman": 0.03621415953703497, "kendall": 0.036214159537034975}, "p_value": {"pearson": 0.24259077743167193, "spearman": 0.24259077743167276, "kendall": 0.24240606192083114}, "kappa_score": 0.004077583463036549, "total_responses": 1043, "valid_responses": 972, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.038379372745480644, "spearman": 0.03837937274548078, "kendall": 0.038379372745480776}, "p_value": {"pearson": 0.21554872257663, "spearman": 0.21554872257662896, "kendall": 0.2153873103670979}, "kappa_score": 0.00441065139396335, "total_responses": 1043, "valid_responses": 1020, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.03970135792119857, "spearman": 0.03970135792119841, "kendall": 0.039701357921198416}, "p_value": {"pearson": 0.20014335936964817, "spearman": 0.20014335936964509, "kendall": 0.19999675257147365}, "kappa_score": 0.003147434661919024, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.05862698789004743, "spearman": 0.05862698789004696, "kendall": 0.05862698789004697}, "p_value": {"pearson": 0.05839162194333789, "spearman": 0.05839162194333963, "kendall": 0.058426973118476076}, "kappa_score": 0.008631599300868542, "total_responses": 1043, "valid_responses": 943, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.044373349164914255, "spearman": 0.04437334916491443, "kendall": 0.044373349164914436}, "p_value": {"pearson": 0.15213039140928425, "spearman": 0.1521303914092784, "kendall": 0.15203715551176833}, "kappa_score": 0.00393024959389765, "total_responses": 1043, "valid_responses": 1007, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.011236086686667436, "spearman": 0.011236086686667342, "kendall": 0.011236086686667342}, "p_value": {"pearson": 0.7170146877065633, "spearman": 0.7170146877065653, "kendall": 0.7168281355501858}, "kappa_score": 0.0016157094079308765, "total_responses": 1043, "valid_responses": 996, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.039900391089589905, "spearman": 0.03990039108958996, "kendall": 0.03990039108958996}, "p_value": {"pearson": 0.1978953234871774, "spearman": 0.19789532348718206, "kendall": 0.19775097127429675}, "kappa_score": 0.0031790212853136657, "total_responses": 1043, "valid_responses": 994, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.16949471911247402, "spearman": 0.16949471911247202, "kendall": 0.16949471911247202}, "p_value": {"pearson": 3.644864871760393e-08, "spearman": 3.64486487176158e-08, "kendall": 4.4676211082204085e-08}, "kappa_score": 0.0686926974012565, "total_responses": 1043, "valid_responses": 914, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.06925570372681619, "spearman": 0.069255703726817, "kendall": 0.06925570372681701}, "p_value": {"pearson": 0.025309080247469373, "spearman": 0.02530908024746839, "kendall": 0.02537956912512419}, "kappa_score": 0.027683550853791816, "total_responses": 1043, "valid_responses": 875, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.04204201319613729, "spearman": 0.0420420131961379, "kendall": 0.04204201319613791}, "p_value": {"pearson": 0.1748638316459146, "spearman": 0.17486383164590658, "kendall": 0.17474396526125346}, "kappa_score": 0.005076752854733524, "total_responses": 1043, "valid_responses": 938, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.00776002822991916, "spearman": 0.00776002822991921, "kendall": 0.00776002822991921}, "p_value": {"pearson": 0.8023419602603494, "spearman": 0.8023419602603444, "kendall": 0.802205418695692}, "kappa_score": 0.0019701339503198634, "total_responses": 1043, "valid_responses": 819, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.09184919040994116, "spearman": 0.09184919040994213, "kendall": 0.09184919040994213}, "p_value": {"pearson": 0.002987342466096812, "spearman": 0.0029873424660965273, "kendall": 0.003027870985848691}, "kappa_score": 0.023829906182847305, "total_responses": 1043, "valid_responses": 1016, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.13926604849727098, "spearman": 0.1392660484972692, "kendall": 0.13926604849726917}, "p_value": {"pearson": 6.352910267374718e-06, "spearman": 6.352910267376682e-06, "kendall": 6.940290793267152e-06}, "kappa_score": 0.04103866105763021, "total_responses": 1043, "valid_responses": 962, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.06653697712277447, "spearman": 0.0665369771227747, "kendall": 0.0665369771227747}, "p_value": {"pearson": 0.03166213247388812, "spearman": 0.031662132473886447, "kendall": 0.03172843342836762}, "kappa_score": 0.0115314170696047, "total_responses": 1043, "valid_responses": 943, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.3314754027093203, "spearman": 0.33147540270932097, "kendall": 0.33147540270932097}, "p_value": {"pearson": 3.6170484010364204e-28, "spearman": 3.6170484010353693e-28, "kendall": 1.0174064351771316e-26}, "kappa_score": 0.23339154366949055, "total_responses": 1043, "valid_responses": 857, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.14685845877525613, "spearman": 0.14685845877525866, "kendall": 0.14685845877525863}, "p_value": {"pearson": 1.9070874974956627e-06, "spearman": 1.9070874974948832e-06, "kendall": 2.130918350681064e-06}, "kappa_score": 0.04222414843676259, "total_responses": 1043, "valid_responses": 958, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.3100007926457936, "spearman": 0.31000079264579766, "kendall": 0.3100007926457977}, "p_value": {"pearson": 1.1440730791944484e-24, "spearman": 1.1440730791926896e-24, "kendall": 1.4223252765920284e-23}, "kappa_score": 0.21913813877960708, "total_responses": 1043, "valid_responses": 953, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.10348595323018941, "spearman": 0.10348595323018923, "kendall": 0.10348595323018925}, "p_value": {"pearson": 0.0008165754206318761, "spearman": 0.0008165754206318822, "kendall": 0.0008361890665362579}, "kappa_score": 0.02119173547817832, "total_responses": 1043, "valid_responses": 977, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.30963189370054733, "spearman": 0.30963189370054944, "kendall": 0.30963189370054944}, "p_value": {"pearson": 1.3065267020980759e-24, "spearman": 1.3065267020969801e-24, "kendall": 1.604082904283236e-23}, "kappa_score": 0.3004053961201072, "total_responses": 1043, "valid_responses": 929, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.16726239561205555, "spearman": 0.16726239561205414, "kendall": 0.1672623956120541}, "p_value": {"pearson": 5.5206967333641036e-08, "spearman": 5.520696733365631e-08, "kendall": 6.69259312731341e-08}, "kappa_score": 0.08086445656735208, "total_responses": 1043, "valid_responses": 935, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.17843592187790921, "spearman": 0.17843592187791024, "kendall": 0.17843592187791024}, "p_value": {"pearson": 6.537422332868723e-09, "spearman": 6.537422332867502e-09, "kendall": 8.415581557750595e-09}, "kappa_score": 0.07315549667999999, "total_responses": 1043, "valid_responses": 852, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.30308705508413203, "spearman": 0.30308705508413913, "kendall": 0.3030870550841391}, "p_value": {"pearson": 1.3354138912840922e-23, "spearman": 1.3354138912808223e-23, "kendall": 1.3233963128776327e-22}, "kappa_score": 0.19063907125864066, "total_responses": 1043, "valid_responses": 914, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": -0.00102099624973728, "spearman": -0.0010209962497373048, "kendall": -0.0010209962497373048}, "p_value": {"pearson": 0.973727168240267, "spearman": 0.9737271682402631, "kendall": 0.9737082526295493}, "kappa_score": -0.00015459240256743279, "total_responses": 1043, "valid_responses": 957, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.12966569387130486, "spearman": 0.1296656938713064, "kendall": 0.1296656938713064}, "p_value": {"pearson": 2.665116636758863e-05, "spearman": 2.6651166367581488e-05, "kendall": 2.843990289505973e-05}, "kappa_score": 0.039677545423834504, "total_responses": 1043, "valid_responses": 952, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.12357018518294653, "spearman": 0.12357018518294718, "kendall": 0.12357018518294718}, "p_value": {"pearson": 6.298977397047372e-05, "spearman": 6.29897739704661e-05, "kendall": 6.639476728755535e-05}, "kappa_score": 0.04861778680040896, "total_responses": 1043, "valid_responses": 993, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": -0.017182573060834865, "spearman": -0.01718257306083478, "kendall": -0.01718257306083478}, "p_value": {"pearson": 0.5793766507909585, "spearman": 0.579376650790959, "kendall": 0.5791314248216998}, "kappa_score": -0.01302143351002516, "total_responses": 1043, "valid_responses": 787, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.061884812541000214, "spearman": 0.06188481254099955, "kendall": 0.06188481254099954}, "p_value": {"pearson": 0.04570360891491628, "spearman": 0.045703608914918, "kendall": 0.04575534725639806}, "kappa_score": 0.05744196112191857, "total_responses": 1043, "valid_responses": 600, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.030793585750287636, "spearman": 0.0307935857502878, "kendall": 0.030793585750287792}, "p_value": {"pearson": 0.32044800694700587, "spearman": 0.32044800694700304, "kendall": 0.3202142449257843}, "kappa_score": 0.01239333826201916, "total_responses": 1043, "valid_responses": 317, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": -0.016100351683704144, "spearman": -0.016100351683704134, "kendall": -0.016100351683704134}, "p_value": {"pearson": 0.6034963109795523, "spearman": 0.6034963109795513, "kendall": 0.6032589184251322}, "kappa_score": -0.01065891472868219, "total_responses": 1043, "valid_responses": 881, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.04396167604114022, "spearman": 0.04396167604114084, "kendall": 0.043961676041140846}, "p_value": {"pearson": 0.155972435705308, "spearman": 0.15597243570530744, "kendall": 0.1558745303091336}, "kappa_score": 0.02203191416816297, "total_responses": 1043, "valid_responses": 835, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.1984237622079662, "spearman": 0.19842376220796573, "kendall": 0.19842376220796573}, "p_value": {"pearson": 1.0136706502008826e-10, "spearman": 1.0136706502009997e-10, "kendall": 1.5024725679342463e-10}, "kappa_score": 0.13430541055882939, "total_responses": 1043, "valid_responses": 881, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.10734486734310233, "spearman": 0.10734486734310214, "kendall": 0.10734486734310215}, "p_value": {"pearson": 0.000515368870836395, "spearman": 0.0005153688708364184, "kendall": 0.0005300442500541851}, "kappa_score": 0.04865308187284667, "total_responses": 1043, "valid_responses": 690, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.12356397112979452, "spearman": 0.12356397112979575, "kendall": 0.12356397112979575}, "p_value": {"pearson": 6.30437840860857e-05, "spearman": 6.304378408607577e-05, "kendall": 6.645092529313934e-05}, "kappa_score": 0.09085866429997791, "total_responses": 1043, "valid_responses": 921, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.24907742691225687, "spearman": 0.24907742691225276, "kendall": 0.2490774269122527}, "p_value": {"pearson": 3.2563872892152684e-16, "spearman": 3.256387289219009e-16, "kendall": 8.967328562887421e-16}, "kappa_score": 0.1931371757614897, "total_responses": 1043, "valid_responses": 821, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.13172002668862404, "spearman": 0.13172002668862387, "kendall": 0.1317200266886239}, "p_value": {"pearson": 1.9770160924758046e-05, "spearman": 1.9770160924758395e-05, "kendall": 2.1194015665610476e-05}, "kappa_score": 0.07947132714363747, "total_responses": 1043, "valid_responses": 784, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": -0.024740993993802564, "spearman": -0.024740993993802578, "kendall": -0.024740993993802578}, "p_value": {"pearson": 0.4247619344153857, "spearman": 0.4247619344153738, "kendall": 0.4244992451727805}, "kappa_score": -0.013145864142388719, "total_responses": 1043, "valid_responses": 867, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.16043242335358643, "spearman": 0.16043242335358554, "kendall": 0.16043242335358554}, "p_value": {"pearson": 1.900569400567256e-07, "spearman": 1.900569400567743e-07, "kendall": 2.2336249178566045e-07}, "kappa_score": 0.1429477633060794, "total_responses": 1043, "valid_responses": 765, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.07706993939712327, "spearman": 0.0770699393971234, "kendall": 0.07706993939712338}, "p_value": {"pearson": 0.012783936999611282, "spearman": 0.012783936999610352, "kendall": 0.012852892779170528}, "kappa_score": 0.05427565250225397, "total_responses": 1043, "valid_responses": 726, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.3542158995257027, "spearman": 0.3542158995257044, "kendall": 0.3542158995257044}, "p_value": {"pearson": 3.4277413541283126e-32, "spearman": 3.427741354126198e-32, "kendall": 2.8245666529254585e-30}, "kappa_score": 0.2714729916481403, "total_responses": 1043, "valid_responses": 753, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.05958125451013677, "spearman": 0.05958125451013753, "kendall": 0.05958125451013752}, "p_value": {"pearson": 0.054403644991317016, "spearman": 0.05440364499131485, "kendall": 0.0544443461461447}, "kappa_score": 0.0513279212569302, "total_responses": 1043, "valid_responses": 785, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.10199095286908201, "spearman": 0.10199095286908101, "kendall": 0.101990952869081}, "p_value": {"pearson": 0.0009720118517050828, "spearman": 0.0009720118517051568, "kendall": 0.0009938197824229578}, "kappa_score": 0.09455590863390984, "total_responses": 1043, "valid_responses": 784, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": -0.027751541411237236, "spearman": -0.027751541411236976, "kendall": -0.02775154141123698}, "p_value": {"pearson": 0.37060113156222224, "spearman": 0.3706011315622145, "kendall": 0.3703486689190666}, "kappa_score": -0.02510721944245886, "total_responses": 1043, "valid_responses": 915, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.051097304074516924, "spearman": 0.051097304074516334, "kendall": 0.05109730407451634}, "p_value": {"pearson": 0.09908369684126088, "spearman": 0.09908369684126139, "kendall": 0.09906116118556853}, "kappa_score": 0.017007868377001856, "total_responses": 1043, "valid_responses": 823, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.2748384061080525, "spearman": 0.2748384061080501, "kendall": 0.2748384061080501}, "p_value": {"pearson": 1.5659883203713561e-19, "spearman": 1.565988320372553e-19, "kendall": 7.1979058661421735e-19}, "kappa_score": 0.24052357435213845, "total_responses": 1043, "valid_responses": 803, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.053041930995397245, "spearman": 0.05304193099539693, "kendall": 0.05304193099539694}, "p_value": {"pearson": 0.08686580945987918, "spearman": 0.08686580945988409, "kendall": 0.08686076675197563}, "kappa_score": 0.02099081288521909, "total_responses": 1043, "valid_responses": 800, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.10089842722714572, "spearman": 0.10089842722714633, "kendall": 0.10089842722714633}, "p_value": {"pearson": 0.0011024381719072164, "spearman": 0.0011024381719071373, "kendall": 0.0011259495278355622}, "kappa_score": 0.08170901709506218, "total_responses": 1043, "valid_responses": 796, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.017233107644547756, "spearman": 0.01723310764454779, "kendall": 0.017233107644547795}, "p_value": {"pearson": 0.5782615020507025, "spearman": 0.5782615020507016, "kendall": 0.5780159427745171}, "kappa_score": 0.01387216113048706, "total_responses": 1043, "valid_responses": 845, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.03657786978343827, "spearman": 0.03657786978343828, "kendall": 0.036577869783438285}, "p_value": {"pearson": 0.2378891005756451, "spearman": 0.23788910057565213, "kendall": 0.2377081944370727}, "kappa_score": 0.024044440759472763, "total_responses": 1043, "valid_responses": 624, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.23320388890040059, "spearman": 0.23320388890039925, "kendall": 0.23320388890039925}, "p_value": {"pearson": 2.387592644898761e-14, "spearman": 2.387592644899578e-14, "kendall": 5.159155945971957e-14}, "kappa_score": 0.18817286795537413, "total_responses": 1043, "valid_responses": 747, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.03434510639213031, "spearman": 0.03434510639213055, "kendall": 0.03434510639213055}, "p_value": {"pearson": 0.2677799320139978, "spearman": 0.26777993201399286, "kendall": 0.2675765016807442}, "kappa_score": 0.030688643833907903, "total_responses": 1043, "valid_responses": 807, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.24635712410622213, "spearman": 0.2463571241062217, "kendall": 0.2463571241062217}, "p_value": {"pearson": 6.949267180578077e-16, "spearman": 6.949267180578693e-16, "kendall": 1.8291169775761935e-15}, "kappa_score": 0.15720802643498022, "total_responses": 1043, "valid_responses": 793, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.02690189159897958, "spearman": 0.026901891598979426, "kendall": 0.026901891598979422}, "p_value": {"pearson": 0.38543507069530597, "spearman": 0.3854350706953069, "kendall": 0.38517882748091503}, "kappa_score": 0.01001572062763878, "total_responses": 1043, "valid_responses": 654, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.06371768214687602, "spearman": 0.06371768214687612, "kendall": 0.0637176821468761}, "p_value": {"pearson": 0.039645995567977196, "spearman": 0.03964599556797686, "kendall": 0.03970466372529936}, "kappa_score": 0.018176928076742094, "total_responses": 1043, "valid_responses": 918, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.14763272293478635, "spearman": 0.14763272293478708, "kendall": 0.14763272293478708}, "p_value": {"pearson": 1.681010612565528e-06, "spearman": 1.681010612565417e-06, "kendall": 1.8830373014106978e-06}, "kappa_score": 0.07423884504271461, "total_responses": 1043, "valid_responses": 876, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.0819013782657713, "spearman": 0.08190137826577194, "kendall": 0.08190137826577192}, "p_value": {"pearson": 0.008137233733332801, "spearman": 0.008137233733332055, "kendall": 0.00819862830145321}, "kappa_score": 0.02871636753783824, "total_responses": 1043, "valid_responses": 856, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.0433322861092687, "spearman": 0.04333228610926837, "kendall": 0.04333228610926838}, "p_value": {"pearson": 0.1619878639221638, "spearman": 0.16198786392217057, "kendall": 0.16188278432057857}, "kappa_score": 0.018236764171611797, "total_responses": 1043, "valid_responses": 696, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.06701565579714917, "spearman": 0.06701565579714942, "kendall": 0.06701565579714941}, "p_value": {"pearson": 0.030453393927246847, "spearman": 0.030453393927246632, "kendall": 0.03052064737628122}, "kappa_score": 0.03409399756399556, "total_responses": 1043, "valid_responses": 762, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.09963738380080853, "spearman": 0.09963738380080862, "kendall": 0.09963738380080864}, "p_value": {"pearson": 0.0012729816134999258, "spearman": 0.0012729816134999647, "kendall": 0.0012985626808860885}, "kappa_score": 0.03474878269818593, "total_responses": 1043, "valid_responses": 252, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.17062845050025793, "spearman": 0.17062845050026001, "kendall": 0.17062845050026004}, "p_value": {"pearson": 2.9457103126773645e-08, "spearman": 2.945710312676219e-08, "kendall": 3.631589444267644e-08}, "kappa_score": 0.15096857116626372, "total_responses": 1043, "valid_responses": 726, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.47796925397846846, "spearman": 0.47796925397847456, "kendall": 0.4779692539784746}, "p_value": {"pearson": 1.213295897876678e-60, "spearman": 1.213295897871778e-60, "kendall": 1.0470436527662326e-53}, "kappa_score": 0.4767226614535578, "total_responses": 1043, "valid_responses": 997, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.09546825614870175, "spearman": 0.0954682561487032, "kendall": 0.09546825614870319}, "p_value": {"pearson": 0.0020249311825228347, "spearman": 0.0020249311825224848, "kendall": 0.00205809937525479}, "kappa_score": 0.08318476699846478, "total_responses": 1043, "valid_responses": 900, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": -0.02242167434570506, "spearman": -0.02242167434570514, "kendall": -0.022421674345705134}, "p_value": {"pearson": 0.46946977018768177, "spearman": 0.46946977018767977, "kendall": 0.46920559697569575}, "kappa_score": -0.014171524311494377, "total_responses": 1043, "valid_responses": 805, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.014118244862387306, "spearman": 0.01411824486238759, "kendall": 0.014118244862387592}, "p_value": {"pearson": 0.6487985685534483, "spearman": 0.6487985685534423, "kendall": 0.6485789005251116}, "kappa_score": 0.007667666878719226, "total_responses": 1043, "valid_responses": 502, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": -0.002858951829593788, "spearman": -0.0028589518295938374, "kendall": -0.002858951829593837}, "p_value": {"pearson": 0.9265226280541721, "spearman": 0.9265226280541761, "kendall": 0.9264699882548182}, "kappa_score": -0.0008727574687490414, "total_responses": 1043, "valid_responses": 552, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.039361550787776436, "spearman": 0.0393615507877765, "kendall": 0.0393615507877765}, "p_value": {"pearson": 0.204024335767058, "spearman": 0.20402433576705817, "kendall": 0.20387389322296767}, "kappa_score": 0.009072779094947525, "total_responses": 1043, "valid_responses": 635, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.09633770953223189, "spearman": 0.09633770953223231, "kendall": 0.09633770953223231}, "p_value": {"pearson": 0.001840746633287459, "spearman": 0.0018407466332873523, "kendall": 0.0018722442284088133}, "kappa_score": 0.03049412519978345, "total_responses": 1043, "valid_responses": 691, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": -0.012779651615998148, "spearman": -0.012779651615998314, "kendall": -0.012779651615998314}, "p_value": {"pearson": 0.6801581734105389, "spearman": 0.6801581734105377, "kendall": 0.6799528498868693}, "kappa_score": -0.006364065611463632, "total_responses": 1043, "valid_responses": 525, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.05064144764724311, "spearman": 0.050641447647242654, "kendall": 0.05064144764724265}, "p_value": {"pearson": 0.10213731096631469, "spearman": 0.1021373109663152, "kendall": 0.10211044555508618}, "kappa_score": 0.028213052348304513, "total_responses": 1043, "valid_responses": 711, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.030535044195943318, "spearman": 0.030535044195943356, "kendall": 0.030535044195943353}, "p_value": {"pearson": 0.32452974277524954, "spearman": 0.32452974277525837, "kendall": 0.324294101942474}, "kappa_score": 0.018819470406126304, "total_responses": 1043, "valid_responses": 795, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.022541803327535935, "spearman": 0.022541803327535744, "kendall": 0.02254180332753574}, "p_value": {"pearson": 0.4670921241453596, "spearman": 0.46709212414537815, "kendall": 0.4668278832504915}, "kappa_score": 0.006420378175934105, "total_responses": 1043, "valid_responses": 739, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.10147869842746843, "spearman": 0.10147869842746798, "kendall": 0.101478698427468}, "p_value": {"pearson": 0.001031278171482693, "spearman": 0.001031278171482741, "kendall": 0.001053874333987134}, "kappa_score": 0.07436776336565865, "total_responses": 1043, "valid_responses": 509, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.013592596799459922, "spearman": 0.013592596799460349, "kendall": 0.01359259679946035}, "p_value": {"pearson": 0.6610429195760992, "spearman": 0.6610429195760884, "kendall": 0.6608286626725279}, "kappa_score": 0.008907902833533488, "total_responses": 1043, "valid_responses": 803, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.05678976533683657, "spearman": 0.05678976533683666, "kendall": 0.05678976533683665}, "p_value": {"pearson": 0.06675278644274513, "spearman": 0.06675278644274303, "kendall": 0.06677654562183946}, "kappa_score": 0.019875425159460725, "total_responses": 1043, "valid_responses": 769, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.03906296082280186, "spearman": 0.03906296082280209, "kendall": 0.0390629608228021}, "p_value": {"pearson": 0.2074794546873376, "spearman": 0.20747945468732976, "kendall": 0.20732565742863285}, "kappa_score": 0.016550457805017293, "total_responses": 1043, "valid_responses": 747, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.09701288803021645, "spearman": 0.09701288803021689, "kendall": 0.09701288803021689}, "p_value": {"pearson": 0.0017084625581260616, "spearman": 0.001708462558126027, "kendall": 0.0017386933891167472}, "kappa_score": 0.04429901181133156, "total_responses": 1043, "valid_responses": 681, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.11840856336270117, "spearman": 0.11840856336270021, "kendall": 0.11840856336270023}, "p_value": {"pearson": 0.0001266048694678604, "spearman": 0.0001266048694678799, "kendall": 0.000132249519466195}, "kappa_score": 0.042637127423140964, "total_responses": 1043, "valid_responses": 665, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": -0.009807802927043693, "spearman": -0.009807802927043786, "kendall": -0.009807802927043786}, "p_value": {"pearson": 0.7517172902936992, "spearman": 0.7517172902936968, "kendall": 0.7515500790646042}, "kappa_score": -0.001464573723967133, "total_responses": 1043, "valid_responses": 446, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.22495227154570419, "spearman": 0.2249522715457041, "kendall": 0.2249522715457041}, "p_value": {"pearson": 1.9724888583484565e-13, "spearman": 1.9724888583485696e-13, "kendall": 3.8292037435310827e-13}, "kappa_score": 0.1642096197412518, "total_responses": 1043, "valid_responses": 471, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.1695507572151034, "spearman": 0.16955075721510665, "kendall": 0.16955075721510662}, "p_value": {"pearson": 3.606818392229575e-08, "spearman": 3.606818392227514e-08, "kendall": 4.422237906869929e-08}, "kappa_score": 0.095809921335688, "total_responses": 1043, "valid_responses": 876, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.16505599952143468, "spearman": 0.16505599952143638, "kendall": 0.1650559995214364}, "p_value": {"pearson": 8.27688813764458e-08, "spearman": 8.276888137642233e-08, "kendall": 9.929369923050146e-08}, "kappa_score": 0.1197671230529328, "total_responses": 1043, "valid_responses": 342, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.12141196837179952, "spearman": 0.12141196837179874, "kendall": 0.12141196837179875}, "p_value": {"pearson": 8.46250019232893e-05, "spearman": 8.462500192329603e-05, "kendall": 8.885024495097567e-05}, "kappa_score": 0.034416674711150286, "total_responses": 1043, "valid_responses": 888, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.2064971545310298, "spearman": 0.20649715453103065, "kendall": 0.2064971545310307}, "p_value": {"pearson": 1.654747878792288e-11, "spearman": 1.6547478787919556e-11, "kendall": 2.6334716809811076e-11}, "kappa_score": 0.19725981297927575, "total_responses": 1043, "valid_responses": 950, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.09507078711343, "spearman": 0.09507078711342969, "kendall": 0.09507078711342969}, "p_value": {"pearson": 0.0021146298634516494, "spearman": 0.002114629863451703, "kendall": 0.0021485758172355538}, "kappa_score": 0.07061483773917554, "total_responses": 1043, "valid_responses": 945, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.07530635182304903, "spearman": 0.07530635182305026, "kendall": 0.07530635182305026}, "p_value": {"pearson": 0.01499103471961299, "spearman": 0.014991034719611373, "kendall": 0.01506174897720111}, "kappa_score": 0.04867412186107489, "total_responses": 1043, "valid_responses": 794, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.2648108813707054, "spearman": 0.26481088137070774, "kendall": 0.2648108813707077}, "p_value": {"pearson": 3.3873155962474086e-18, "spearman": 3.3873155962453767e-18, "kendall": 1.2512931656804469e-17}, "kappa_score": 0.18817943595464803, "total_responses": 1043, "valid_responses": 913, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.078632686969284, "spearman": 0.07863268696928342, "kendall": 0.07863268696928341}, "p_value": {"pearson": 0.01107346598648878, "spearman": 0.011073465986488994, "kendall": 0.01114035662764328}, "kappa_score": 0.027462603008403308, "total_responses": 1043, "valid_responses": 714, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.11026303134453141, "spearman": 0.11026303134453157, "kendall": 0.11026303134453157}, "p_value": {"pearson": 0.00036024655706717515, "spearman": 0.0003602465570671608, "kendall": 0.00037185394754797786}, "kappa_score": 0.0638079330782435, "total_responses": 1043, "valid_responses": 551, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.08821862025889599, "spearman": 0.08821862025889554, "kendall": 0.08821862025889554}, "p_value": {"pearson": 0.004355326599487286, "spearman": 0.004355326599487533, "kendall": 0.004403651853206926}, "kappa_score": 0.06702085846333172, "total_responses": 1043, "valid_responses": 734, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.12035657255998417, "spearman": 0.12035657255998268, "kendall": 0.12035657255998268}, "p_value": {"pearson": 9.759762531248018e-05, "spearman": 9.75976253125042e-05, "kendall": 0.00010228224220866521}, "kappa_score": 0.10689434435973955, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.21756672372479602, "spearman": 0.21756672372479496, "kendall": 0.21756672372479488}, "p_value": {"pearson": 1.218485332023832e-12, "spearman": 1.2184853320240986e-12, "kendall": 2.1706213130693723e-12}, "kappa_score": 0.21670176265296204, "total_responses": 1043, "valid_responses": 940, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": -0.008953790495844596, "spearman": -0.008953790495844436, "kendall": -0.008953790495844433}, "p_value": {"pearson": 0.7727143230822309, "spearman": 0.7727143230822374, "kendall": 0.772559507464678}, "kappa_score": -0.008083648185572612, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": -0.008587567332159065, "spearman": -0.008587567332159077, "kendall": -0.008587567332159079}, "p_value": {"pearson": 0.7817705747822249, "spearman": 0.7817705747822266, "kendall": 0.7816212522476664}, "kappa_score": -0.0051842743677510406, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": -0.04581732240405648, "spearman": -0.04581732240405705, "kendall": -0.04581732240405705}, "p_value": {"pearson": 0.13922157006328273, "spearman": 0.139221570063275, "kendall": 0.13914451021087915}, "kappa_score": -0.014582916818571823, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.04467666393739757, "spearman": 0.04467666393739758, "kendall": 0.04467666393739758}, "p_value": {"pearson": 0.14934597449730216, "spearman": 0.14934597449730355, "kendall": 0.14925616475594186}, "kappa_score": 0.04080234020091267, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.007251013991027162, "spearman": 0.007251013991027337, "kendall": 0.007251013991027337}, "p_value": {"pearson": 0.8150645793383391, "spearman": 0.8150645793383304, "kendall": 0.814936138664968}, "kappa_score": 0.006092982962749072, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.26000020269939716, "spearman": 0.26000020269939933, "kendall": 0.26000020269939933}, "p_value": {"pearson": 1.4142460236925015e-17, "spearman": 1.414246023691625e-17, "kendall": 4.7464629599985685e-17}, "kappa_score": 0.25178398378997446, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.12963310970371006, "spearman": 0.12963310970371086, "kendall": 0.12963310970371086}, "p_value": {"pearson": 2.6776758298153652e-05, "spearman": 2.677675829815244e-05, "kendall": 2.857189839169592e-05}, "kappa_score": 0.12935176806470383, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": -0.0273868947190466, "spearman": -0.0273868947190464, "kendall": -0.027386894719046397}, "p_value": {"pearson": 0.37692358428046613, "spearman": 0.37692358428047945, "kendall": 0.3766694166119898}, "kappa_score": -0.01721071653949857, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.010662272991991892, "spearman": 0.010662272991991892, "kendall": 0.010662272991991892}, "p_value": {"pearson": 0.7308910978147961, "spearman": 0.7308910978147957, "kendall": 0.7307120980205273}, "kappa_score": 0.009295822749685212, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.04429348705309698, "spearman": 0.04429348705309689, "kendall": 0.04429348705309689}, "p_value": {"pearson": 0.15287004491158898, "spearman": 0.15287004491158926, "kendall": 0.15277590481252223}, "kappa_score": 0.039625549111510394, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": -0.003393480782679568, "spearman": -0.0033934807826795613, "kendall": -0.0033934807826795613}, "p_value": {"pearson": 0.9128351940554456, "spearman": 0.912835194055448, "kendall": 0.9127728935308029}, "kappa_score": -0.003183973997545664, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.24845836135333885, "spearman": 0.24845836135334057, "kendall": 0.24845836135334054}, "p_value": {"pearson": 3.8726092487759663e-16, "spearman": 3.87260924877431e-16, "kendall": 1.0553698116250017e-15}, "kappa_score": 0.2484481755753688, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.21276529517681858, "spearman": 0.21276529517681966, "kendall": 0.21276529517681966}, "p_value": {"pearson": 3.844930900939028e-12, "spearman": 3.844930900938159e-12, "kendall": 6.50767450006045e-12}, "kappa_score": 0.18850728020451268, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.04279108252628354, "spearman": 0.04279108252628339, "kendall": 0.0427910825262834}, "p_value": {"pearson": 0.1672988708326861, "spearman": 0.16729887083268855, "kendall": 0.16718759742034917}, "kappa_score": 0.039903875526953514, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.07010180112481636, "spearman": 0.07010180112481593, "kendall": 0.07010180112481591}, "p_value": {"pearson": 0.023571383417678282, "spearman": 0.023571383417678622, "kendall": 0.02364260185842894}, "kappa_score": 0.04482098207160712, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.05973521651091879, "spearman": 0.05973521651091795, "kendall": 0.05973521651091795}, "p_value": {"pearson": 0.05378198555359697, "spearman": 0.0537819855536003, "kendall": 0.053823506933604645}, "kappa_score": 0.05966004712218109, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.19727999514102573, "spearman": 0.1972799951410256, "kendall": 0.19727999514102562}, "p_value": {"pearson": 1.302488103057194e-10, "spearman": 1.3024881030572336e-10, "kendall": 1.912555164867589e-10}, "kappa_score": 0.18223682251709528, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.05781241964815051, "spearman": 0.05781241964815033, "kendall": 0.05781241964815033}, "p_value": {"pearson": 0.06198487849114229, "spearman": 0.06198487849114635, "kendall": 0.06201529968645458}, "kappa_score": 0.028367941821678566, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.3646432299517186, "spearman": 0.3646432299517203, "kendall": 0.3646432299517204}, "p_value": {"pearson": 3.7732513017910847e-34, "spearman": 3.7732513017885903e-34, "kendall": 5.52689445131329e-32}, "kappa_score": 0.34062766432544356, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.09501100492234169, "spearman": 0.09501100492234178, "kendall": 0.09501100492234178}, "p_value": {"pearson": 0.002128431668698421, "spearman": 0.0021284316686983455, "kendall": 0.0021624953376917903}, "kappa_score": 0.0901532819426395, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.1849315893769642, "spearman": 0.18493158937696508, "kendall": 0.1849315893769651}, "p_value": {"pearson": 1.7738031727443116e-09, "spearman": 1.7738031727440326e-09, "kendall": 2.3784136314972545e-09}, "kappa_score": 0.184354582376832, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.08687536441364277, "spearman": 0.08687536441364095, "kendall": 0.08687536441364094}, "p_value": {"pearson": 0.0049907603983864735, "spearman": 0.0049907603983875976, "kendall": 0.005041987475709923}, "kappa_score": 0.0867562337220521, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.1717788957054398, "spearman": 0.17177889570544158, "kendall": 0.17177889570544158}, "p_value": {"pearson": 2.36975303288365e-08, "spearman": 2.3697530328829186e-08, "kendall": 2.9390879649224886e-08}, "kappa_score": 0.13452495835663925, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.21467737748990331, "spearman": 0.21467737748990243, "kendall": 0.21467737748990248}, "p_value": {"pearson": 2.4409380171976104e-12, "spearman": 2.4409380171982566e-12, "kendall": 4.214626192564435e-12}, "kappa_score": 0.21458652907544284, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.023393008054542336, "spearman": 0.02339300805454224, "kendall": 0.023393008054542246}, "p_value": {"pearson": 0.4504371192578148, "spearman": 0.45043711925780616, "kendall": 0.4501728563572588}, "kappa_score": 0.023386973847527415, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.06153229644893835, "spearman": 0.061532296448938276, "kendall": 0.06153229644893829}, "p_value": {"pearson": 0.046953792184598914, "spearman": 0.046953792184599226, "kendall": 0.0470040117259409}, "kappa_score": 0.03807430407181389, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.1272581700162273, "spearman": 0.12725817001622894, "kendall": 0.12725817001622897}, "p_value": {"pearson": 3.760744105108043e-05, "spearman": 3.760744105107091e-05, "kendall": 3.992782859099823e-05}, "kappa_score": 0.12099458568024601, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": -0.019314135313728664, "spearman": -0.019314135313728786, "kendall": -0.019314135313728786}, "p_value": {"pearson": 0.5332385159518731, "spearman": 0.533238515951873, "kendall": 0.5329817764384727}, "kappa_score": -0.01857894862206133, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.061500977709244876, "spearman": 0.061500977709244425, "kendall": 0.06150097770924444}, "p_value": {"pearson": 0.047066239231351135, "spearman": 0.04706623923135132, "kendall": 0.04711632089051238}, "kappa_score": 0.043612414411640765, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.04510005411100072, "spearman": 0.045100054111000966, "kendall": 0.04510005411100096}, "p_value": {"pearson": 0.14552443184196723, "spearman": 0.1455244318419697, "kendall": 0.14543938130545253}, "kappa_score": 0.041623799388993965, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.026805313253818026, "spearman": 0.026805313253818172, "kendall": 0.026805313253818176}, "p_value": {"pearson": 0.38714385351072345, "spearman": 0.3871438535107202, "kendall": 0.3868872236334665}, "kappa_score": 0.014210272374569621, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.17664245117265226, "spearman": 0.17664245117265406, "kendall": 0.17664245117265404}, "p_value": {"pearson": 9.293911710085656e-09, "spearman": 9.293911710082363e-09, "kendall": 1.1839405578658138e-08}, "kappa_score": 0.12252790718115492, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.36880378129017544, "spearman": 0.3688037812901734, "kendall": 0.3688037812901734}, "p_value": {"pearson": 5.954783700788532e-35, "spearman": 5.954783700793781e-35, "kendall": 1.1146971976428658e-32}, "kappa_score": 0.3631091605752097, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.1466897725665557, "spearman": 0.1466897725665562, "kendall": 0.1466897725665562}, "p_value": {"pearson": 1.9600747897709626e-06, "spearman": 1.960074789770756e-06, "kendall": 2.1889369300154455e-06}, "kappa_score": 0.12618745752741067, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": -0.0172499359918677, "spearman": -0.017249935991867683, "kendall": -0.017249935991867686}, "p_value": {"pearson": 0.5778903740338046, "spearman": 0.5778903740337887, "kendall": 0.5776447044108063}, "kappa_score": -0.01599589848756744, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": -0.01923403833909168, "spearman": -0.019234038339092072, "kendall": -0.019234038339092076}, "p_value": {"pearson": 0.5349381186747705, "spearman": 0.5349381186747482, "kendall": 0.5346817171620402}, "kappa_score": -0.014650898393089529, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.06988269008177954, "spearman": 0.0698826900817789, "kendall": 0.0698826900817789}, "p_value": {"pearson": 0.02401116751848815, "spearman": 0.024011167518490126, "kendall": 0.02408222155879877}, "kappa_score": 0.02578830400566856, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.06732739210293641, "spearman": 0.06732739210293626, "kendall": 0.06732739210293626}, "p_value": {"pearson": 0.029687674958520024, "spearman": 0.029687674958520528, "kendall": 0.029755497729475326}, "kappa_score": 0.06672631982615362, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.014180630335921388, "spearman": 0.014180630335921379, "kendall": 0.01418063033592138}, "p_value": {"pearson": 0.6473515629293226, "spearman": 0.6473515629293234, "kendall": 0.6471312720722813}, "kappa_score": 0.004906637590295859, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": -0.013543629538617229, "spearman": -0.013543629538617062, "kendall": -0.01354362953861706}, "p_value": {"pearson": 0.662188244204505, "spearman": 0.6621882442045107, "kendall": 0.6619745061290443}, "kappa_score": -0.0045264641211639756, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.04958372144885946, "spearman": 0.049583721448859384, "kendall": 0.049583721448859384}, "p_value": {"pearson": 0.10951079651438417, "spearman": 0.10951079651438402, "kendall": 0.10947357495330105}, "kappa_score": 0.015586499180285207, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": -0.013112084052103071, "spearman": -0.013112084052103004, "kendall": -0.013112084052103007}, "p_value": {"pearson": 0.6723158018807347, "spearman": 0.6723158018807378, "kendall": 0.6721067435020902}, "kappa_score": -0.011526413769270993, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": -0.05021445669707932, "spearman": -0.05021445669707917, "kendall": -0.05021445669707916}, "p_value": {"pearson": 0.10506495416004856, "spearman": 0.105064954160049, "kendall": 0.10503395901295062}, "kappa_score": -0.03520148216767005, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.234783793240104, "spearman": 0.23478379324010273, "kendall": 0.23478379324010265}, "p_value": {"pearson": 1.5787213858359716e-14, "spearman": 1.5787213858364522e-14, "kendall": 3.48693995624337e-14}, "kappa_score": 0.21388375339252574, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.02180970272528701, "spearman": 0.021809702725287337, "kendall": 0.021809702725287344}, "p_value": {"pearson": 0.4816853008728281, "spearman": 0.4816853008728236, "kendall": 0.4814217231807425}, "kappa_score": 0.009465320206400896, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": -0.02400988222069498, "spearman": -0.02400988222069495, "kendall": -0.024009882220694955}, "p_value": {"pearson": 0.43858004836388503, "spearman": 0.438580048363873, "kendall": 0.43831626426030335}, "kappa_score": -0.023962653523271316, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": -0.03732097294717984, "spearman": -0.03732097294718047, "kendall": -0.03732097294718047}, "p_value": {"pearson": 0.228483647854703, "spearman": 0.2284836478546964, "kendall": 0.2283106665012471}, "kappa_score": -0.034863829204871966, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.036522653550682536, "spearman": 0.03652265355068334, "kendall": 0.03652265355068334}, "p_value": {"pearson": 0.23859871289338863, "spearman": 0.2385987128933857, "kendall": 0.23841722534831877}, "kappa_score": 0.030551626591230563, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": -0.0483664889550759, "spearman": -0.048366488955075254, "kendall": -0.04836648895507525}, "p_value": {"pearson": 0.11850934875415028, "spearman": 0.1185093487541588, "kendall": 0.1184597140016397}, "kappa_score": -0.043725637824392205, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.02276064029239216, "spearman": 0.022760640292392376, "kendall": 0.022760640292392376}, "p_value": {"pearson": 0.4627779952163694, "spearman": 0.4627779952163532, "kendall": 0.4625136722724452}, "kappa_score": 0.010064527636046261, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.3007625002938986, "spearman": 0.3007625002939011, "kendall": 0.30076250029390106}, "p_value": {"pearson": 3.0062258966587065e-23, "spearman": 3.0062258966558e-23, "kendall": 2.7706012820472795e-22}, "kappa_score": 0.30076039765821905, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.030954178220506313, "spearman": 0.030954178220506983, "kendall": 0.030954178220506976}, "p_value": {"pearson": 0.31792959160881623, "spearman": 0.31792959160881373, "kendall": 0.3176970215368792}, "kappa_score": 0.023450878801550612, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": -0.03823709109348027, "spearman": -0.0382370910934809, "kendall": -0.0382370910934809}, "p_value": {"pearson": 0.21725626276455706, "spearman": 0.21725626276454238, "kendall": 0.21709327847165072}, "kappa_score": -0.026062710291332225, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.02058433098513527, "spearman": 0.020584330985135277, "kendall": 0.020584330985135277}, "p_value": {"pearson": 0.5066553167187348, "spearman": 0.5066553167187344, "kendall": 0.506394205265719}, "kappa_score": 0.011312161798192943, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.17661421349310358, "spearman": 0.17661421349310302, "kendall": 0.17661421349310302}, "p_value": {"pearson": 9.345267292554017e-09, "spearman": 9.34526729255476e-09, "kendall": 1.1902896271951102e-08}, "kappa_score": 0.1766127016744884, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.1588980964741047, "spearman": 0.15889809647410189, "kendall": 0.15889809647410189}, "p_value": {"pearson": 2.491388235573054e-07, "spearman": 2.491388235574265e-07, "kendall": 2.9092277228741835e-07}, "kappa_score": 0.10253091643495638, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.1754201048229429, "spearman": 0.17542010482294362, "kendall": 0.17542010482294362}, "p_value": {"pearson": 1.1788011077977323e-08, "spearman": 1.1788011077975758e-08, "kendall": 1.4912657091447953e-08}, "kappa_score": 0.10562729276729965, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.228824294126649, "spearman": 0.22882429412665412, "kendall": 0.22882429412665412}, "p_value": {"pearson": 7.398131255253013e-14, "spearman": 7.398131255243577e-14, "kendall": 1.5079641500461868e-13}, "kappa_score": 0.18006467351222555, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.08357661822925905, "spearman": 0.08357661822925819, "kendall": 0.08357661822925819}, "p_value": {"pearson": 0.006920641604869877, "spearman": 0.0069206416048705165, "kendall": 0.006978776638202003}, "kappa_score": 0.07555729221268115, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.2284863188882026, "spearman": 0.2284863188882019, "kendall": 0.22848631888820192}, "p_value": {"pearson": 8.065066456021289e-14, "spearman": 8.065066456022711e-14, "kendall": 1.63675286579733e-13}, "kappa_score": 0.15739701208827095, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.1084500865028698, "spearman": 0.10845008650286984, "kendall": 0.10845008650286984}, "p_value": {"pearson": 0.00045046505642792835, "spearman": 0.0004504650564279192, "kendall": 0.0004639134599135904}, "kappa_score": 0.030907189820476133, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "OLMo-7B-Instruct (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.010971053305863307, "spearman": 0.010971053305863216, "kendall": 0.010971053305863215}, "p_value": {"pearson": 0.7234126666943508, "spearman": 0.723412666694355, "kendall": 0.7232295655126106}, "kappa_score": 0.002358796991133838, "total_responses": 1043, "valid_responses": 959, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": -0.013598678240741645, "spearman": -0.01359867824074171, "kendall": -0.01359867824074171}, "p_value": {"pearson": 0.6609007323354127, "spearman": 0.660900732335409, "kendall": 0.6606864111708419}, "kappa_score": -0.005886630970951545, "total_responses": 1043, "valid_responses": 949, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.023073972782276256, "spearman": 0.023073972782276526, "kendall": 0.023073972782276523}, "p_value": {"pearson": 0.45663980400538473, "spearman": 0.4566398040053786, "kendall": 0.4563754558607225}, "kappa_score": 0.007217603537890915, "total_responses": 1043, "valid_responses": 981, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.035942135067669495, "spearman": 0.03594213506766914, "kendall": 0.03594213506766915}, "p_value": {"pearson": 0.24614962310219382, "spearman": 0.24614962310219882, "kendall": 0.24596209103165423}, "kappa_score": 0.004976428910150821, "total_responses": 1043, "valid_responses": 930, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": -0.03578707724636197, "spearman": -0.03578707724636211, "kendall": -0.03578707724636212}, "p_value": {"pearson": 0.24819449022781326, "spearman": 0.24819449022780404, "kendall": 0.24800536573165666}, "kappa_score": -0.00951888858970551, "total_responses": 1043, "valid_responses": 1015, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.04082541257596805, "spearman": 0.04082541257596832, "kendall": 0.04082541257596831}, "p_value": {"pearson": 0.18768924363122746, "spearman": 0.18768924363122355, "kendall": 0.18755542998972707}, "kappa_score": 0.016663852996558814, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.03447621679743093, "spearman": 0.03447621679743039, "kendall": 0.03447621679743039}, "p_value": {"pearson": 0.26595649979860253, "spearman": 0.2659564997986092, "kendall": 0.26575432980328617}, "kappa_score": 0.005335759133491602, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.015660116860845435, "spearman": 0.015660116860845546, "kendall": 0.015660116860845542}, "p_value": {"pearson": 0.6134352356910878, "spearman": 0.6134352356910855, "kendall": 0.6132014066138194}, "kappa_score": 0.0037858395707066617, "total_responses": 1043, "valid_responses": 969, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.0946311015298247, "spearman": 0.09463110152982443, "kendall": 0.0946311015298244}, "p_value": {"pearson": 0.0022180841859121016, "spearman": 0.0022180841859121775, "kendall": 0.0022529002806763875}, "kappa_score": 0.039761959750823195, "total_responses": 1043, "valid_responses": 934, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.03474883665043563, "spearman": 0.0347488366504354, "kendall": 0.0347488366504354}, "p_value": {"pearson": 0.2621923849235376, "spearman": 0.26219238492354835, "kendall": 0.2619928627479803}, "kappa_score": 0.007587067776144152, "total_responses": 1043, "valid_responses": 1013, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.022524558726730957, "spearman": 0.022524558726731196, "kendall": 0.022524558726731193}, "p_value": {"pearson": 0.46743302646918067, "spearman": 0.46743302646918694, "kendall": 0.46716879430201497}, "kappa_score": 0.004282617035893721, "total_responses": 1043, "valid_responses": 975, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.08375223918804439, "spearman": 0.08375223918804411, "kendall": 0.08375223918804411}, "p_value": {"pearson": 0.0068030610271090815, "spearman": 0.0068030610271094015, "kendall": 0.006860841955962457}, "kappa_score": 0.023084608968483078, "total_responses": 1043, "valid_responses": 1008, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": -0.030231489789443525, "spearman": -0.030231489789443827, "kendall": -0.03023148978944382}, "p_value": {"pearson": 0.329365067090727, "spearman": 0.32936506709071345, "kendall": 0.3291272848003911}, "kappa_score": -0.005219922380336195, "total_responses": 1043, "valid_responses": 1015, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.0925049361884938, "spearman": 0.09250493618849503, "kendall": 0.09250493618849502}, "p_value": {"pearson": 0.0027868032175610274, "spearman": 0.002786803217560713, "kendall": 0.002825956812997857}, "kappa_score": 0.019045100156068084, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.03478427078146728, "spearman": 0.034784270781467834, "kendall": 0.034784270781467834}, "p_value": {"pearson": 0.2617058512008512, "spearman": 0.26170585120085005, "kendall": 0.26150667582034626}, "kappa_score": 0.008058086135709353, "total_responses": 1043, "valid_responses": 952, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.09842867823371436, "spearman": 0.09842867823371505, "kendall": 0.09842867823371504}, "p_value": {"pearson": 0.0014589668589581972, "spearman": 0.0014589668589580621, "kendall": 0.0014866334346465262}, "kappa_score": 0.05909785921470678, "total_responses": 1043, "valid_responses": 991, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.008936445743800536, "spearman": 0.00893644574380036, "kendall": 0.008936445743800361}, "p_value": {"pearson": 0.7731425518142572, "spearman": 0.773142551814262, "kendall": 0.7729879940126894}, "kappa_score": 0.0016731263670900498, "total_responses": 1043, "valid_responses": 1008, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.02428184264924571, "spearman": 0.024281842649245614, "kendall": 0.024281842649245617}, "p_value": {"pearson": 0.43341007027733747, "spearman": 0.43341007027734146, "kendall": 0.43314662723020003}, "kappa_score": 0.004627217846964626, "total_responses": 1043, "valid_responses": 1002, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.08784225125770434, "spearman": 0.0878422512577036, "kendall": 0.08784225125770362}, "p_value": {"pearson": 0.004525544597935801, "spearman": 0.004525544597936027, "kendall": 0.0045746846782309045}, "kappa_score": 0.044470311809530094, "total_responses": 1043, "valid_responses": 978, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.08912787672793787, "spearman": 0.08912787672793734, "kendall": 0.08912787672793734}, "p_value": {"pearson": 0.003967762706426344, "spearman": 0.003967762706426664, "kendall": 0.004014118970583017}, "kappa_score": 0.025398797574612497, "total_responses": 1043, "valid_responses": 974, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.10828510164823779, "spearman": 0.10828510164823717, "kendall": 0.10828510164823717}, "p_value": {"pearson": 0.0004596441853629945, "spearman": 0.0004596441853630307, "kendall": 0.00047327062388850935}, "kappa_score": 0.034215925824702675, "total_responses": 1043, "valid_responses": 1001, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.03020772991643238, "spearman": 0.03020772991643227, "kendall": 0.030207729916432273}, "p_value": {"pearson": 0.3297454955433927, "spearman": 0.32974549554338406, "kendall": 0.32950754862082454}, "kappa_score": 0.005045927000241868, "total_responses": 1043, "valid_responses": 1014, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": -0.03192054790006703, "spearman": -0.031920547900067216, "kendall": -0.03192054790006722}, "p_value": {"pearson": 0.3030491237812411, "spearman": 0.3030491237812315, "kendall": 0.30282411391193165}, "kappa_score": -0.013605442176870763, "total_responses": 1043, "valid_responses": 440, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.00793221153320668, "spearman": 0.007932211533206425, "kendall": 0.007932211533206423}, "p_value": {"pearson": 0.7980499383084989, "spearman": 0.7980499383085066, "kendall": 0.7979106967730243}, "kappa_score": 0.001950565009069205, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.043315877869564826, "spearman": 0.04331587786956475, "kendall": 0.04331587786956475}, "p_value": {"pearson": 0.16214699294522678, "spearman": 0.16214699294522178, "kendall": 0.1620417258446598}, "kappa_score": 0.011606258285911109, "total_responses": 1043, "valid_responses": 1015, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.044438907668164995, "spearman": 0.044438907668165065, "kendall": 0.04443890766816507}, "p_value": {"pearson": 0.15152524855648136, "spearman": 0.15152524855647645, "kendall": 0.15143275427952374}, "kappa_score": 0.010866366120856785, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": -0.013243555995741426, "spearman": -0.013243555995741474, "kendall": -0.013243555995741476}, "p_value": {"pearson": 0.6692240031584584, "spearman": 0.6692240031584566, "kendall": 0.669013498775433}, "kappa_score": -0.001884168705922784, "total_responses": 1043, "valid_responses": 809, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.0231320404588141, "spearman": 0.023132040458813945, "kendall": 0.023132040458813945}, "p_value": {"pearson": 0.45550729643414767, "spearman": 0.45550729643416243, "kendall": 0.45524295549981086}, "kappa_score": 0.0021683631108297963, "total_responses": 1043, "valid_responses": 972, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": -0.028655450343062872, "spearman": -0.028655450343062678, "kendall": -0.02865545034306268}, "p_value": {"pearson": 0.3552143294358509, "spearman": 0.35521432943585274, "kendall": 0.35496661110593697}, "kappa_score": -0.00865900170354883, "total_responses": 1043, "valid_responses": 899, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.02349288904284238, "spearman": 0.023492889042842316, "kendall": 0.023492889042842316}, "p_value": {"pearson": 0.44850507262309813, "spearman": 0.44850507262308437, "kendall": 0.4482408592707481}, "kappa_score": 0.0033901256653319223, "total_responses": 1043, "valid_responses": 975, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": -0.009947819134466561, "spearman": -0.009947819134466664, "kendall": -0.009947819134466665}, "p_value": {"pearson": 0.7482917867413362, "spearman": 0.7482917867413336, "kendall": 0.7481226006710904}, "kappa_score": -0.0008175865690260853, "total_responses": 1043, "valid_responses": 995, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.030058697425484004, "spearman": 0.030058697425484095, "kendall": 0.030058697425484088}, "p_value": {"pearson": 0.33213819033235437, "spearman": 0.3321381903323525, "kendall": 0.3318992207689362}, "kappa_score": 0.004502518311793935, "total_responses": 1043, "valid_responses": 948, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.027607610958270724, "spearman": 0.027607610958270613, "kendall": 0.027607610958270613}, "p_value": {"pearson": 0.3730887844816391, "spearman": 0.3730887844816535, "kendall": 0.3728356342111139}, "kappa_score": 0.005735061731567348, "total_responses": 1043, "valid_responses": 956, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.18039287283022126, "spearman": 0.1803928728302231, "kendall": 0.18039287283022312}, "p_value": {"pearson": 4.435099308529171e-09, "spearman": 4.435099308527433e-09, "kendall": 5.7770667785179805e-09}, "kappa_score": 0.11987326455228642, "total_responses": 1043, "valid_responses": 1001, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.07921037385122896, "spearman": 0.07921037385122871, "kendall": 0.07921037385122871}, "p_value": {"pearson": 0.010494543873166099, "spearman": 0.010494543873165878, "kendall": 0.010560567739839068}, "kappa_score": 0.048772187738212014, "total_responses": 1043, "valid_responses": 1020, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": -0.06985452704246423, "spearman": -0.06985452704246506, "kendall": -0.06985452704246506}, "p_value": {"pearson": 0.024068206483595082, "spearman": 0.024068206483594295, "kendall": 0.02413923816441301}, "kappa_score": -0.049315031925134756, "total_responses": 1043, "valid_responses": 1017, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.009816384898188084, "spearman": 0.009816384898187975, "kendall": 0.009816384898187975}, "p_value": {"pearson": 0.7515071905804812, "spearman": 0.751507190580482, "kendall": 0.7513398578318626}, "kappa_score": 0.001643985096449363, "total_responses": 1043, "valid_responses": 1009, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": -0.005883370913485234, "spearman": -0.005883370913485066, "kendall": -0.005883370913485065}, "p_value": {"pearson": 0.8494813189622905, "spearman": 0.8494813189622998, "kendall": 0.8493754568438036}, "kappa_score": -0.0013656538067599033, "total_responses": 1043, "valid_responses": 890, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.025137702417501517, "spearman": 0.02513770241750152, "kendall": 0.025137702417501524}, "p_value": {"pearson": 0.417371648771003, "spearman": 0.41737164877100197, "kendall": 0.41710978858051406}, "kappa_score": 0.003146642356158802, "total_responses": 1043, "valid_responses": 926, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.07154691847516684, "spearman": 0.07154691847516723, "kendall": 0.07154691847516723}, "p_value": {"pearson": 0.020841946379630955, "spearman": 0.020841946379630966, "kendall": 0.02091383967734275}, "kappa_score": 0.010185782457894144, "total_responses": 1043, "valid_responses": 959, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.043454775008986396, "spearman": 0.0434547750089864, "kendall": 0.0434547750089864}, "p_value": {"pearson": 0.160803669280984, "spearman": 0.16080366928099343, "kendall": 0.1606999887052163}, "kappa_score": 0.005319047930508525, "total_responses": 1043, "valid_responses": 974, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": -0.0016181738209457078, "spearman": -0.0016181738209458368, "kendall": -0.0016181738209458368}, "p_value": {"pearson": 0.9583716295134131, "spearman": 0.9583716295134133, "kendall": 0.95834169119756}, "kappa_score": -0.00039207998431667335, "total_responses": 1043, "valid_responses": 890, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.004066786783973479, "spearman": 0.004066786783973549, "kendall": 0.004066786783973549}, "p_value": {"pearson": 0.8956313303154543, "spearman": 0.8956313303154501, "kendall": 0.8955569939618325}, "kappa_score": 0.0009699981280738568, "total_responses": 1043, "valid_responses": 991, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": -0.017239462283860738, "spearman": -0.017239462283860474, "kendall": -0.017239462283860474}, "p_value": {"pearson": 0.5781213453289524, "spearman": 0.5781213453289751, "kendall": 0.5778757443461954}, "kappa_score": -0.0032068918460870233, "total_responses": 1043, "valid_responses": 994, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.002190370621671824, "spearman": 0.0021903706216718113, "kendall": 0.002190370621671811}, "p_value": {"pearson": 0.9436728160171293, "spearman": 0.9436728160171306, "kendall": 0.9436323679087825}, "kappa_score": 0.0003090360514952373, "total_responses": 1043, "valid_responses": 1016, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.059813985719063836, "spearman": 0.059813985719063795, "kendall": 0.05981398571906379}, "p_value": {"pearson": 0.053466232347304174, "spearman": 0.05346623234730273, "kendall": 0.053508168762495464}, "kappa_score": 0.022770192278384283, "total_responses": 1043, "valid_responses": 1010, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.02545527491742323, "spearman": 0.025455274917423568, "kendall": 0.025455274917423564}, "p_value": {"pearson": 0.4115105004142804, "spearman": 0.41151050041427517, "kendall": 0.4112494209898059}, "kappa_score": 0.006846694456191127, "total_responses": 1043, "valid_responses": 995, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.0265084655027561, "spearman": 0.02650846550275618, "kendall": 0.026508465502756186}, "p_value": {"pearson": 0.39242486439983804, "spearman": 0.3924248643998375, "kendall": 0.39216710226348417}, "kappa_score": 0.003311007148568468, "total_responses": 1043, "valid_responses": 1006, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": -0.061399050864467966, "spearman": -0.061399050864468625, "kendall": -0.06139905086446862}, "p_value": {"pearson": 0.04743376536275571, "spearman": 0.0474337653627519, "kendall": 0.04748339494565205}, "kappa_score": -0.01224467410328911, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": -0.018743667679837428, "spearman": -0.018743667679837893, "kendall": -0.018743667679837893}, "p_value": {"pearson": 0.545402565465407, "spearman": 0.5454025654653966, "kendall": 0.5451483946483535}, "kappa_score": -0.0021201160333774727, "total_responses": 1043, "valid_responses": 1008, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.009632971488566608, "spearman": 0.009632971488566606, "kendall": 0.009632971488566608}, "p_value": {"pearson": 0.756001410013307, "spearman": 0.7560014100133092, "kendall": 0.7558366878007767}, "kappa_score": 0.0014012779743675097, "total_responses": 1043, "valid_responses": 922, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.018728455555030624, "spearman": 0.01872845555503084, "kendall": 0.01872845555503084}, "p_value": {"pearson": 0.5457288052078473, "spearman": 0.5457288052078426, "kendall": 0.5454747080270954}, "kappa_score": 0.0016881550452764182, "total_responses": 1043, "valid_responses": 849, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": -0.007470635799347864, "spearman": -0.0074706357993478585, "kendall": -0.007470635799347857}, "p_value": {"pearson": 0.8095690296671947, "spearman": 0.8095690296671965, "kendall": 0.8094370722811358}, "kappa_score": -0.003196422546950961, "total_responses": 1043, "valid_responses": 934, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": -0.04075618931491233, "spearman": -0.04075618931491284, "kendall": -0.04075618931491283}, "p_value": {"pearson": 0.18843931145867385, "spearman": 0.1884393114586753, "kendall": 0.18830470640453112}, "kappa_score": -0.00895235094594149, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": -0.07708241529367536, "spearman": -0.0770824152936768, "kendall": -0.07708241529367679}, "p_value": {"pearson": 0.012769405495636219, "spearman": 0.012769405495634926, "kendall": 0.012838346550470258}, "kappa_score": -0.029069646677606364, "total_responses": 1043, "valid_responses": 986, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": -0.03830444386438008, "spearman": -0.03830444386438026, "kendall": -0.03830444386438027}, "p_value": {"pearson": 0.21644674648462764, "spearman": 0.21644674648463208, "kendall": 0.21628450578274072}, "kappa_score": -0.0037392142955550156, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": -0.010032078777859447, "spearman": -0.010032078777859414, "kendall": -0.010032078777859416}, "p_value": {"pearson": 0.746232754084643, "spearman": 0.7462327540846407, "kendall": 0.7460623876064285}, "kappa_score": -0.006156505195179518, "total_responses": 1043, "valid_responses": 838, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.0054063866794608235, "spearman": 0.005406386679460732, "kendall": 0.0054063866794607325}, "p_value": {"pearson": 0.8615558904323409, "spearman": 0.8615558904323466, "kendall": 0.8614581532680237}, "kappa_score": 0.0010479614144042193, "total_responses": 1043, "valid_responses": 914, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": -0.033468733777628996, "spearman": -0.03346873377762956, "kendall": -0.03346873377762955}, "p_value": {"pearson": 0.28018838088049314, "spearman": 0.2801883808804762, "kendall": 0.2799767569754471}, "kappa_score": -0.007143496129619509, "total_responses": 1043, "valid_responses": 972, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.04009269079093293, "spearman": 0.04009269079093315, "kendall": 0.040092690790933146}, "p_value": {"pearson": 0.1957409149571879, "spearman": 0.19574091495718016, "kendall": 0.1955987460022226}, "kappa_score": 0.008507669896936854, "total_responses": 1043, "valid_responses": 997, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.033248877637652205, "spearman": 0.03324887763765193, "kendall": 0.033248877637651934}, "p_value": {"pearson": 0.2833615437650545, "spearman": 0.2833615437650603, "kendall": 0.2831479306706677}, "kappa_score": 0.0035446965370008465, "total_responses": 1043, "valid_responses": 996, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": -0.020361519027503425, "spearman": -0.020361519027503227, "kendall": -0.02036151902750323}, "p_value": {"pearson": 0.5112675837174769, "spearman": 0.5112675837174671, "kendall": 0.5110071049540419}, "kappa_score": -0.004230543021874755, "total_responses": 1043, "valid_responses": 985, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": -0.03459725444848042, "spearman": -0.03459725444848044, "kendall": -0.03459725444848044}, "p_value": {"pearson": 0.26428074895455755, "spearman": 0.2642807489545507, "kendall": 0.2640797500589157}, "kappa_score": -0.008218310348359736, "total_responses": 1043, "valid_responses": 928, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Meta-Llama-3-70B-Instruct (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.24493862419764686, "spearman": 0.24493862419764403, "kendall": 0.24493862419764403}, "p_value": {"pearson": 1.0280738738917544e-15, "spearman": 1.028073873892554e-15, "kendall": 2.6446103665065868e-15}, "kappa_score": 0.20187780010986123, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.48799006906883197, "spearman": 0.48799006906882814, "kendall": 0.48799006906882814}, "p_value": {"pearson": 1.663770884751034e-63, "spearman": 1.6637708847551778e-63, "kendall": 6.619507850863528e-56}, "kappa_score": 0.47173328459911756, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.12473624805446927, "spearman": 0.1247362480544705, "kendall": 0.1247362480544705}, "p_value": {"pearson": 5.35936643413743e-05, "spearman": 5.3593664341364784e-05, "kendall": 5.661584375600284e-05}, "kappa_score": 0.03978830105178044, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.17742051548267562, "spearman": 0.1774205154826738, "kendall": 0.17742051548267382}, "p_value": {"pearson": 7.981863522089929e-09, "spearman": 7.98186352209279e-09, "kendall": 1.0213869767404842e-08}, "kappa_score": 0.08645473749291577, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.12009977645845718, "spearman": 0.12009977645845879, "kendall": 0.12009977645845879}, "p_value": {"pearson": 0.00010102633293968792, "spearman": 0.00010102633293967197, "kendall": 0.00010582895728100333}, "kappa_score": 0.04315177873670628, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.4391975126924331, "spearman": 0.43919751269243507, "kendall": 0.43919751269243507}, "p_value": {"pearson": 2.022845107649942e-50, "spearman": 2.0228451076475391e-50, "kendall": 1.2661354762515601e-45}, "kappa_score": 0.3682036366817193, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.22003838236646583, "spearman": 0.22003838236646656, "kendall": 0.22003838236646658}, "p_value": {"pearson": 6.672703012793516e-13, "spearman": 6.672703012792518e-13, "kendall": 1.2221494971896348e-12}, "kappa_score": 0.09569907089350738, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.5311317497559818, "spearman": 0.5311317497559919, "kendall": 0.531131749755992}, "p_value": {"pearson": 5.595616969645411e-77, "spearman": 5.595616969602075e-77, "kendall": 6.856248384209396e-66}, "kappa_score": 0.46329944769070674, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.45077138626402924, "spearman": 0.4507713862640254, "kendall": 0.45077138626402535}, "p_value": {"pearson": 2.4621996567424963e-53, "spearman": 2.46219965674829e-53, "kendall": 5.762998606075034e-48}, "kappa_score": 0.3762058627064142, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.19908654737915746, "spearman": 0.19908654737915837, "kendall": 0.19908654737915835}, "p_value": {"pearson": 8.76004569849227e-11, "spearman": 8.760045698490411e-11, "kendall": 1.3055938173474565e-10}, "kappa_score": 0.10126573112626891, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.39710406238061446, "spearman": 0.39710406238061274, "kendall": 0.3971040623806127}, "p_value": {"pearson": 9.993646186573374e-41, "spearman": 9.993646186582034e-41, "kendall": 1.291270853125127e-37}, "kappa_score": 0.3062093993524946, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.42806538792116755, "spearman": 0.4280653879211701, "kendall": 0.42806538792117005}, "p_value": {"pearson": 1.011432496306894e-47, "spearman": 1.0114324963055405e-47, "kendall": 1.9861541762752077e-43}, "kappa_score": 0.3391480504871829, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.23251531342955883, "spearman": 0.23251531342956017, "kendall": 0.2325153134295602}, "p_value": {"pearson": 2.856596684549047e-14, "spearman": 2.856596684547927e-14, "kendall": 6.114783293176117e-14}, "kappa_score": 0.11644482017926006, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.7645144266661447, "spearman": 0.7645144266661519, "kendall": 0.7645144266661518}, "p_value": {"pearson": 9.666606493061704e-201, "spearman": 9.666606492930683e-201, "kendall": 1.8180397174315993e-134}, "kappa_score": 0.7447149240893165, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.6947755760605787, "spearman": 0.6947755760605814, "kendall": 0.6947755760605815}, "p_value": {"pearson": 3.532285452144692e-151, "spearman": 3.532285452131267e-151, "kendall": 2.1283940994798165e-111}, "kappa_score": 0.6799070542329781, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.31468894602135766, "spearman": 0.3146889460213562, "kendall": 0.3146889460213563}, "p_value": {"pearson": 2.081920780235657e-25, "spearman": 2.081920780236709e-25, "kendall": 3.0475194700913046e-24}, "kappa_score": 0.20612644777907851, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.1612317127098969, "spearman": 0.16123171270989645, "kendall": 0.16123171270989645}, "p_value": {"pearson": 1.6489252394462891e-07, "spearman": 1.6489252394465086e-07, "kendall": 1.9445293501104788e-07}, "kappa_score": 0.07493172682547644, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.23432423691418297, "spearman": 0.23432423691418186, "kendall": 0.23432423691418194}, "p_value": {"pearson": 1.7811410507306257e-14, "spearman": 1.7811410507310873e-14, "kendall": 3.908832610111887e-14}, "kappa_score": 0.12737920937042446, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.677715021472785, "spearman": 0.6777150214727777, "kendall": 0.6777150214727776}, "p_value": {"pearson": 3.684233593498691e-141, "spearman": 3.684233593533468e-141, "kendall": 4.3347060446046604e-106}, "kappa_score": 0.6774050125167937, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.47356754363722986, "spearman": 0.47356754363722403, "kendall": 0.47356754363722414}, "p_value": {"pearson": 2.05004122134191e-59, "spearman": 2.0500412213497943e-59, "kendall": 9.367970703724957e-53}, "kappa_score": 0.4488081662170055, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.6531948395783427, "spearman": 0.6531948395783469, "kendall": 0.653194839578347}, "p_value": {"pearson": 6.756201355801195e-128, "spearman": 6.756201355767277e-128, "kendall": 1.088781833834226e-98}, "kappa_score": 0.6426858513189448, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.3087901731292686, "spearman": 0.30879017312926765, "kendall": 0.30879017312926765}, "p_value": {"pearson": 1.76760616734502e-24, "spearman": 1.7676061673456504e-24, "kendall": 2.10944073643182e-23}, "kappa_score": 0.23566479861506917, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.7588802193009005, "spearman": 0.7588802193009174, "kendall": 0.7588802193009173}, "p_value": {"pearson": 4.0766186895230405e-196, "spearman": 4.076618689395123e-196, "kendall": 1.6028247555899778e-132}, "kappa_score": 0.7587495329430813, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.6588505488754397, "spearman": 0.6588505488754376, "kendall": 0.6588505488754377}, "p_value": {"pearson": 7.606167617574392e-131, "spearman": 7.606167617594275e-131, "kendall": 2.260398885060347e-100}, "kappa_score": 0.6557026511698947, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.5209366914391492, "spearman": 0.5209366914391571, "kendall": 0.5209366914391571}, "p_value": {"pearson": 1.2840170933385793e-73, "spearman": 1.2840170933311167e-73, "kendall": 1.8679619461196954e-63}, "kappa_score": 0.4539101270241148, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.49577003773966816, "spearman": 0.49577003773966216, "kendall": 0.49577003773966216}, "p_value": {"pearson": 8.549033786413957e-66, "spearman": 8.549033786448794e-66, "kendall": 1.2084935406124059e-57}, "kappa_score": 0.41093330965278385, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.2582743612258539, "spearman": 0.2582743612258507, "kendall": 0.25827436122585073}, "p_value": {"pearson": 2.3447034358312022e-17, "spearman": 2.3447034358332785e-17, "kendall": 7.613288208101786e-17}, "kappa_score": 0.14610184557086392, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.23451201602972727, "spearman": 0.23451201602972882, "kendall": 0.2345120160297288}, "p_value": {"pearson": 1.6955224747847054e-14, "spearman": 1.695522474784114e-14, "kendall": 3.7307000957735715e-14}, "kappa_score": 0.1212757809508177, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.44790754157272983, "spearman": 0.44790754157273366, "kendall": 0.44790754157273366}, "p_value": {"pearson": 1.3274864850408143e-52, "spearman": 1.327486485037747e-52, "kendall": 2.2168178543398773e-47}, "kappa_score": 0.39775739927854314, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.11396884989482231, "spearman": 0.11396884989482277, "kendall": 0.11396884989482274}, "p_value": {"pearson": 0.00022576451802302014, "spearman": 0.00022576451802300824, "kendall": 0.00023422619915765554}, "kappa_score": 0.0534986692327839, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.25181868891989234, "spearman": 0.2518186889198925, "kendall": 0.25181868891989256}, "p_value": {"pearson": 1.5030006945780188e-16, "spearman": 1.5030006945779555e-16, "kendall": 4.338703440761492e-16}, "kappa_score": 0.14508966772052134, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.20181096354638905, "spearman": 0.20181096354639216, "kendall": 0.20181096354639216}, "p_value": {"pearson": 4.782190296661998e-11, "spearman": 4.7821902966588394e-11, "kendall": 7.295020637506383e-11}, "kappa_score": 0.08526582603652189, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.3518586135247025, "spearman": 0.35185861352470266, "kendall": 0.35185861352470277}, "p_value": {"pearson": 9.282774993860411e-32, "spearman": 9.282774993860866e-32, "kendall": 6.767255757505541e-30}, "kappa_score": 0.2656776464671864, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.6416820123676051, "spearman": 0.6416820123676121, "kendall": 0.6416820123676122}, "p_value": {"pearson": 4.364701686963732e-122, "spearman": 4.364701686928383e-122, "kendall": 2.616701532413912e-95}, "kappa_score": 0.5833244014849603, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.9201314089540382, "spearman": 0.9201314089540403, "kendall": 0.9201314089540403}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 7.264457705577878e-194}, "kappa_score": 0.9199271072824027, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.4620865895911541, "spearman": 0.462086589591159, "kendall": 0.462086589591159}, "p_value": {"pearson": 2.6986794895984445e-56, "spearman": 2.6986794895901993e-56, "kendall": 2.5871582177343116e-50}, "kappa_score": 0.3845313422022797, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.22053178830736797, "spearman": 0.2205317883073699, "kendall": 0.22053178830736986}, "p_value": {"pearson": 5.911795550510548e-13, "spearman": 5.911795550508279e-13, "kendall": 1.0889319016791275e-12}, "kappa_score": 0.10814413582554916, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.2864156703888527, "spearman": 0.2864156703888544, "kendall": 0.28641567038885446}, "p_value": {"pearson": 3.8267636641747494e-21, "spearman": 3.8267636641724526e-21, "kendall": 2.3413259433735602e-20}, "kappa_score": 0.19766810461854045, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.1609163858627487, "spearman": 0.16091638586274734, "kendall": 0.1609163858627473}, "p_value": {"pearson": 1.7441009051251247e-07, "spearman": 1.7441009051255456e-07, "kendall": 2.0539777511929022e-07}, "kappa_score": 0.05938181076409377, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.22231291042772391, "spearman": 0.22231291042772536, "kendall": 0.22231291042772533}, "p_value": {"pearson": 3.8094243034009555e-13, "spearman": 3.8094243033998554e-13, "kendall": 7.164096986794558e-13}, "kappa_score": 0.09922499058492396, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.17007948738320683, "spearman": 0.17007948738320877, "kendall": 0.17007948738320877}, "p_value": {"pearson": 3.266272133744893e-08, "spearman": 3.2662721337438405e-08, "kendall": 4.015469127372506e-08}, "kappa_score": 0.06976784855506502, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.12715037542786445, "spearman": 0.1271503754278636, "kendall": 0.12715037542786362}, "p_value": {"pearson": 3.8186373257553145e-05, "spearman": 3.8186373257557556e-05, "kendall": 4.0533528721286004e-05}, "kappa_score": 0.04399307614199344, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.11019956287242594, "spearman": 0.11019956287242545, "kendall": 0.11019956287242547}, "p_value": {"pearson": 0.00036309680290371566, "spearman": 0.00036309680290375166, "kendall": 0.00037476514191128957}, "kappa_score": 0.028300725975144547, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.1440744144084337, "spearman": 0.14407441440843358, "kendall": 0.1440744144084336}, "p_value": {"pearson": 2.986135451685684e-06, "spearman": 2.9861354516857478e-06, "kendall": 3.3076908113411293e-06}, "kappa_score": 0.047600561003682706, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.12732944260688692, "spearman": 0.1273294426068877, "kendall": 0.12732944260688767}, "p_value": {"pearson": 3.722923735821674e-05, "spearman": 3.722923735821167e-05, "kendall": 3.95320743823885e-05}, "kappa_score": 0.031908252213924015, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.37922048631954663, "spearman": 0.37922048631954486, "kendall": 0.3792204863195448}, "p_value": {"pearson": 5.188224857355956e-37, "spearman": 5.188224857359778e-37, "kendall": 1.8713587118187088e-34}, "kappa_score": 0.28180029940753026, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.22930231657835076, "spearman": 0.22930231657835443, "kendall": 0.22930231657835445}, "p_value": {"pearson": 6.546379143296613e-14, "spearman": 6.546379143290712e-14, "kendall": 1.342653003212268e-13}, "kappa_score": 0.15664822134387346, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.13596558323547508, "spearman": 0.1359655832354751, "kendall": 0.13596558323547508}, "p_value": {"pearson": 1.0515646052377259e-05, "spearman": 1.05156460523775e-05, "kendall": 1.1388752223454304e-05}, "kappa_score": 0.048818081785914624, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.1708750720784321, "spearman": 0.17087507207843416, "kendall": 0.17087507207843416}, "p_value": {"pearson": 2.811826103325331e-08, "spearman": 2.8118261033242885e-08, "kendall": 3.470951351792443e-08}, "kappa_score": 0.0691564019799411, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.18711005045817647, "spearman": 0.187110050458178, "kendall": 0.18711005045817802}, "p_value": {"pearson": 1.133166144288041e-09, "spearman": 1.1331661442877363e-09, "kendall": 1.5419346007861494e-09}, "kappa_score": 0.06765183949686082, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.21703422198933936, "spearman": 0.21703422198933695, "kendall": 0.21703422198933697}, "p_value": {"pearson": 1.3859626451716858e-12, "spearman": 1.3859626451724827e-12, "kendall": 2.454556343536652e-12}, "kappa_score": 0.08996978352513285, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.18636779529702635, "spearman": 0.18636779529702657, "kendall": 0.18636779529702655}, "p_value": {"pearson": 1.3208831336463474e-09, "spearman": 1.3208831336462967e-09, "kendall": 1.7882698393907786e-09}, "kappa_score": 0.06713414306924481, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.8009085552585862, "spearman": 0.8009085552585881, "kendall": 0.8009085552585877}, "p_value": {"pearson": 4.2616916510515984e-234, "spearman": 4.2616916510327965e-234, "kendall": 2.2310780703667713e-147}, "kappa_score": 0.787905332478218, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.3132043513071985, "spearman": 0.31320435130720164, "kendall": 0.31320435130720164}, "p_value": {"pearson": 3.582910626492194e-25, "spearman": 3.582910626488049e-25, "kendall": 4.976007855749844e-24}, "kappa_score": 0.1786672192782498, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.5030328559740513, "spearman": 0.5030328559740572, "kendall": 0.5030328559740572}, "p_value": {"pearson": 5.507319775196094e-68, "spearman": 5.5073197751732475e-68, "kendall": 2.7202200119550265e-59}, "kappa_score": 0.4779598334387666, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.40837962214262236, "spearman": 0.4083796221426215, "kendall": 0.40837962214262163}, "p_value": {"pearson": 3.4439545677614797e-43, "spearman": 3.4439545677630544e-43, "kendall": 1.106556236911724e-39}, "kappa_score": 0.29395133994345546, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.5266972886994394, "spearman": 0.5266972886994453, "kendall": 0.5266972886994452}, "p_value": {"pearson": 1.6738602863655873e-75, "spearman": 1.6738602863581878e-75, "kendall": 7.963452636625332e-65}, "kappa_score": 0.5265278329455825, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.5938592949127326, "spearman": 0.5938592949127219, "kendall": 0.5938592949127219}, "p_value": {"pearson": 2.0417757111515287e-100, "spearman": 2.0417757111723954e-100, "kendall": 6.617187189065265e-82}, "kappa_score": 0.5741466601339213, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.49227385654364975, "spearman": 0.4922738565436574, "kendall": 0.4922738565436573}, "p_value": {"pearson": 9.288380104013025e-65, "spearman": 9.288380103965325e-65, "kendall": 7.360509963804423e-57}, "kappa_score": 0.4269075907293478, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.6571290368175419, "spearman": 0.6571290368175611, "kendall": 0.657129036817561}, "p_value": {"pearson": 6.1011981547536256e-130, "spearman": 6.101198154611977e-130, "kendall": 7.377674470004212e-100}, "kappa_score": 0.6457143781440564, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.17122041760519302, "spearman": 0.17122041760519252, "kendall": 0.17122041760519255}, "p_value": {"pearson": 2.6342130413898266e-08, "spearman": 2.6342130413900648e-08, "kendall": 3.2575421663107847e-08}, "kappa_score": 0.07846294602012815, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.3193990157824078, "spearman": 0.319399015782411, "kendall": 0.319399015782411}, "p_value": {"pearson": 3.643837061470298e-26, "spearman": 3.643837061465968e-26, "kendall": 6.336393744935631e-25}, "kappa_score": 0.20084076248459815, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.2770738715490476, "spearman": 0.2770738715490475, "kendall": 0.27707387154904745}, "p_value": {"pearson": 7.752970527322563e-20, "spearman": 7.752970527322888e-20, "kendall": 3.754975914794827e-19}, "kappa_score": 0.14955816311748504, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.03290693864206462, "spearman": 0.03290693864206438, "kendall": 0.03290693864206438}, "p_value": {"pearson": 0.28834485065264415, "spearman": 0.2883448506526569, "kendall": 0.28812819976607273}, "kappa_score": 0.016233121525019656, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.399655189231653, "spearman": 0.39965518923165194, "kendall": 0.39965518923165194}, "p_value": {"pearson": 2.8236993361099355e-41, "spearman": 2.8236993361116305e-41, "kendall": 4.4498978316971414e-38}, "kappa_score": 0.3995542242486, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.07784534536933663, "spearman": 0.0778453453693371, "kendall": 0.07784534536933709}, "p_value": {"pearson": 0.011908050241020748, "spearman": 0.011908050241020138, "kendall": 0.011976035296155424}, "kappa_score": 0.040988658164431646, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.22262990905054594, "spearman": 0.22262990905054253, "kendall": 0.22262990905054253}, "p_value": {"pearson": 3.5214279467278707e-13, "spearman": 3.521427946730759e-13, "kendall": 6.647378568946667e-13}, "kappa_score": 0.1692853522554486, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.01116818171627773, "spearman": 0.011168181716277868, "kendall": 0.01116818171627787}, "p_value": {"pearson": 0.7186520650820781, "spearman": 0.7186520650820727, "kendall": 0.7184663909412029}, "kappa_score": 0.0056736355601918476, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.3194033530991928, "spearman": 0.3194033530991928, "kendall": 0.3194033530991928}, "p_value": {"pearson": 3.63794131569693e-26, "spearman": 3.6379413156970025e-26, "kendall": 6.327169202999095e-25}, "kappa_score": 0.25251744089530603, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.19443745319054187, "spearman": 0.19443745319054123, "kendall": 0.19443745319054123}, "p_value": {"pearson": 2.412882530624674e-10, "spearman": 2.4128825306251546e-10, "kendall": 3.4640004347716045e-10}, "kappa_score": 0.10238920282496933, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.4217487079955936, "spearman": 0.421748707995601, "kendall": 0.4217487079956011}, "p_value": {"pearson": 3.1055515303318365e-46, "spearman": 3.1055515303195375e-46, "kendall": 3.3037470199579355e-42}, "kappa_score": 0.3678860161690546, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.46916835824161274, "spearman": 0.4691683582416068, "kendall": 0.46916835824160674}, "p_value": {"pearson": 3.3195910711739104e-58, "spearman": 3.3195910711862516e-58, "kendall": 8.204583958619751e-52}, "kappa_score": 0.3994858736903565, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.17734039923799322, "spearman": 0.1773403992379942, "kendall": 0.17734039923799422}, "p_value": {"pearson": 8.108182200070981e-09, "spearman": 8.108182200068996e-09, "kendall": 1.0370674552763715e-08}, "kappa_score": 0.148746718822379, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.3179820606154929, "spearman": 0.3179820606154912, "kendall": 0.3179820606154913}, "p_value": {"pearson": 6.175738322403922e-26, "spearman": 6.175738322407987e-26, "kendall": 1.0188012916905883e-24}, "kappa_score": 0.28348980993817263, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.3983713301098748, "spearman": 0.39837133010987297, "kendall": 0.398371330109873}, "p_value": {"pearson": 5.341411997181132e-41, "spearman": 5.341411997186233e-41, "kendall": 7.612970928581912e-38}, "kappa_score": 0.3942195541125335, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.15047164935882865, "spearman": 0.15047164935882998, "kendall": 0.15047164935882992}, "p_value": {"pearson": 1.0525516190064434e-06, "spearman": 1.05255161900622e-06, "kendall": 1.1904015259706369e-06}, "kappa_score": 0.08981008155905179, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.6617279750216081, "spearman": 0.6617279750216207, "kendall": 0.6617279750216207}, "p_value": {"pearson": 2.2716348936556398e-132, "spearman": 2.2716348936205e-132, "kendall": 3.108240266819544e-101}, "kappa_score": 0.6480626610859437, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.3624367933530691, "spearman": 0.36243679335307105, "kendall": 0.36243679335307105}, "p_value": {"pearson": 9.935364271656106e-34, "spearman": 9.935364271647544e-34, "kendall": 1.2825401010210396e-31}, "kappa_score": 0.28229051075885414, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.3524246350544039, "spearman": 0.3524246350544022, "kendall": 0.35242463505440214}, "p_value": {"pearson": 7.31343700904403e-32, "spearman": 7.313437009049305e-32, "kendall": 5.4894116395935266e-30}, "kappa_score": 0.33800986880768635, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.05907626420763434, "spearman": 0.059076264207633615, "kendall": 0.05907626420763362}, "p_value": {"pearson": 0.05648482647483406, "spearman": 0.056484826474835395, "kendall": 0.05652275362023751}, "kappa_score": 0.04101052262875993, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.05915410208386393, "spearman": 0.05915410208386371, "kendall": 0.05915410208386372}, "p_value": {"pearson": 0.056159789450665104, "spearman": 0.05615978945066673, "kendall": 0.056198152545698536}, "kappa_score": 0.04043875568117927, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.5441185757593918, "spearman": 0.544118575759391, "kendall": 0.5441185757593912}, "p_value": {"pearson": 1.982081590553055e-81, "spearman": 1.982081590554143e-81, "kendall": 4.6349534000267603e-69}, "kappa_score": 0.5424364218073533, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.3645308575655793, "spearman": 0.3645308575655776, "kendall": 0.36453085756557757}, "p_value": {"pearson": 3.964692873795367e-34, "spearman": 3.964692873797978e-34, "kendall": 5.769700840541408e-32}, "kappa_score": 0.3305679035823804, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.6168208917341172, "spearman": 0.6168208917341129, "kendall": 0.6168208917341128}, "p_value": {"pearson": 2.3520677010072886e-110, "spearman": 2.3520677010182394e-110, "kendall": 3.2676909851067314e-88}, "kappa_score": 0.616796397720379, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.2488942740961424, "spearman": 0.24889427409614287, "kendall": 0.24889427409614284}, "p_value": {"pearson": 3.4278813042434503e-16, "spearman": 3.427881304242799e-16, "kendall": 9.410442552810546e-16}, "kappa_score": 0.24794881330975382, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.2164710919154312, "spearman": 0.21647109191543212, "kendall": 0.21647109191543218}, "p_value": {"pearson": 1.5876014978664666e-12, "spearman": 1.5876014978661065e-12, "kendall": 2.794445901746208e-12}, "kappa_score": 0.20131030375223358, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.42336022497269665, "spearman": 0.4233602249726893, "kendall": 0.42336022497268927}, "p_value": {"pearson": 1.3053370927485958e-46, "spearman": 1.30533709275364e-46, "kendall": 1.6188721705700695e-42}, "kappa_score": 0.3606686647343115, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.3725304145800378, "spearman": 0.3725304145800441, "kendall": 0.3725304145800441}, "p_value": {"pearson": 1.1132192437258458e-35, "spearman": 1.1132192437226725e-35, "kendall": 2.6166453569823418e-33}, "kappa_score": 0.2935404691626534, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.4455241820449548, "spearman": 0.4455241820449529, "kendall": 0.44552418204495303}, "p_value": {"pearson": 5.32933340888089e-52, "spearman": 5.329333408886933e-52, "kendall": 6.758217707603602e-47}, "kappa_score": 0.40989965465268374, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.2056922072948813, "spearman": 0.20569220729488188, "kendall": 0.20569220729488188}, "p_value": {"pearson": 1.9892393333709317e-11, "spearman": 1.989239333370657e-11, "kendall": 3.142165963518704e-11}, "kappa_score": 0.08637904692615495, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.1673096729820938, "spearman": 0.16730967298209437, "kendall": 0.1673096729820944}, "p_value": {"pearson": 5.4726779831836736e-08, "spearman": 5.4726779831829384e-08, "kendall": 6.635901212514002e-08}, "kappa_score": 0.059824962843042395, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.2781676355044185, "spearman": 0.27816763550442053, "kendall": 0.2781676355044206}, "p_value": {"pearson": 5.483426609329519e-20, "spearman": 5.48342660932628e-20, "kendall": 2.7259845328342123e-19}, "kappa_score": 0.19802341493081954, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.10803477072915268, "spearman": 0.10803477072915357, "kendall": 0.10803477072915355}, "p_value": {"pearson": 0.00047390499872426955, "spearman": 0.0004739049987241906, "kendall": 0.00048780498410033366}, "kappa_score": 0.05253342321087506, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.2333851269032322, "spearman": 0.23338512690323038, "kendall": 0.2333851269032304}, "p_value": {"pearson": 2.2772878627535663e-14, "spearman": 2.27728786275465e-14, "kendall": 4.933080845257828e-14}, "kappa_score": 0.1270256035471793, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.11171769313860352, "spearman": 0.1117176931386042, "kendall": 0.1117176931386042}, "p_value": {"pearson": 0.00030037633427480026, "spearman": 0.0003003763342747772, "kendall": 0.0003106539779011878}, "kappa_score": 0.027038430026643634, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.18630785913830705, "spearman": 0.18630785913830727, "kendall": 0.1863078591383073}, "p_value": {"pearson": 1.3372976713797615e-09, "spearman": 1.3372976713796623e-09, "kendall": 1.8097558670774077e-09}, "kappa_score": 0.12548037092121422, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.43461556467928586, "spearman": 0.43461556467929036, "kendall": 0.4346155646792904}, "p_value": {"pearson": 2.685690441745202e-49, "spearman": 2.685690441738495e-49, "kendall": 1.0301771916025835e-44}, "kappa_score": 0.3240689246269035, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8258377575499997, "spearman": 0.8258377575499951, "kendall": 0.825837757549995}, "p_value": {"pearson": 3.0454364388167027e-261, "spearman": 3.045436438853178e-261, "kendall": 1.443138579017191e-156}, "kappa_score": 0.8242848803269118, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.3993315155361766, "spearman": 0.3993315155361801, "kendall": 0.39933151553618007}, "p_value": {"pearson": 3.3168574221599747e-41, "spearman": 3.3168574221538725e-41, "kendall": 5.095807811972693e-38}, "kappa_score": 0.3629428798671195, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.1977189039914867, "spearman": 0.19771890399148903, "kendall": 0.197718903991489}, "p_value": {"pearson": 1.1832338349560842e-10, "spearman": 1.1832338349554713e-10, "kendall": 1.743667591011257e-10}, "kappa_score": 0.14841561439813067, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.2856595506287541, "spearman": 0.2856595506287556, "kendall": 0.2856595506287557}, "p_value": {"pearson": 4.902829641149821e-21, "spearman": 4.9028296411475935e-21, "kendall": 2.9407497746327057e-20}, "kappa_score": 0.24077908677799842, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.1068036098399956, "spearman": 0.10680360983999568, "kendall": 0.10680360983999568}, "p_value": {"pearson": 0.0005502364071742173, "spearman": 0.0005502364071741905, "kendall": 0.0005655424715449021}, "kappa_score": 0.05801739540180251, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.20486146992626722, "spearman": 0.20486146992626875, "kendall": 0.20486146992626875}, "p_value": {"pearson": 2.4035937801032376e-11, "spearman": 2.4035937801023597e-11, "kendall": 3.7677818377263106e-11}, "kappa_score": 0.12202242361285243, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.08152878211336863, "spearman": 0.08152878211336918, "kendall": 0.08152878211336918}, "p_value": {"pearson": 0.008432521218388948, "spearman": 0.008432521218388857, "kendall": 0.00849460676516123}, "kappa_score": 0.033503985909661416, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.05950241253530123, "spearman": 0.05950241253530119, "kendall": 0.0595024125353012}, "p_value": {"pearson": 0.0547242993845827, "spearman": 0.05472429938458117, "kendall": 0.054764575899654444}, "kappa_score": 0.030632692421336594, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.045602198912947305, "spearman": 0.045602198912947214, "kendall": 0.04560219891294721}, "p_value": {"pearson": 0.14108949238002352, "spearman": 0.14108949238002078, "kendall": 0.14101004628094382}, "kappa_score": 0.004150489896358245, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.07900790999644586, "spearman": 0.07900790999644518, "kendall": 0.07900790999644518}, "p_value": {"pearson": 0.010694306173083335, "spearman": 0.010694306173084273, "kendall": 0.010760639661294862}, "kappa_score": 0.025544232565926306, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.030865522795037965, "spearman": 0.030865522795038052, "kendall": 0.030865522795038056}, "p_value": {"pearson": 0.3193182826735347, "spearman": 0.3193182826735347, "kendall": 0.3190850522430313}, "kappa_score": 0.009289337996433611, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.2218430339775938, "spearman": 0.22184303397759297, "kendall": 0.22184303397759295}, "p_value": {"pearson": 4.279264504794607e-13, "spearman": 4.2792645047956507e-13, "kendall": 8.003303600878796e-13}, "kappa_score": 0.11073823934211091, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.04368751239867771, "spearman": 0.04368751239867813, "kendall": 0.04368751239867812}, "p_value": {"pearson": 0.1585716303902348, "spearman": 0.1585716303902272, "kendall": 0.1584706045197184}, "kappa_score": 0.022135062716011067, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.07410864566835537, "spearman": 0.07410864566835523, "kendall": 0.07410864566835522}, "p_value": {"pearson": 0.016674890027197017, "spearman": 0.016674890027196958, "kendall": 0.01674639375304253}, "kappa_score": 0.05883715173245385, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.06573006493873089, "spearman": 0.06573006493873154, "kendall": 0.06573006493873156}, "p_value": {"pearson": 0.0337927389821719, "spearman": 0.03379273898217102, "kendall": 0.03385721457332813}, "kappa_score": 0.06431797101890013, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.2304966394557037, "spearman": 0.23049663945570492, "kendall": 0.23049663945570498}, "p_value": {"pearson": 4.8167961206875806e-14, "spearman": 4.81679612068568e-14, "kendall": 1.0035258986076963e-13}, "kappa_score": 0.13355650268320873, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.3418497166960885, "spearman": 0.3418497166960891, "kendall": 0.3418497166960891}, "p_value": {"pearson": 5.8110230649210066e-30, "spearman": 5.811023064919293e-30, "kendall": 2.5928985914730085e-28}, "kappa_score": 0.23734538975684605, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.04411584284573593, "spearman": 0.044115842845736594, "kendall": 0.0441158428457366}, "p_value": {"pearson": 0.15452511366037047, "spearman": 0.15452511366035526, "kendall": 0.15442895935099324}, "kappa_score": 0.009324473881720308, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.5409084453363227, "spearman": 0.5409084453363194, "kendall": 0.5409084453363194}, "p_value": {"pearson": 2.602651539383529e-80, "spearman": 2.602651539390251e-80, "kendall": 2.862238488841569e-68}, "kappa_score": 0.5405117662175558, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.28189677602999286, "spearman": 0.28189677602999785, "kendall": 0.2818967760299978}, "p_value": {"pearson": 1.66382705342192e-20, "spearman": 1.66382705341922e-20, "kendall": 9.063598192325057e-20}, "kappa_score": 0.18088030557241286, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.33286281006423696, "spearman": 0.3328628100642412, "kendall": 0.3328628100642412}, "p_value": {"pearson": 2.100769426989332e-28, "spearman": 2.1007694269860387e-28, "kendall": 6.268423697996146e-27}, "kappa_score": 0.3125836454977705, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.17572014271284664, "spearman": 0.17572014271284675, "kendall": 0.17572014271284678}, "p_value": {"pearson": 1.1121560196422681e-08, "spearman": 1.1121560196421832e-08, "kendall": 1.4093364074420612e-08}, "kappa_score": 0.07094725533260349, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.3320371848924688, "spearman": 0.33203718489247347, "kendall": 0.3320371848924736}, "p_value": {"pearson": 2.9036903606818944e-28, "spearman": 2.903690360676754e-28, "kendall": 8.364313120008255e-27}, "kappa_score": 0.25247030348603605, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.41093158980793165, "spearman": 0.41093158980792044, "kendall": 0.4109315898079205}, "p_value": {"pearson": 9.256142608275607e-44, "spearman": 9.256142608328217e-44, "kendall": 3.700032845468278e-40}, "kappa_score": 0.4103407514005242, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.3111371948599201, "spearman": 0.31113719485992336, "kendall": 0.31113719485992336}, "p_value": {"pearson": 7.59104236256825e-25, "spearman": 7.591042362559348e-25, "kendall": 9.81129303665527e-24}, "kappa_score": 0.24214743922439752, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.49723923298602013, "spearman": 0.49723923298602324, "kendall": 0.4972392329860233}, "p_value": {"pearson": 3.111384240001512e-66, "spearman": 3.111384239995265e-66, "kendall": 5.6345851772028504e-58}, "kappa_score": 0.47675835280290113, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.1284989885749655, "spearman": 0.1284989885749642, "kendall": 0.12849898857496417}, "p_value": {"pearson": 3.151537412062242e-05, "spearman": 3.151537412062899e-05, "kendall": 3.354648529489722e-05}, "kappa_score": 0.06013035326649785, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.3346648949189177, "spearman": 0.3346648949189204, "kendall": 0.33466489491892043}, "p_value": {"pearson": 1.0328976175284782e-28, "spearman": 1.0328976175274506e-28, "kendall": 3.3316988134624295e-27}, "kappa_score": 0.2297535211267605, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.2741128674362172, "spearman": 0.274112867436218, "kendall": 0.27411286743621804}, "p_value": {"pearson": 1.9646120727131952e-19, "spearman": 1.964612072712597e-19, "kendall": 8.880667826889709e-19}, "kappa_score": 0.1603154584204729, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gpt-4o (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.404416276633119, "spearman": 0.4044162766331171, "kendall": 0.40441627663311713}, "p_value": {"pearson": 2.591241052940283e-42, "spearman": 2.591241052942763e-42, "kendall": 5.984900247437593e-39}, "kappa_score": 0.40438380131951446, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.3933734195444672, "spearman": 0.39337341954446664, "kendall": 0.39337341954446664}, "p_value": {"pearson": 6.2203123009695225e-40, "spearman": 6.220312300971578e-40, "kendall": 6.057981749407511e-37}, "kappa_score": 0.29164283671718616, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.4120353579699756, "spearman": 0.41203535796997653, "kendall": 0.4120353579699765}, "p_value": {"pearson": 5.225019200494077e-44, "spearman": 5.225019200491694e-44, "kendall": 2.298900228079458e-40}, "kappa_score": 0.4104439019110272, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.4785113316157919, "spearman": 0.47851133161579007, "kendall": 0.47851133161579007}, "p_value": {"pearson": 8.541207290442471e-61, "spearman": 8.541207290451756e-61, "kendall": 7.982885698894855e-54}, "kappa_score": 0.4775700747330248, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.3331643191669904, "spearman": 0.3331643191669967, "kendall": 0.33316431916699674}, "p_value": {"pearson": 1.8661040002365094e-28, "spearman": 1.8661040002319911e-28, "kendall": 5.640715146739698e-27}, "kappa_score": 0.2684613072375672, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.44421016112107703, "spearman": 0.4442101611210758, "kendall": 0.44421016112107575}, "p_value": {"pearson": 1.1413903218066563e-51, "spearman": 1.1413903218073526e-51, "kendall": 1.2463463679103364e-46}, "kappa_score": 0.44129207138016713, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.44014231825878636, "spearman": 0.44014231825878386, "kendall": 0.44014231825878386}, "p_value": {"pearson": 1.1809476739052885e-50, "spearman": 1.1809476739069844e-50, "kendall": 8.195431439764115e-46}, "kappa_score": 0.4071857817060165, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.6532127787115698, "spearman": 0.6532127787115788, "kendall": 0.6532127787115788}, "p_value": {"pearson": 6.613790655472314e-128, "spearman": 6.613790655400886e-128, "kendall": 1.0755391644027946e-98}, "kappa_score": 0.6482036883415225, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.5046007249072193, "spearman": 0.5046007249072098, "kendall": 0.5046007249072096}, "p_value": {"pearson": 1.823852603908052e-68, "spearman": 1.823852603920603e-68, "kendall": 1.1906847944452356e-59}, "kappa_score": 0.48989140106183005, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.31253736961280365, "spearman": 0.31253736961280065, "kendall": 0.31253736961280065}, "p_value": {"pearson": 4.567995394851045e-25, "spearman": 4.567995394856365e-25, "kendall": 6.1976086697107015e-24}, "kappa_score": 0.29899390968969397, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.5940164727201103, "spearman": 0.5940164727201077, "kendall": 0.5940164727201077}, "p_value": {"pearson": 1.7566503987280274e-100, "spearman": 1.7566503987321808e-100, "kendall": 6.002238310849351e-82}, "kappa_score": 0.5719553234880006, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.6168764763919405, "spearman": 0.6168764763919415, "kendall": 0.6168764763919415}, "p_value": {"pearson": 2.2201815107185037e-110, "spearman": 2.2201815107162636e-110, "kendall": 3.1527231213610016e-88}, "kappa_score": 0.6168674948133048, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.7158216399790222, "spearman": 0.7158216399790213, "kendall": 0.7158216399790213}, "p_value": {"pearson": 1.4954673862077442e-164, "spearman": 1.4954673862099524e-164, "kendall": 3.961163745205268e-118}, "kappa_score": 0.697856315179606, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.8444352370803669, "spearman": 0.8444352370803825, "kendall": 0.8444352370803824}, "p_value": {"pearson": 1.7301265237977074e-284, "spearman": 1.7301265237152642e-284, "kendall": 1.3217452120524212e-163}, "kappa_score": 0.8381942289792119, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.8967041610277198, "spearman": 0.8967041610277288, "kendall": 0.8967041610277288}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 3.184944406156878e-184}, "kappa_score": 0.8966828901054633, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.529392308337837, "spearman": 0.5293923083378334, "kendall": 0.5293923083378334}, "p_value": {"pearson": 2.1349056865527826e-76, "spearman": 2.1349056865590696e-76, "kendall": 1.798463137083494e-65}, "kappa_score": 0.5224811787685131, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.26063842344965976, "spearman": 0.26063842344965626, "kendall": 0.26063842344965626}, "p_value": {"pearson": 1.1719684018998494e-17, "spearman": 1.171968401901038e-17, "kendall": 3.9824367359401125e-17}, "kappa_score": 0.20411177713274808, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.23634562081125587, "spearman": 0.23634562081125385, "kendall": 0.2363456208112539}, "p_value": {"pearson": 1.0457141792761635e-14, "spearman": 1.045714179276686e-14, "kendall": 2.3613708963262424e-14}, "kappa_score": 0.21750547045951862, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.7998950636483337, "spearman": 0.7998950636483392, "kendall": 0.799895063648339}, "p_value": {"pearson": 4.473934823084907e-233, "spearman": 4.473934823028299e-233, "kendall": 5.201870705345194e-147}, "kappa_score": 0.7902874195733153, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.5416929224217745, "spearman": 0.5416929224217659, "kendall": 0.5416929224217659}, "p_value": {"pearson": 1.3907457136866128e-80, "spearman": 1.3907457136961245e-80, "kendall": 1.8361873433419949e-68}, "kappa_score": 0.522265764161026, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.7650873056437553, "spearman": 0.7650873056437543, "kendall": 0.7650873056437543}, "p_value": {"pearson": 3.2190939897409115e-201, "spearman": 3.2190939897472103e-201, "kendall": 1.150816943071614e-134}, "kappa_score": 0.7436664140741802, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.3648513750939837, "spearman": 0.3648513750939828, "kendall": 0.3648513750939828}, "p_value": {"pearson": 3.442552160082368e-34, "spearman": 3.442552160083558e-34, "kendall": 5.103641658910976e-32}, "kappa_score": 0.34752689965801986, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.8026818735763501, "spearman": 0.8026818735763602, "kendall": 0.8026818735763601}, "p_value": {"pearson": 6.739681242282257e-236, "spearman": 6.739681242121815e-236, "kendall": 5.059711810958492e-148}, "kappa_score": 0.8012538348672802, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.7167033787127349, "spearman": 0.7167033787127319, "kendall": 0.7167033787127319}, "p_value": {"pearson": 3.871751722167195e-165, "spearman": 3.8717517221846056e-165, "kendall": 2.0487495389583253e-118}, "kappa_score": 0.7166923203928481, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.7043363758902697, "spearman": 0.7043363758902712, "kendall": 0.7043363758902712}, "p_value": {"pearson": 4.1663311279075666e-157, "spearman": 4.1663311278985144e-157, "kendall": 1.9744405280301348e-114}, "kappa_score": 0.6876741989726579, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.7798462663266023, "spearman": 0.7798462663266065, "kendall": 0.7798462663266066}, "p_value": {"pearson": 5.1740700109726195e-214, "spearman": 5.174070010926188e-214, "kendall": 7.824782547685865e-140}, "kappa_score": 0.7790847089058022, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.305665444032724, "spearman": 0.3056654440327261, "kendall": 0.30566544403272616}, "p_value": {"pearson": 5.382359988325793e-24, "spearman": 5.3823599883215706e-24, "kendall": 5.793406489998097e-23}, "kappa_score": 0.2149430510977931, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.5427938540377313, "spearman": 0.5427938540377379, "kendall": 0.5427938540377379}, "p_value": {"pearson": 5.755371065286544e-81, "spearman": 5.755371065255613e-81, "kendall": 9.83761577369047e-69}, "kappa_score": 0.489553137823288, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.5984098537405306, "spearman": 0.5984098537405409, "kendall": 0.5984098537405408}, "p_value": {"pearson": 2.5358647405353623e-102, "spearman": 2.5358647405092846e-102, "kendall": 3.888338409475756e-83}, "kappa_score": 0.5715960688254271, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.27861295822963916, "spearman": 0.2786129582296428, "kendall": 0.2786129582296428}, "p_value": {"pearson": 4.7601029532245604e-20, "spearman": 4.7601029532187116e-20, "kendall": 2.3918974803393136e-19}, "kappa_score": 0.21897035881435245, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.36706939056314797, "spearman": 0.3670693905631482, "kendall": 0.3670693905631483}, "p_value": {"pearson": 1.2899235610437552e-34, "spearman": 1.2899235610435795e-34, "kendall": 2.1775055553972182e-32}, "kappa_score": 0.3264915477041581, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.4572143741380629, "spearman": 0.457214374138068, "kendall": 0.45721437413806804}, "p_value": {"pearson": 5.2412266698187485e-55, "spearman": 5.241226669802661e-55, "kendall": 2.6967748780181437e-49}, "kappa_score": 0.3789287504053297, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.39513415096835586, "spearman": 0.39513415096835164, "kendall": 0.39513415096835164}, "p_value": {"pearson": 2.632080377921259e-40, "spearman": 2.6320803779267877e-40, "kendall": 2.9259928152643397e-37}, "kappa_score": 0.34051556420233464, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.7831412379709227, "spearman": 0.7831412379709217, "kendall": 0.7831412379709216}, "p_value": {"pearson": 5.263843027061122e-217, "spearman": 5.263843027071491e-217, "kendall": 5.325614956945076e-141}, "kappa_score": 0.772215269086358, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.9149465246209703, "spearman": 0.9149465246209646, "kendall": 0.9149465246209645}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 1.0387497766346702e-191}, "kappa_score": 0.9149134041980405, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.5020411606322457, "spearman": 0.5020411606322486, "kendall": 0.5020411606322486}, "p_value": {"pearson": 1.1046564936484789e-67, "spearman": 1.1046564936463407e-67, "kendall": 4.581224420472318e-59}, "kappa_score": 0.4416651680600223, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.4303764442391581, "spearman": 0.4303764442391576, "kendall": 0.43037644423915755}, "p_value": {"pearson": 2.837128756778258e-48, "spearman": 2.8371287567795153e-48, "kendall": 7.027562325705772e-44}, "kappa_score": 0.41750826080886116, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.5276144255966168, "spearman": 0.527614425596622, "kendall": 0.5276144255966219}, "p_value": {"pearson": 8.322858572263938e-76, "spearman": 8.322858572231664e-76, "kendall": 4.803547396480532e-65}, "kappa_score": 0.5275092675892783, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.38339170204978623, "spearman": 0.3833917020497826, "kendall": 0.3833917020497827}, "p_value": {"pearson": 7.394647133657088e-38, "spearman": 7.394647133670141e-38, "kendall": 3.5294389712498696e-35}, "kappa_score": 0.31819532429252284, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.4246932913913074, "spearman": 0.42469329139130874, "kendall": 0.4246932913913087}, "p_value": {"pearson": 6.350362208906486e-47, "spearman": 6.350362208902606e-47, "kendall": 8.954955822874837e-43}, "kappa_score": 0.40141910575468254, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.3708051100815041, "spearman": 0.3708051100815093, "kendall": 0.37080511008150935}, "p_value": {"pearson": 2.4262749848682133e-35, "spearman": 2.4262749848626085e-35, "kendall": 5.127637080538109e-33}, "kappa_score": 0.3377534024716805, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.17258628290532357, "spearman": 0.1725862829053216, "kendall": 0.1725862829053216}, "p_value": {"pearson": 2.032408766950583e-08, "spearman": 2.0324087669512942e-08, "kendall": 2.531512477615123e-08}, "kappa_score": 0.1547485817929225, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.28645898716696916, "spearman": 0.2864589871669688, "kendall": 0.2864589871669689}, "p_value": {"pearson": 3.7727375611266496e-21, "spearman": 3.772737561127133e-21, "kendall": 2.310908814503197e-20}, "kappa_score": 0.2858897682192554, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.40362588381109427, "spearman": 0.40362588381109343, "kendall": 0.4036258838110935}, "p_value": {"pearson": 3.8626277446261954e-42, "spearman": 3.862627744627699e-42, "kendall": 8.363868673034482e-39}, "kappa_score": 0.3957244315407801, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.34269834548525707, "spearman": 0.34269834548525596, "kendall": 0.342698345485256}, "p_value": {"pearson": 4.1157446154134096e-30, "spearman": 4.11574461541509e-30, "kendall": 1.9110885398332343e-28}, "kappa_score": 0.26155371081650347, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.5324074919023096, "spearman": 0.53240749190231, "kendall": 0.5324074919023098}, "p_value": {"pearson": 2.085366708543152e-77, "spearman": 2.08536670854282e-77, "kendall": 3.373273426290175e-66}, "kappa_score": 0.5157122496194579, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.4543055973867485, "spearman": 0.45430559738675386, "kendall": 0.45430559738675386}, "p_value": {"pearson": 3.010711639162756e-54, "spearman": 3.0107116391528064e-54, "kendall": 1.080236195515372e-48}, "kappa_score": 0.4416777468874653, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.08822959617010692, "spearman": 0.08822959617010764, "kendall": 0.08822959617010766}, "p_value": {"pearson": 0.004350450738099859, "spearman": 0.004350450738099638, "kendall": 0.004398752220308943}, "kappa_score": 0.0840163934426229, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.3173658934554864, "spearman": 0.31736589345549215, "kendall": 0.3173658934554922}, "p_value": {"pearson": 7.761455020925405e-26, "spearman": 7.761455020908342e-26, "kendall": 1.2516872829541668e-24}, "kappa_score": 0.3172475190489906, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.2889691180398459, "spearman": 0.2889691180398506, "kendall": 0.28896911803985065}, "p_value": {"pearson": 1.648071552233049e-21, "spearman": 1.6480715522305095e-21, "kendall": 1.0795837815610609e-20}, "kappa_score": 0.16973404348819632, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.6113490469666005, "spearman": 0.611349046966592, "kendall": 0.6113490469665919}, "p_value": {"pearson": 6.5188345278075315e-108, "spearman": 6.518834527864294e-108, "kendall": 1.0931728635537239e-86}, "kappa_score": 0.5526890123609747, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.1786754297484106, "spearman": 0.1786754297484141, "kendall": 0.17867542974841408}, "p_value": {"pearson": 6.235679529542693e-09, "spearman": 6.2356795295386684e-09, "kendall": 8.038581649957622e-09}, "kappa_score": 0.09373601200663528, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.7619395394111532, "spearman": 0.7619395394111448, "kendall": 0.7619395394111447}, "p_value": {"pearson": 1.3029558042438394e-198, "spearman": 1.3029558042647572e-198, "kendall": 1.4138256070755263e-133}, "kappa_score": 0.7545324034486275, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.33338807447995067, "spearman": 0.3333880744799587, "kendall": 0.3333880744799587}, "p_value": {"pearson": 1.7089221618871698e-28, "spearman": 1.708922161881731e-28, "kendall": 5.215558869636736e-27}, "kappa_score": 0.23311690739379132, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.7561460266202105, "spearman": 0.7561460266202066, "kendall": 0.7561460266202067}, "p_value": {"pearson": 6.442861494619221e-194, "spearman": 6.442861494665139e-194, "kendall": 1.3922993631399725e-131}, "kappa_score": 0.7525650910384911, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.4374158985638699, "spearman": 0.437415898563865, "kendall": 0.4374158985638649}, "p_value": {"pearson": 5.555278237419008e-50, "spearman": 5.555278237434528e-50, "kendall": 2.868202167842661e-45}, "kappa_score": 0.3729458917835672, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.5852452206188354, "spearman": 0.5852452206188312, "kendall": 0.5852452206188313}, "p_value": {"pearson": 6.848629969691872e-97, "spearman": 6.848629969718675e-97, "kendall": 1.3340090019844982e-79}, "kappa_score": 0.5746946246692521, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.7878652203159564, "spearman": 0.7878652203159489, "kendall": 0.787865220315949}, "p_value": {"pearson": 2.1783993687490672e-221, "spearman": 2.178399368784546e-221, "kendall": 1.1080092579452376e-142}, "kappa_score": 0.7844977714808583, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.59550830293019, "spearman": 0.5955083029302014, "kendall": 0.5955083029302012}, "p_value": {"pearson": 4.196488041686269e-101, "spearman": 4.1964880416404254e-101, "kendall": 2.3752130832776426e-82}, "kappa_score": 0.5804055141339912, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.7974928382057842, "spearman": 0.7974928382057906, "kendall": 0.7974928382057906}, "p_value": {"pearson": 1.1159077963763105e-230, "spearman": 1.115907796359942e-230, "kendall": 3.8522518121539403e-146}, "kappa_score": 0.786411522446472, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.22918003748867052, "spearman": 0.22918003748866725, "kendall": 0.22918003748866728}, "p_value": {"pearson": 6.75462036650608e-14, "spearman": 6.754620366512044e-14, "kendall": 1.383161374586245e-13}, "kappa_score": 0.10911194996280271, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.423701891704265, "spearman": 0.4237018917042676, "kendall": 0.4237018917042676}, "p_value": {"pearson": 1.0855595028176791e-46, "spearman": 1.0855595028160763e-46, "kendall": 1.3911729931578506e-42}, "kappa_score": 0.3227941902974014, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.3429101627509493, "spearman": 0.34291016275095315, "kendall": 0.3429101627509532}, "p_value": {"pearson": 3.775591207727457e-30, "spearman": 3.775591207721852e-30, "kendall": 1.7707501059734795e-28}, "kappa_score": 0.21841088294795097, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.176533705583581, "spearman": 0.17653370558358006, "kendall": 0.17653370558358011}, "p_value": {"pearson": 9.493203036995907e-09, "spearman": 9.493203036997686e-09, "kendall": 1.2085735072151173e-08}, "kappa_score": 0.1388238108714489, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.3781635647726672, "spearman": 0.37816356477266755, "kendall": 0.3781635647726675}, "p_value": {"pearson": 8.46178205283025e-37, "spearman": 8.461782052829133e-37, "kendall": 2.847603422097845e-34}, "kappa_score": 0.3194951107317693, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.19926911537537256, "spearman": 0.19926911537537298, "kendall": 0.19926911537537295}, "p_value": {"pearson": 8.414077702013096e-11, "spearman": 8.414077702012703e-11, "kendall": 1.2559476232156323e-10}, "kappa_score": 0.16840366763483117, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.22567783383018747, "spearman": 0.2256778338301869, "kendall": 0.2256778338301869}, "p_value": {"pearson": 1.6436236882215563e-13, "spearman": 1.643623688221827e-13, "kendall": 3.219422547357573e-13}, "kappa_score": 0.1573394108213051, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.017429965898652984, "spearman": 0.017429965898653175, "kendall": 0.01742996589865318}, "p_value": {"pearson": 0.5739270614313104, "spearman": 0.5739270614313068, "kendall": 0.5736802315511622}, "kappa_score": 0.01034509494079816, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.4422038329350667, "spearman": 0.442203832935068, "kendall": 0.44220383293506804}, "p_value": {"pearson": 3.6280351986976014e-51, "spearman": 3.6280351986954435e-51, "kendall": 3.1621934007521e-46}, "kappa_score": 0.4163841990293874, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.25157284476633596, "spearman": 0.25157284476633685, "kendall": 0.25157284476633685}, "p_value": {"pearson": 1.6115304592021742e-16, "spearman": 1.6115304592018538e-16, "kendall": 4.632059299142353e-16}, "kappa_score": 0.1484630962857718, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.5115029475037874, "spearman": 0.5115029475037948, "kendall": 0.5115029475037949}, "p_value": {"pearson": 1.312569741589652e-70, "spearman": 1.3125697415827843e-70, "kendall": 3.0411763659240337e-61}, "kappa_score": 0.5010281417073028, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.4814501181173653, "spearman": 0.48145011811735816, "kendall": 0.4814501181173581}, "p_value": {"pearson": 1.2596979711803464e-61, "spearman": 1.2596979711862895e-61, "kendall": 1.8247131087495822e-54}, "kappa_score": 0.4765182476518248, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.27800132474231376, "spearman": 0.27800132474231454, "kendall": 0.2780013247423146}, "p_value": {"pearson": 5.780521758120508e-20, "spearman": 5.780521758119146e-20, "kendall": 2.862240172561316e-19}, "kappa_score": 0.2119501452765169, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.3782572967374649, "spearman": 0.3782572967374659, "kendall": 0.3782572967374659}, "p_value": {"pearson": 8.103137507509291e-37, "spearman": 8.103137507504934e-37, "kendall": 2.7436627588861933e-34}, "kappa_score": 0.3045410653875058, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.38713347658532626, "spearman": 0.38713347658532604, "kendall": 0.38713347658532604}, "p_value": {"pearson": 1.257246293416426e-38, "spearman": 1.2572462934165407e-38, "kendall": 7.783622817270729e-36}, "kappa_score": 0.336835112692764, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.26786934353890623, "spearman": 0.26786934353890685, "kendall": 0.26786934353890685}, "p_value": {"pearson": 1.3446156060133233e-18, "spearman": 1.3446156060130627e-18, "kendall": 5.295020300247955e-18}, "kappa_score": 0.18605470775706245, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.8189516704863116, "spearman": 0.8189516704863178, "kendall": 0.8189516704863177}, "p_value": {"pearson": 2.50386221607945e-253, "spearman": 2.503862216039289e-253, "kendall": 5.317114769942496e-154}, "kappa_score": 0.8128272149182694, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.5193245383906492, "spearman": 0.5193245383906484, "kendall": 0.5193245383906485}, "p_value": {"pearson": 4.261913815650007e-73, "spearman": 4.2619138156522875e-73, "kendall": 4.4891990437952435e-63}, "kappa_score": 0.48709002093510123, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.4285314575492399, "spearman": 0.4285314575492392, "kendall": 0.42853145754923927}, "p_value": {"pearson": 7.833364750664763e-48, "spearman": 7.833364750667484e-48, "kendall": 1.6114305235976824e-43}, "kappa_score": 0.4013218315402781, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.09936289390469111, "spearman": 0.09936289390468925, "kendall": 0.09936289390468926}, "p_value": {"pearson": 0.0013131893446974316, "spearman": 0.0013131893446977042, "kendall": 0.0013392353985080417}, "kappa_score": 0.04300801129622189, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.0802778842617331, "spearman": 0.08027788426173244, "kendall": 0.08027788426173245}, "p_value": {"pearson": 0.009495112300428295, "spearman": 0.009495112300428923, "kendall": 0.00955940696505364}, "kappa_score": 0.06774396831112706, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.7581005677431183, "spearman": 0.7581005677431106, "kendall": 0.7581005677431107}, "p_value": {"pearson": 1.7388742034328884e-195, "spearman": 1.7388742034575333e-195, "kendall": 2.971263564454094e-132}, "kappa_score": 0.7563774432577764, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.3886606544967585, "spearman": 0.38866065449675574, "kendall": 0.3886606544967557}, "p_value": {"pearson": 6.06007934117572e-39, "spearman": 6.060079341183571e-39, "kendall": 4.182316945437289e-36}, "kappa_score": 0.3783292028735452, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.7581643395472217, "spearman": 0.7581643395472276, "kendall": 0.7581643395472276}, "p_value": {"pearson": 1.544648967995384e-195, "spearman": 1.5446489679784784e-195, "kendall": 2.8250481205676715e-132}, "kappa_score": 0.7495557796667147, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.21277525824263377, "spearman": 0.2127752582426339, "kendall": 0.2127752582426339}, "p_value": {"pearson": 3.835881316099037e-12, "spearman": 3.835881316098903e-12, "kendall": 6.493023365129972e-12}, "kappa_score": 0.14434095448470996, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.6596685697840416, "spearman": 0.6596685697840482, "kendall": 0.6596685697840484}, "p_value": {"pearson": 2.8144288447597506e-131, "spearman": 2.814428844737249e-131, "kendall": 1.2870691976407256e-100}, "kappa_score": 0.658710066305003, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.40957713517626615, "spearman": 0.40957713517626, "kendall": 0.40957713517626}, "p_value": {"pearson": 1.861685154926952e-43, "spearman": 1.861685154933011e-43, "kendall": 6.623445346086895e-40}, "kappa_score": 0.4056189806811922, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.5464532336364673, "spearman": 0.5464532336364707, "kendall": 0.5464532336364706}, "p_value": {"pearson": 2.993467314057717e-82, "spearman": 2.993467314048815e-82, "kendall": 1.2248855677442616e-69}, "kappa_score": 0.5323448467794304, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.6367366400010659, "spearman": 0.6367366400010626, "kendall": 0.6367366400010627}, "p_value": {"pearson": 1.1477581659530495e-119, "spearman": 1.1477581659572362e-119, "kendall": 7.10590273738984e-94}, "kappa_score": 0.6192082391085197, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.21025832920186113, "spearman": 0.21025832920186133, "kendall": 0.21025832920186133}, "p_value": {"pearson": 6.930909712793784e-12, "spearman": 6.930909712793715e-12, "kendall": 1.1437497619013668e-11}, "kappa_score": 0.10127677527539514, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.20768320778204769, "spearman": 0.20768320778204907, "kendall": 0.2076832077820491}, "p_value": {"pearson": 1.2598671536881144e-11, "spearman": 1.259867153687803e-11, "kendall": 2.0276375023145316e-11}, "kappa_score": 0.0897057936332375, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.3105069173096797, "spearman": 0.3105069173096813, "kendall": 0.3105069173096813}, "p_value": {"pearson": 9.532468985906623e-25, "spearman": 9.532468985901659e-25, "kendall": 1.2057122553718254e-23}, "kappa_score": 0.23106341607265446, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.1313528905345162, "spearman": 0.1313528905345161, "kendall": 0.1313528905345161}, "p_value": {"pearson": 2.086084011443794e-05, "spearman": 2.086084011443854e-05, "kendall": 2.234455528743059e-05}, "kappa_score": 0.07504277988034114, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.22493301345794303, "spearman": 0.22493301345793998, "kendall": 0.22493301345793998}, "p_value": {"pearson": 1.9820440681846162e-13, "spearman": 1.9820440681859885e-13, "kendall": 3.8468453636322895e-13}, "kappa_score": 0.13195274250617228, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.15804332115207698, "spearman": 0.15804332115207795, "kendall": 0.15804332115207792}, "p_value": {"pearson": 2.8936709257568233e-07, "spearman": 2.893670925756344e-07, "kendall": 3.3671866231144854e-07}, "kappa_score": 0.054518443448919096, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.22854228829455425, "spearman": 0.22854228829455134, "kendall": 0.22854228829455137}, "p_value": {"pearson": 7.950680919819276e-14, "spearman": 7.950680919825034e-14, "kendall": 1.6147024230648883e-13}, "kappa_score": 0.11867054169280589, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.6426207732609912, "spearman": 0.6426207732609996, "kendall": 0.6426207732609998}, "p_value": {"pearson": 1.498094295380658e-122, "spearman": 1.4980942953662683e-122, "kendall": 1.3941906411842253e-95}, "kappa_score": 0.6123718092602746, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8546087131694394, "spearman": 0.8546087131694523, "kendall": 0.8546087131694523}, "p_value": {"pearson": 1.5407652447350953e-298, "spearman": 1.5407652446685372e-298, "kendall": 1.6028270728688227e-167}, "kappa_score": 0.8535903729257679, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.4171341183238293, "spearman": 0.41713411832383424, "kendall": 0.41713411832383424}, "p_value": {"pearson": 3.6203937345334325e-45, "spearman": 3.620393734524142e-45, "kendall": 2.509793001752167e-41}, "kappa_score": 0.3652225571062695, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.156610274134523, "spearman": 0.15661027413452377, "kendall": 0.15661027413452377}, "p_value": {"pearson": 3.712448390783198e-07, "spearman": 3.7124483907826856e-07, "kendall": 4.2952669657537295e-07}, "kappa_score": 0.07845166145380156, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.3647164167882969, "spearman": 0.3647164167882985, "kendall": 0.3647164167882985}, "p_value": {"pearson": 3.653528075147522e-34, "spearman": 3.653528075144686e-34, "kendall": 5.374241524232925e-32}, "kappa_score": 0.2909405119668601, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.22071546419794102, "spearman": 0.22071546419794208, "kendall": 0.22071546419794202}, "p_value": {"pearson": 5.650839277693761e-13, "spearman": 5.650839277692303e-13, "kendall": 1.0430713202401995e-12}, "kappa_score": 0.12023065501881836, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.2126237559959856, "spearman": 0.21262375599598687, "kendall": 0.21262375599598687}, "p_value": {"pearson": 3.975772961477629e-12, "spearman": 3.975772961476358e-12, "kendall": 6.719347156569896e-12}, "kappa_score": 0.12355195801857277, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.2501754064415656, "spearman": 0.25017540644156816, "kendall": 0.2501754064415682}, "p_value": {"pearson": 2.3918407187788065e-16, "spearman": 2.3918407187770346e-16, "kendall": 6.710806605918294e-16}, "kappa_score": 0.18329526916802608, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.07535935877740449, "spearman": 0.07535935877740421, "kendall": 0.07535935877740421}, "p_value": {"pearson": 0.014920098537355656, "spearman": 0.014920098537355455, "kendall": 0.014990769866918928}, "kappa_score": 0.07532976922870271, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.08680943422277365, "spearman": 0.08680943422277361, "kendall": 0.08680943422277362}, "p_value": {"pearson": 0.005024002733441413, "spearman": 0.005024002733441523, "kendall": 0.005075371591529056}, "kappa_score": 0.02728829413802325, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.1563392710418818, "spearman": 0.1563392710418809, "kendall": 0.1563392710418809}, "p_value": {"pearson": 3.8905869821861206e-07, "spearman": 3.890586982186716e-07, "kendall": 4.4965792493173074e-07}, "kappa_score": 0.1124717895593621, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.10789751093682687, "spearman": 0.10789751093682681, "kendall": 0.1078975109368268}, "p_value": {"pearson": 0.00048189828062664483, "spearman": 0.00048189828062666657, "kendall": 0.0004959500112743455}, "kappa_score": 0.034255213068598356, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.40637976143393917, "spearman": 0.40637976143393884, "kendall": 0.4063797614339388}, "p_value": {"pearson": 9.567172264075393e-43, "spearman": 9.567172264076993e-43, "kendall": 2.5987400843122225e-39}, "kappa_score": 0.35339854450616737, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.1340802247135231, "spearman": 0.13408022471352496, "kendall": 0.13408022471352496}, "p_value": {"pearson": 1.3951174389498477e-05, "spearman": 1.3951174389494213e-05, "kendall": 1.5039232405782828e-05}, "kappa_score": 0.10967089538518116, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.06161678706823425, "spearman": 0.06161678706823443, "kendall": 0.061616787068234424}, "p_value": {"pearson": 0.0466515616023011, "spearman": 0.04665156160230048, "kendall": 0.046702150715065845}, "kappa_score": 0.05539970400477123, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.13343581016479478, "spearman": 0.1334358101647957, "kendall": 0.13343581016479572}, "p_value": {"pearson": 1.5353279297661625e-05, "spearman": 1.5353279297659738e-05, "kendall": 1.6525099618542943e-05}, "kappa_score": 0.10372710920862305, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.15513158877086197, "spearman": 0.15513158877086292, "kendall": 0.15513158877086294}, "p_value": {"pearson": 4.789622525587517e-07, "spearman": 4.789622525586647e-07, "kendall": 5.509817104839064e-07}, "kappa_score": 0.06150047439957029, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.30536443862696994, "spearman": 0.30536443862696894, "kendall": 0.30536443862696894}, "p_value": {"pearson": 5.987538385971426e-24, "spearman": 5.9875383859730976e-24, "kendall": 6.382184557313308e-23}, "kappa_score": 0.1829719058884659, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.06494812231433683, "spearman": 0.06494812231433764, "kendall": 0.06494812231433764}, "p_value": {"pearson": 0.03597303153622874, "spearman": 0.035973031536226545, "kendall": 0.03603546755129775}, "kappa_score": 0.016694265330765123, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.764001895321718, "spearman": 0.764001895321726, "kendall": 0.7640018953217259}, "p_value": {"pearson": 2.5784326990658736e-200, "spearman": 2.578432699026448e-200, "kendall": 2.736241348839226e-134}, "kappa_score": 0.7612854584864763, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.2521884537702139, "spearman": 0.25218845377021976, "kendall": 0.2521884537702197}, "p_value": {"pearson": 1.3531798228782865e-16, "spearman": 1.3531798228761105e-16, "kendall": 3.931629112510787e-16}, "kappa_score": 0.12806872641734446, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.2675333895528903, "spearman": 0.26753338955289113, "kendall": 0.2675333895528911}, "p_value": {"pearson": 1.4891142446858732e-18, "spearman": 1.489114244685326e-18, "kendall": 5.822343460689624e-18}, "kappa_score": 0.16088050006471177, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.17450323567379233, "spearman": 0.1745032356737924, "kendall": 0.17450323567379242}, "p_value": {"pearson": 1.4073641014139096e-08, "spearman": 1.4073641014138797e-08, "kendall": 1.771335421713827e-08}, "kappa_score": 0.07007092198581566, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.5968339939328117, "spearman": 0.596833993932811, "kendall": 0.5968339939328111}, "p_value": {"pearson": 1.1683979496113266e-101, "spearman": 1.1683979496122424e-101, "kendall": 1.0401265331146837e-82}, "kappa_score": 0.5955628197484124, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.3492891563182058, "spearman": 0.3492891563181963, "kendall": 0.3492891563181963}, "p_value": {"pearson": 2.7234771923359445e-31, "spearman": 2.723477192346513e-31, "kendall": 1.7425458751471117e-29}, "kappa_score": 0.34192720231490537, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.4910597018308018, "spearman": 0.4910597018308057, "kendall": 0.4910597018308057}, "p_value": {"pearson": 2.1131496160188144e-64, "spearman": 2.1131496160133575e-64, "kendall": 1.3744122731566765e-56}, "kappa_score": 0.4161917362100549, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.6990954384437889, "spearman": 0.6990954384437928, "kendall": 0.6990954384437927}, "p_value": {"pearson": 7.918926541181259e-154, "spearman": 7.918926541135952e-154, "kendall": 9.182048925794076e-113}, "kappa_score": 0.6935057302380252, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.17075128837799985, "spearman": 0.1707512883779985, "kendall": 0.1707512883779985}, "p_value": {"pearson": 2.8782707353915955e-08, "spearman": 2.8782707353924686e-08, "kendall": 3.550697361974373e-08}, "kappa_score": 0.07438935841989847, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.34578015445978627, "spearman": 0.34578015445978805, "kendall": 0.34578015445978805}, "p_value": {"pearson": 1.1655177425361473e-30, "spearman": 1.165517742535258e-30, "kendall": 6.271455229328261e-29}, "kappa_score": 0.22598780324169798, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.2673861268770993, "spearman": 0.2673861268770998, "kendall": 0.26738612687709973}, "p_value": {"pearson": 1.5571837189152915e-18, "spearman": 1.557183718915023e-18, "kendall": 6.0695268419690655e-18}, "kappa_score": 0.14362000950717058, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.3498341667706236, "spearman": 0.3498341667706209, "kendall": 0.3498341667706209}, "p_value": {"pearson": 2.1693780929503917e-31, "spearman": 2.1693780929527253e-31, "kendall": 1.4266018196426625e-29}, "kappa_score": 0.3359323816817842, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.46529896818116284, "spearman": 0.4652989681811596, "kendall": 0.4652989681811596}, "p_value": {"pearson": 3.717758741200115e-57, "spearman": 3.7177587412073515e-57, "kendall": 5.442070955236069e-51}, "kappa_score": 0.404946227828194, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.11601351305734249, "spearman": 0.1160135130573426, "kendall": 0.11601351305734256}, "p_value": {"pearson": 0.00017340497335301374, "spearman": 0.0001734049733530107, "kendall": 0.00018045193035020482}, "kappa_score": 0.041046841766189224, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.24678720507210353, "spearman": 0.24678720507210486, "kendall": 0.24678720507210478}, "p_value": {"pearson": 6.168176448172656e-16, "spearman": 6.168176448171101e-16, "kendall": 1.6349959384205704e-15}, "kappa_score": 0.1585122072796601, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.08573357177754534, "spearman": 0.0857335717775461, "kendall": 0.0857335717775461}, "p_value": {"pearson": 0.005595452270084803, "spearman": 0.005595452270084518, "kendall": 0.005649119582057763}, "kappa_score": 0.04415460022585782, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.3256244323214356, "spearman": 0.32562443232143595, "kendall": 0.32562443232143595}, "p_value": {"pearson": 3.469144110653279e-27, "spearman": 3.469144110653097e-27, "kendall": 7.673985337864476e-26}, "kappa_score": 0.21127778721646473, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.15881839294687655, "spearman": 0.15881839294687555, "kendall": 0.15881839294687558}, "p_value": {"pearson": 2.526490561060426e-07, "spearman": 2.5264905610607716e-07, "kendall": 2.94924825846097e-07}, "kappa_score": 0.05452178069322422, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.5523203431040337, "spearman": 0.5523203431040314, "kendall": 0.5523203431040316}, "p_value": {"pearson": 2.422584269029103e-84, "spearman": 2.4225842690331137e-84, "kendall": 4.215269145787236e-71}, "kappa_score": 0.5015833370500871, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.47475553175401963, "spearman": 0.47475553175401386, "kendall": 0.4747555317540138}, "p_value": {"pearson": 9.59737923877556e-60, "spearman": 9.597379238810236e-60, "kendall": 5.195823836300683e-53}, "kappa_score": 0.3982149095091001, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.16561535638084018, "spearman": 0.1656153563808412, "kendall": 0.1656153563808412}, "p_value": {"pearson": 7.473097116530574e-08, "spearman": 7.473097116529228e-08, "kendall": 8.988554585283071e-08}, "kappa_score": 0.0712987986460707, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.30175536163924144, "spearman": 0.3017553616392442, "kendall": 0.3017553616392442}, "p_value": {"pearson": 2.1276210540064117e-23, "spearman": 2.12762105400416e-23, "kendall": 2.0221555261457574e-22}, "kappa_score": 0.1938380806477329, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.38092727900437584, "spearman": 0.38092727900437817, "kendall": 0.3809272790043781}, "p_value": {"pearson": 2.3458094728641044e-37, "spearman": 2.3458094728614625e-37, "kendall": 9.476962916558588e-35}, "kappa_score": 0.2871528189737429, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.1950481103576649, "spearman": 0.1950481103576658, "kendall": 0.1950481103576658}, "p_value": {"pearson": 2.1152047805233607e-10, "spearman": 2.1152047805229618e-10, "kendall": 3.051137018310839e-10}, "kappa_score": 0.07594464322340977, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.8307123157814112, "spearman": 0.8307123157814245, "kendall": 0.8307123157814245}, "p_value": {"pearson": 4.642358301249506e-267, "spearman": 4.642358301079345e-267, "kendall": 2.136294518892242e-158}, "kappa_score": 0.8166261318017991, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.6497526626489152, "spearman": 0.6497526626489151, "kendall": 0.6497526626489152}, "p_value": {"pearson": 3.921072829918719e-126, "spearman": 3.9210728299191356e-126, "kendall": 1.132476540364053e-97}, "kappa_score": 0.6044169457911981, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.2943025526073032, "spearman": 0.29430255260730354, "kendall": 0.29430255260730354}, "p_value": {"pearson": 2.7581781256826423e-22, "spearman": 2.7581781256822435e-22, "kendall": 2.097015413330295e-21}, "kappa_score": 0.19244214014645356, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.07132756406447255, "spearman": 0.07132756406447162, "kendall": 0.07132756406447163}, "p_value": {"pearson": 0.02123766097987132, "spearman": 0.021237660979873566, "kendall": 0.021309496183153052}, "kappa_score": 0.028127686614585423, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.10463362855370757, "spearman": 0.10463362855370587, "kendall": 0.10463362855370588}, "p_value": {"pearson": 0.0007132406334740454, "spearman": 0.0007132406334742067, "kendall": 0.0007312770935125111}, "kappa_score": 0.042750281382909816, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.751925600817184, "spearman": 0.7519256008171784, "kendall": 0.7519256008171783}, "p_value": {"pearson": 1.4009434024123616e-190, "spearman": 1.400943402426631e-190, "kendall": 3.8572746913451946e-130}, "kappa_score": 0.7389046803837334, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.6361618038279271, "spearman": 0.6361618038279225, "kendall": 0.6361618038279225}, "p_value": {"pearson": 2.179015829719966e-119, "spearman": 2.1790158297310782e-119, "kendall": 1.0412892245313029e-93}, "kappa_score": 0.6356402592865737, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.6467417103503798, "spearman": 0.6467417103503783, "kendall": 0.6467417103503783}, "p_value": {"pearson": 1.310515367972898e-124, "spearman": 1.3105153679751485e-124, "kendall": 8.695879973844348e-97}, "kappa_score": 0.6324597345346756, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.318240646597453, "spearman": 0.3182406465974513, "kendall": 0.3182406465974514}, "p_value": {"pearson": 5.610037829527872e-26, "spearman": 5.610037829531278e-26, "kendall": 9.343675148583504e-25}, "kappa_score": 0.20349167121863776, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.568185699762205, "spearman": 0.568185699762202, "kendall": 0.568185699762202}, "p_value": {"pearson": 3.267709219767884e-90, "spearman": 3.2677092197760975e-90, "kendall": 3.892176740213342e-75}, "kappa_score": 0.4984617611929495, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.595086364890007, "spearman": 0.5950863648899977, "kendall": 0.5950863648899977}, "p_value": {"pearson": 6.296246139538966e-101, "spearman": 6.296246139594386e-101, "kendall": 3.087989529291926e-82}, "kappa_score": 0.5387741636601013, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.5814268294550575, "spearman": 0.5814268294550574, "kendall": 0.5814268294550575}, "p_value": {"pearson": 2.3166954848263826e-95, "spearman": 2.3166954848267735e-95, "kendall": 1.3676160780325045e-78}, "kappa_score": 0.5240829883706113, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.5728366788009233, "spearman": 0.572836678800915, "kendall": 0.5728366788009152}, "p_value": {"pearson": 5.3977539354603114e-92, "spearman": 5.397753935499251e-92, "kendall": 2.4316470502721357e-76}, "kappa_score": 0.5100212439562815, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.21392448576766623, "spearman": 0.2139244857676678, "kendall": 0.2139244857676678}, "p_value": {"pearson": 2.9206528653848608e-12, "spearman": 2.9206528653837916e-12, "kendall": 5.003124287657627e-12}, "kappa_score": 0.10445934342973029, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.1543424156455085, "spearman": 0.15434241564550782, "kendall": 0.15434241564550782}, "p_value": {"pearson": 5.481864604369351e-07, "spearman": 5.48186460436974e-07, "kendall": 6.287288272341588e-07}, "kappa_score": 0.051411606940457655, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.36397866636641174, "spearman": 0.3639786663664119, "kendall": 0.36397866636641196}, "p_value": {"pearson": 5.054806433223082e-34, "spearman": 5.054806433222292e-34, "kendall": 7.125650958888076e-32}, "kappa_score": 0.24305573704578587, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.1716208779864087, "spearman": 0.17162087798640993, "kendall": 0.17162087798640993}, "p_value": {"pearson": 2.4418498553693143e-08, "spearman": 2.44184985536877e-08, "kendall": 3.025991496292213e-08}, "kappa_score": 0.06900418274231501, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.2330784159859556, "spearman": 0.23307841598595502, "kendall": 0.2330784159859551}, "p_value": {"pearson": 2.4670148157663068e-14, "spearman": 2.4670148157664548e-14, "kendall": 5.3216062295424176e-14}, "kappa_score": 0.12046458808846505, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.21666460226828, "spearman": 0.21666460226828135, "kendall": 0.21666460226828133}, "p_value": {"pearson": 1.5152661121257592e-12, "spearman": 1.5152661121251966e-12, "kendall": 2.672743168327768e-12}, "kappa_score": 0.10082573379851023, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.196010193052978, "spearman": 0.1960101930529778, "kendall": 0.19601019305297776}, "p_value": {"pearson": 1.7174492766972634e-10, "spearman": 1.7174492766973911e-10, "kendall": 2.4962723285944815e-10}, "kappa_score": 0.09053384625767702, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.5331161566860422, "spearman": 0.5331161566860485, "kendall": 0.5331161566860485}, "p_value": {"pearson": 1.2030095034272777e-77, "spearman": 1.2030095034212996e-77, "kendall": 2.2731252957254913e-66}, "kappa_score": 0.4426257524258018, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8965736042122375, "spearman": 0.8965736042122492, "kendall": 0.8965736042122492}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 3.5986509164183555e-184}, "kappa_score": 0.8959443227302294, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.42714901865856975, "spearman": 0.42714901865857113, "kendall": 0.42714901865857113}, "p_value": {"pearson": 1.6697533612648852e-47, "spearman": 1.6697533612635998e-47, "kendall": 2.9940438083113195e-43}, "kappa_score": 0.32267946636549727, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.08988633011664612, "spearman": 0.08988633011664665, "kendall": 0.08988633011664665}, "p_value": {"pearson": 0.003668699018139121, "spearman": 0.00366869901813879, "kendall": 0.0037134170801749935}, "kappa_score": 0.04280670099083839, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.41217098923207895, "spearman": 0.4121709892320835, "kendall": 0.41217098923208356}, "p_value": {"pearson": 4.869757457589724e-44, "spearman": 4.869757457578328e-44, "kendall": 2.1681271303032375e-40}, "kappa_score": 0.33851997758456953, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.22960840149752787, "spearman": 0.22960840149752765, "kendall": 0.22960840149752768}, "p_value": {"pearson": 6.052354320245645e-14, "spearman": 6.05235432024585e-14, "kendall": 1.2462956270437384e-13}, "kappa_score": 0.1461656279708462, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.21787992784081942, "spearman": 0.2178799278408198, "kendall": 0.21787992784081978}, "p_value": {"pearson": 1.1294186851443436e-12, "spearman": 1.1294186851442745e-12, "kendall": 2.0189389478426743e-12}, "kappa_score": 0.10062145044750381, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.184117395247067, "spearman": 0.1841173952470685, "kendall": 0.18411739524706852}, "p_value": {"pearson": 2.094321593533317e-09, "spearman": 2.0943215935326234e-09, "kendall": 2.7931651505085865e-09}, "kappa_score": 0.08017986026024249, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.12277450569118507, "spearman": 0.12277450569118441, "kendall": 0.12277450569118442}, "p_value": {"pearson": 7.02731547177747e-05, "spearman": 7.027315471778322e-05, "kendall": 7.396290794234057e-05}, "kappa_score": 0.037007565518728525, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.04040891291224498, "spearman": 0.04040891291224481, "kendall": 0.04040891291224482}, "p_value": {"pearson": 0.1922355625576051, "spearman": 0.1922355625576113, "kendall": 0.19209699315536277}, "kappa_score": 0.007331865183413333, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.11365938239046322, "spearman": 0.11365938239046326, "kendall": 0.11365938239046326}, "p_value": {"pearson": 0.00023487526717710244, "spearman": 0.00023487526717711488, "kendall": 0.00024356996237982664}, "kappa_score": 0.06691029182123232, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.07468991511675217, "spearman": 0.07468991511675283, "kendall": 0.0746899151167528}, "p_value": {"pearson": 0.015838019175036012, "spearman": 0.01583801917503495, "kendall": 0.01590918383354122}, "kappa_score": 0.017173662746279406, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.3187505664628933, "spearman": 0.3187505664628932, "kendall": 0.3187505664628931}, "p_value": {"pearson": 4.6405528673019203e-26, "spearman": 4.64055286730185e-26, "kendall": 7.8766228935459745e-25}, "kappa_score": 0.1990008706264328, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.10100756250779495, "spearman": 0.10100756250779569, "kendall": 0.1010075625077957}, "p_value": {"pearson": 0.0010887178486000473, "spearman": 0.0010887178485999474, "kendall": 0.0011120552760291581}, "kappa_score": 0.08683909836917003, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.06492148881281237, "spearman": 0.06492148881281225, "kendall": 0.06492148881281225}, "p_value": {"pearson": 0.03604935566024983, "spearman": 0.03604935566024927, "kendall": 0.03611171741644833}, "kappa_score": 0.04204066296497322, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.0634368510970219, "spearman": 0.0634368510970228, "kendall": 0.0634368510970228}, "p_value": {"pearson": 0.04052746573917827, "spearman": 0.04052746573917603, "kendall": 0.04058517579666746}, "kappa_score": 0.05736267640992765, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.17984001853100748, "spearman": 0.17984001853100764, "kendall": 0.17984001853100764}, "p_value": {"pearson": 4.951032518794609e-09, "spearman": 4.9510325187943066e-09, "kendall": 6.427377298042179e-09}, "kappa_score": 0.07362049714990881, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.284482266807894, "spearman": 0.2844822668078951, "kendall": 0.28448226680789507}, "p_value": {"pearson": 7.200296892942998e-21, "spearman": 7.200296892941088e-21, "kendall": 4.188769854870934e-20}, "kappa_score": 0.16129866027196615, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.11852704883316705, "spearman": 0.11852704883316834, "kendall": 0.11852704883316836}, "p_value": {"pearson": 0.00012463078784373885, "spearman": 0.00012463078784371754, "kendall": 0.0001302126413101852}, "kappa_score": 0.027708061439614573, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.6887578514681854, "spearman": 0.6887578514681791, "kendall": 0.688757851468179}, "p_value": {"pearson": 1.4491896157273116e-147, "spearman": 1.4491896157396116e-147, "kendall": 1.6430658057374886e-109}, "kappa_score": 0.6511908150940684, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.28223301097090014, "spearman": 0.2822330109709028, "kendall": 0.2822330109709028}, "p_value": {"pearson": 1.492859239892392e-20, "spearman": 1.4928592398911736e-20, "kendall": 8.20117921944297e-20}, "kappa_score": 0.15221755496154066, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.463265247138239, "spearman": 0.46326524713824396, "kendall": 0.4632652471382441}, "p_value": {"pearson": 1.307236118247922e-56, "spearman": 1.3072361182439004e-56, "kendall": 1.4619838723542777e-50}, "kappa_score": 0.38276527730041376, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.18482313343758683, "spearman": 0.18482313343758672, "kendall": 0.18482313343758672}, "p_value": {"pearson": 1.8135662547813939e-09, "spearman": 1.8135662547814969e-09, "kendall": 2.4299835073990253e-09}, "kappa_score": 0.0699008999368429, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.6186296199178519, "spearman": 0.6186296199178491, "kendall": 0.6186296199178494}, "p_value": {"pearson": 3.575759118873491e-111, "spearman": 3.5757591188845996e-111, "kendall": 1.0170909627651874e-88}, "kappa_score": 0.6172361217780165, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.726028857550548, "spearman": 0.7260288575505388, "kendall": 0.7260288575505388}, "p_value": {"pearson": 1.74042070798179e-171, "spearman": 1.7404207080074947e-171, "kendall": 1.8266477132496252e-121}, "kappa_score": 0.722925706189675, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.3165161006564393, "spearman": 0.3165161006564414, "kendall": 0.31651610065644137}, "p_value": {"pearson": 1.0627960035562807e-25, "spearman": 1.0627960035553471e-25, "kendall": 1.6615833473314985e-24}, "kappa_score": 0.18880114564601025, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.7702806424355007, "spearman": 0.7702806424355156, "kendall": 0.7702806424355156}, "p_value": {"pearson": 1.3045099306074967e-205, "spearman": 1.3045099305690335e-205, "kendall": 1.794291763751875e-136}, "kappa_score": 0.7701124090808904, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.1537565352070525, "spearman": 0.1537565352070513, "kendall": 0.1537565352070513}, "p_value": {"pearson": 6.057078373348466e-07, "spearman": 6.057078373349524e-07, "kendall": 6.931798349670403e-07}, "kappa_score": 0.049414040376756896, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.2872466325225984, "spearman": 0.28724663252259847, "kendall": 0.28724663252259847}, "p_value": {"pearson": 2.911956920446736e-21, "spearman": 2.911956920446433e-21, "kendall": 1.821258905859061e-20}, "kappa_score": 0.15611274262181385, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.22913359545063589, "spearman": 0.2291335954506375, "kendall": 0.2291335954506375}, "p_value": {"pearson": 6.835403351848089e-14, "spearman": 6.835403351845536e-14, "kendall": 1.3988592474289586e-13}, "kappa_score": 0.10592499106701225, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": -0.07139389578165302, "spearman": -0.07139389578165256, "kendall": -0.07139389578165256}, "p_value": {"pearson": 0.021117315160239722, "spearman": 0.02111731516024016, "kendall": 0.021189169556259522}, "kappa_score": -0.06083619251685013, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.06341145819078585, "spearman": 0.06341145819078607, "kendall": 0.06341145819078606}, "p_value": {"pearson": 0.040607980430430346, "spearman": 0.0406079804304294, "kendall": 0.04066560203042417}, "kappa_score": 0.06289941228129436, "total_responses": 1043, "valid_responses": 1022, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": -0.04693297693134058, "spearman": -0.046932976931341235, "kendall": -0.04693297693134122}, "p_value": {"pearson": 0.12983784512350077, "spearman": 0.1298378451234964, "kendall": 0.1297729970895283}, "kappa_score": -0.0338147895855343, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.04700926527970854, "spearman": 0.04700926527970796, "kendall": 0.047009265279707946}, "p_value": {"pearson": 0.1292145465624818, "spearman": 0.12921454656248363, "kendall": 0.1291505225758256}, "kappa_score": 0.04397232581208166, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.0319267648222174, "spearman": 0.03192676482221779, "kendall": 0.03192676482221779}, "p_value": {"pearson": 0.3029549153891295, "spearman": 0.3029549153891416, "kendall": 0.30272995623628307}, "kappa_score": 0.030902646340204343, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.17280615512902456, "spearman": 0.17280615512902403, "kendall": 0.17280615512902403}, "p_value": {"pearson": 1.9489229159609714e-08, "spearman": 1.9489229159612063e-08, "kendall": 2.430383497738701e-08}, "kappa_score": 0.1721792408743963, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.0973211674436758, "spearman": 0.09732116744367571, "kendall": 0.09732116744367571}, "p_value": {"pearson": 0.0016510159547484192, "spearman": 0.001651015954748381, "kendall": 0.001680677635560967}, "kappa_score": 0.07645951359576353, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.14453286233456508, "spearman": 0.14453286233456586, "kendall": 0.14453286233456586}, "p_value": {"pearson": 2.7751721071431565e-06, "spearman": 2.775172107142771e-06, "kendall": 3.0783099558612403e-06}, "kappa_score": 0.13774047234242226, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.07523161522008884, "spearman": 0.07523161522008806, "kendall": 0.07523161522008807}, "p_value": {"pearson": 0.015091554421875406, "spearman": 0.015091554421877469, "kendall": 0.015162328095200376}, "kappa_score": 0.07515624776533503, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.1437567762443619, "spearman": 0.1437567762443624, "kendall": 0.1437567762443624}, "p_value": {"pearson": 3.1412218197981936e-06, "spearman": 3.141221819798072e-06, "kendall": 3.476137720259705e-06}, "kappa_score": 0.13071773728775982, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": -0.013266396012878268, "spearman": -0.013266396012878157, "kendall": -0.013266396012878158}, "p_value": {"pearson": 0.6686874477198587, "spearman": 0.6686874477198621, "kendall": 0.6684766939373251}, "kappa_score": -0.011509095292951521, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.2901411490046676, "spearman": 0.2901411490046672, "kendall": 0.2901411490046672}, "p_value": {"pearson": 1.1163158475844465e-21, "spearman": 1.1163158475844892e-21, "kendall": 7.550242764330272e-21}, "kappa_score": 0.2901317800190568, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.11720287142992544, "spearman": 0.11720287142992593, "kendall": 0.1172028714299259}, "p_value": {"pearson": 0.0001484373423074843, "spearman": 0.00014843734230747413, "kendall": 0.00015475547763882814}, "kappa_score": 0.10938792297960032, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.4950431779264538, "spearman": 0.4950431779264544, "kendall": 0.49504317792645436}, "p_value": {"pearson": 1.4070104018268179e-65, "spearman": 1.4070104018263251e-65, "kendall": 1.7612882500615032e-57}, "kappa_score": 0.4381224058406743, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.350606892883661, "spearman": 0.3506068928836607, "kendall": 0.3506068928836607}, "p_value": {"pearson": 1.5701361294875775e-31, "spearman": 1.5701361294878519e-31, "kendall": 1.0737222355545357e-29}, "kappa_score": 0.34713731638401557, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.01136339085500784, "spearman": 0.011363390855007758, "kendall": 0.011363390855007758}, "p_value": {"pearson": 0.7139485329128473, "spearman": 0.7139485329128514, "kendall": 0.7137603462498017}, "kappa_score": 0.008752807943322782, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.013442329132629103, "spearman": 0.01344232913262896, "kendall": 0.01344232913262896}, "p_value": {"pearson": 0.6645601239246262, "spearman": 0.6645601239246308, "kendall": 0.664347467079508}, "kappa_score": 0.004194087359770893, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.026512964569659393, "spearman": 0.026512964569659125, "kendall": 0.02651296456965913}, "p_value": {"pearson": 0.39234450052745407, "spearman": 0.3923445005274674, "kendall": 0.3920867549147997}, "kappa_score": 0.01702071513392267, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.17275995650364778, "spearman": 0.17275995650364573, "kendall": 0.17275995650364576}, "p_value": {"pearson": 1.9661839649210486e-08, "spearman": 1.9661839649217722e-08, "kendall": 2.4513014907203548e-08}, "kappa_score": 0.1035668242372152, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.37430828541661165, "spearman": 0.37430828541661054, "kendall": 0.37430828541661054}, "p_value": {"pearson": 4.963179229005508e-36, "spearman": 4.963179229008204e-36, "kendall": 1.3039793292482362e-33}, "kappa_score": 0.24577821259943, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.4021013784779135, "spearman": 0.4021013784779168, "kendall": 0.4021013784779168}, "p_value": {"pearson": 8.317046370784216e-42, "spearman": 8.317046370770237e-42, "kendall": 1.5920770413902888e-38}, "kappa_score": 0.3965255377316188, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.01910275953995727, "spearman": 0.019102759539957444, "kendall": 0.019102759539957447}, "p_value": {"pearson": 0.5377296516972251, "spearman": 0.5377296516972235, "kendall": 0.5374738201759186}, "kappa_score": 0.018352941176470683, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.12177229793279101, "spearman": 0.12177229793279043, "kendall": 0.12177229793279044}, "p_value": {"pearson": 8.058165996851454e-05, "spearman": 8.058165996852522e-05, "kendall": 8.465917308525653e-05}, "kappa_score": 0.10632497273718644, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.3773071958537035, "spearman": 0.37730719585370254, "kendall": 0.37730719585370254}, "p_value": {"pearson": 1.256085873536055e-36, "spearman": 1.2560858735367187e-36, "kendall": 3.997952540417608e-34}, "kappa_score": 0.35914834504314375, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.2360630446504129, "spearman": 0.23606304465041789, "kendall": 0.2360630446504179}, "p_value": {"pearson": 1.126872624766928e-14, "spearman": 1.1268726247654483e-14, "kendall": 2.534381664681035e-14}, "kappa_score": 0.21250854955187026, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.42610087740419017, "spearman": 0.4261008774041864, "kendall": 0.42610087740418645}, "p_value": {"pearson": 2.9570168002316524e-47, "spearman": 2.9570168002377136e-47, "kendall": 4.782677577845216e-43}, "kappa_score": 0.3891708667565841, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.07952704883852316, "spearman": 0.07952704883852281, "kendall": 0.07952704883852281}, "p_value": {"pearson": 0.010188737526250692, "spearman": 0.01018873752625136, "kendall": 0.010254264973476633}, "kappa_score": 0.04100041892678563, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.1932196577008588, "spearman": 0.1932196577008581, "kendall": 0.19321965770085817}, "p_value": {"pearson": 3.133439236550677e-10, "spearman": 3.133439236550862e-10, "kendall": 4.4565640808026825e-10}, "kappa_score": 0.1849174562860213, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.08075324785787995, "spearman": 0.08075324785788077, "kendall": 0.08075324785788075}, "p_value": {"pearson": 0.009078015575873476, "spearman": 0.009078015575872503, "kendall": 0.009141492148747505}, "kappa_score": 0.0765886596984553, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.10304905380766971, "spearman": 0.10304905380766925, "kendall": 0.10304905380766927}, "p_value": {"pearson": 0.0008594351751244825, "spearman": 0.0008594351751245324, "kendall": 0.0008796737037827791}, "kappa_score": 0.03104331621222778, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.06304522558336959, "spearman": 0.0630452255833703, "kendall": 0.0630452255833703}, "p_value": {"pearson": 0.04178435477447095, "spearman": 0.041784354774467354, "kendall": 0.04184066670564902}, "kappa_score": 0.023293711153080765, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.17628965458026635, "spearman": 0.1762896545802635, "kendall": 0.17628965458026352}, "p_value": {"pearson": 9.955677505339009e-09, "spearman": 9.955677505344265e-09, "kendall": 1.265682299976964e-08}, "kappa_score": 0.1517494071619967, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.576625080301602, "spearman": 0.5766250803016022, "kendall": 0.5766250803016023}, "p_value": {"pearson": 1.817447753843358e-93, "spearman": 1.8174477538429604e-93, "kendall": 2.4988775271379852e-77}, "kappa_score": 0.5765575398281166, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.5117312253031334, "spearman": 0.5117312253031371, "kendall": 0.5117312253031371}, "p_value": {"pearson": 1.1127758827699532e-70, "spearman": 1.1127758827669678e-70, "kendall": 2.6915181179727596e-61}, "kappa_score": 0.489471160569796, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.2278891905593334, "spearman": 0.22788919055933413, "kendall": 0.22788919055933413}, "p_value": {"pearson": 9.390563262664686e-14, "spearman": 9.390563262663391e-14, "kendall": 1.8912211358495619e-13}, "kappa_score": 0.2276653212345605, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.26789914463866127, "spearman": 0.2678991446386666, "kendall": 0.2678991446386666}, "p_value": {"pearson": 1.3324864240104525e-18, "spearman": 1.3324864240083267e-18, "kendall": 5.2505866821655514e-18}, "kappa_score": 0.22621697197968382, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.20777543897179623, "spearman": 0.20777543897179754, "kendall": 0.20777543897179754}, "p_value": {"pearson": 1.2333525309760342e-11, "spearman": 1.2333525309756436e-11, "kendall": 1.986712720433568e-11}, "kappa_score": 0.12180149764629378, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.06281462838008083, "spearman": 0.06281462838008066, "kendall": 0.06281462838008066}, "p_value": {"pearson": 0.042539734824639, "spearman": 0.04253973482463937, "kendall": 0.04259518944156445}, "kappa_score": 0.024383575048856354, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.07150899235112335, "spearman": 0.07150899235112292, "kendall": 0.0715089923511229}, "p_value": {"pearson": 0.020909902616336656, "spearman": 0.020909902616337687, "kendall": 0.020981786968399637}, "kappa_score": 0.0477415713550573, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.08997079845816396, "spearman": 0.08997079845816547, "kendall": 0.08997079845816548}, "p_value": {"pearson": 0.0036366917452247175, "spearman": 0.0036366917452241637, "kendall": 0.0036812278171940048}, "kappa_score": 0.07635540686805087, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.09630409989820281, "spearman": 0.09630409989820303, "kendall": 0.09630409989820304}, "p_value": {"pearson": 0.001847570859004188, "spearman": 0.0018475708590041543, "kendall": 0.0018791322234248944}, "kappa_score": 0.08545112528385035, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.08569643541006994, "spearman": 0.08569643541006972, "kendall": 0.08569643541006972}, "p_value": {"pearson": 0.005616183585175147, "spearman": 0.005616183585175403, "kendall": 0.005669929614153498}, "kappa_score": 0.033017722748239664, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.05701015004777156, "spearman": 0.05701015004777156, "kendall": 0.057010150047771546}, "p_value": {"pearson": 0.06570057199300351, "spearman": 0.06570057199300562, "kendall": 0.06572581117965415}, "kappa_score": 0.050695829737466336, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.08369521428072277, "spearman": 0.08369521428072288, "kendall": 0.08369521428072288}, "p_value": {"pearson": 0.006841041933545775, "spearman": 0.0068410419335458526, "kendall": 0.006898938065748021}, "kappa_score": 0.04475403772654407, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.04796988719163659, "spearman": 0.047969887191636744, "kendall": 0.04796988719163674}, "p_value": {"pearson": 0.1215631680033956, "spearman": 0.1215631680033906, "kendall": 0.12150938431463898}, "kappa_score": 0.040005508004725354, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.12576160745052523, "spearman": 0.12576160745052717, "kendall": 0.12576160745052717}, "p_value": {"pearson": 4.6442283412763554e-05, "spearman": 4.644228341275086e-05, "kendall": 4.915941964095799e-05}, "kappa_score": 0.07025498294128207, "total_responses": 1043, "valid_responses": 1025, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.02615544562023088, "spearman": 0.026155445620230793, "kendall": 0.026155445620230793}, "p_value": {"pearson": 0.3987616585411146, "spearman": 0.39876165854112755, "kendall": 0.3985026616219063}, "kappa_score": 0.0225120565437259, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.18777385764430352, "spearman": 0.1877738576443063, "kendall": 0.18777385764430632}, "p_value": {"pearson": 9.874817474750464e-10, "spearman": 9.874817474744407e-10, "kendall": 1.3498812088563334e-09}, "kappa_score": 0.18271684314158854, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.057577870024939956, "spearman": 0.05757787002494048, "kendall": 0.057577870024940477}, "p_value": {"pearson": 0.06305277962758987, "spearman": 0.0630527796275873, "kendall": 0.06308171927716573}, "kappa_score": 0.05702908341036761, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": -0.015387405871574432, "spearman": -0.015387405871574632, "kendall": -0.015387405871574633}, "p_value": {"pearson": 0.6196280150885753, "spearman": 0.6196280150885691, "kendall": 0.6193965015181959}, "kappa_score": -0.012344142754038057, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.09593087247376714, "spearman": 0.09593087247376957, "kendall": 0.09593087247376955}, "p_value": {"pearson": 0.0019249279744237946, "spearman": 0.001924927974423227, "kendall": 0.0019572019073494052}, "kappa_score": 0.07613368764447892, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.4468916976078797, "spearman": 0.4468916976078795, "kendall": 0.4468916976078794}, "p_value": {"pearson": 2.40382827245846e-52, "spearman": 2.4038282724588948e-52, "kendall": 3.5676201942447825e-47}, "kappa_score": 0.38945560279059943, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.17280920861596663, "spearman": 0.17280920861597138, "kendall": 0.17280920861597138}, "p_value": {"pearson": 1.94778724187474e-08, "spearman": 1.9477872418729142e-08, "kendall": 2.4290070486146414e-08}, "kappa_score": 0.17249824650162704, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.25256864668641854, "spearman": 0.2525686466864218, "kendall": 0.2525686466864218}, "p_value": {"pearson": 1.2144746376444093e-16, "spearman": 1.2144746376431725e-16, "kendall": 3.5523423373472473e-16}, "kappa_score": 0.19537538316595782, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.1307809048047513, "spearman": 0.13078090480475033, "kendall": 0.13078090480475035}, "p_value": {"pearson": 2.267479340136662e-05, "spearman": 2.2674793401369235e-05, "kendall": 2.4256261877032696e-05}, "kappa_score": 0.10019135342003704, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.23365007581923553, "spearman": 0.23365007581923877, "kendall": 0.23365007581923875}, "p_value": {"pearson": 2.124987504098387e-14, "spearman": 2.1249875040966006e-14, "kendall": 4.620011256196738e-14}, "kappa_score": 0.16103399105434413, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": -0.02576814094443171, "spearman": -0.02576814094443119, "kendall": -0.025768140944431195}, "p_value": {"pearson": 0.4057841829553445, "spearman": 0.40578418295535434, "kendall": 0.40552397320622324}, "kappa_score": -0.023983169705469765, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.23337784706339407, "spearman": 0.23337784706339593, "kendall": 0.2333778470633959}, "p_value": {"pearson": 2.2816204099998302e-14, "spearman": 2.2816204099987725e-14, "kendall": 4.941970940384571e-14}, "kappa_score": 0.15930080024444582, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.33679938664992704, "spearman": 0.3367993866499374, "kendall": 0.3367993866499374}, "p_value": {"pearson": 4.427927959691011e-29, "spearman": 4.427927959672537e-29, "kendall": 1.5691170872938194e-27}, "kappa_score": 0.33673135104927443, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.05478112737370703, "spearman": 0.05478112737370699, "kendall": 0.05478112737370699}, "p_value": {"pearson": 0.07699556169974238, "spearman": 0.07699556169974138, "kendall": 0.07700472399729011}, "kappa_score": 0.054397098821396206, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.02070255611573951, "spearman": 0.020702556115739793, "kendall": 0.020702556115739797}, "p_value": {"pearson": 0.5042169240522715, "spearman": 0.5042169240522665, "kendall": 0.5039555000050624}, "kappa_score": 0.019807706209788223, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.13986875540093688, "spearman": 0.1398687554009382, "kendall": 0.1398687554009382}, "p_value": {"pearson": 5.787127973014606e-06, "spearman": 5.787127973013177e-06, "kendall": 6.332665879308884e-06}, "kappa_score": 0.11871567384875381, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}}