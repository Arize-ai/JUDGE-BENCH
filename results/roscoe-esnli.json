{"Meta-Llama-3-8B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": -0.1317658691861765, "spearman": -0.17066044213206066, "kendall": -0.1592126829604352}, "p_value": {"pearson": 0.10679861654044388, "spearman": 0.03616397657679813, "kendall": 0.03660387725587901}, "kappa_score": -0.05904106095383832, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": -0.0011754590711477511, "spearman": 0.04011177211996582, "kendall": 0.0395972758011341}, "p_value": {"pearson": 0.9885712869271932, "spearman": 0.6248398209993535, "kendall": 0.6232377073921275}, "kappa_score": -0.005649458019474363, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.05951859734163208, "spearman": -0.05951859734163198, "kendall": -0.05951859734163198}, "p_value": {"pearson": 0.4678736869770201, "spearman": 0.46787368697702003, "kendall": 0.46603165565148763}, "kappa_score": -0.008377853326857698, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.15872266067121432, "spearman": 0.15872266067121454, "kendall": 0.15872266067121454}, "p_value": {"pearson": 0.05158665346595906, "spearman": 0.05158665346595854, "kendall": 0.051901764749889306}, "kappa_score": 0.0491475963753647, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.2 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4336695787255016, "spearman": 0.3965509275280291, "kendall": 0.36370125254593294}, "p_value": {"pearson": 2.6605899061109772e-08, "spearman": 4.640045335113776e-07, "kendall": 1.349920703923755e-06}, "kappa_score": 0.10983873153543844, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.07603049175998744, "spearman": 0.07213135825263699, "kendall": 0.07041344856305182}, "p_value": {"pearson": 0.3534809725091352, "spearman": 0.37877989765768005, "kendall": 0.37653443536329545}, "kappa_score": 0.042496384469907666, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.10915645981396235, "spearman": 0.10915645981396226, "kendall": 0.10915645981396227}, "p_value": {"pearson": 0.18214452824671976, "spearman": 0.18214452824671945, "kendall": 0.18125915161008377}, "kappa_score": 0.10313943622136312, "total_responses": 151, "valid_responses": 150, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.22440289220036996, "spearman": 0.22440289220037005, "kendall": 0.22440289220037005}, "p_value": {"pearson": 0.005605409679088961, "spearman": 0.005605409679088972, "kendall": 0.0059893674755257115}, "kappa_score": 0.12634870992963265, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.1075972778529576, "spearman": 0.15657950320110525, "kendall": 0.14546769184468825}, "p_value": {"pearson": 0.1885060559063298, "spearman": 0.054863949301434574, "kendall": 0.05465506969782662}, "kappa_score": -0.011683277962347693, "total_responses": 151, "valid_responses": 150, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.07475443250860075, "spearman": 0.0650699907791702, "kendall": 0.06186199840361567}, "p_value": {"pearson": 0.3616415203613183, "spearman": 0.42731730892444264, "kendall": 0.4251864067995972}, "kappa_score": -0.002804014167650637, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.052814983861483866, "spearman": 0.052814983861483804, "kendall": 0.052814983861483804}, "p_value": {"pearson": 0.5195378141024335, "spearman": 0.519537814102434, "kendall": 0.5177298013058682}, "kappa_score": 0.05252149663025796, "total_responses": 151, "valid_responses": 126, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.127440322688417, "spearman": -0.127440322688417, "kendall": -0.127440322688417}, "p_value": {"pearson": 0.11891007141321577, "spearman": 0.11891007141321636, "kendall": 0.11856650652402555}, "kappa_score": -0.04205569538036835, "total_responses": 151, "valid_responses": 55, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.48497372200403577, "spearman": 0.42699803109515244, "kendall": 0.39094653516118405}, "p_value": {"pearson": 2.7818663292137055e-10, "spearman": 4.563480965801946e-08, "kendall": 1.5864165838120729e-07}, "kappa_score": 0.10332541567695952, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.08580196785636852, "spearman": 0.12763836765040804, "kendall": 0.12340312851062346}, "p_value": {"pearson": 0.29485802047268417, "spearman": 0.11833321351122783, "kendall": 0.11547363811259902}, "kappa_score": 0.06638962092033229, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.04984825458176529, "spearman": -0.0498482545817653, "kendall": -0.04984825458176529}, "p_value": {"pearson": 0.5432979063313643, "spearman": 0.5432979063313649, "kendall": 0.5415214110234945}, "kappa_score": -0.013099041533546352, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3-70B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5828277376587799, "spearman": 0.5221855223302713, "kendall": 0.4773969205543263}, "p_value": {"pearson": 4.120600317245302e-15, "spearman": 6.1388000653928914e-12, "kendall": 6.191340028730328e-11}, "kappa_score": 0.25531914893617014, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.2731558251769095, "spearman": 0.2312971733655838, "kendall": 0.22328685059809078}, "p_value": {"pearson": 0.0006901210892592407, "spearman": 0.004270439641559838, "kendall": 0.00434164096151458}, "kappa_score": 0.1784836784836783, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.4656614523091296, "spearman": 0.46566145230912903, "kendall": 0.465661452309129}, "p_value": {"pearson": 1.6925791254331057e-09, "spearman": 1.6925791254332062e-09, "kendall": 1.1760321100605282e-08}, "kappa_score": 0.41544958648601094, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.292634131667217, "spearman": 0.29263413166721697, "kendall": 0.292634131667217}, "p_value": {"pearson": 0.00026612980355846135, "spearman": 0.00026612980355846053, "kendall": 0.00033834419118749175}, "kappa_score": 0.1973208590261536, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.09208602734991093, "spearman": 0.07323788721173843, "kendall": 0.06747773805568917}, "p_value": {"pearson": 0.26077548956591373, "spearman": 0.371490678430473, "kendall": 0.3641178472394525}, "kappa_score": 0.01976659372720646, "total_responses": 151, "valid_responses": 149, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": -0.08525022908992957, "spearman": -0.09954156688445889, "kendall": -0.09141404566334563}, "p_value": {"pearson": 0.29798546460526826, "spearman": 0.22396760639011729, "kendall": 0.22030711502514078}, "kappa_score": -0.030499620861066612, "total_responses": 151, "valid_responses": 137, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.018758148487225713, "spearman": 0.018758148487225693, "kendall": 0.01875814848722569}, "p_value": {"pearson": 0.8191731014296638, "spearman": 0.8191731014296635, "kendall": 0.8182942290386039}, "kappa_score": 0.017724144432921585, "total_responses": 151, "valid_responses": 144, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.15026696099429476, "spearman": 0.15026696099429487, "kendall": 0.15026696099429485}, "p_value": {"pearson": 0.06552807043841252, "spearman": 0.06552807043841233, "kendall": 0.0657114556099437}, "kappa_score": 0.04416310908287946, "total_responses": 151, "valid_responses": 148, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.44489197428962846, "spearman": 0.3998042638459157, "kendall": 0.3595724401739402}, "p_value": {"pearson": 1.0453319138053065e-08, "spearman": 3.6610752774609184e-07, "kendall": 1.3369914765803451e-06}, "kappa_score": 0.09796893667861417, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.306223069951403, "spearman": 0.27606147294609856, "kendall": 0.26179109876987955}, "p_value": {"pearson": 0.00013133458786140985, "spearman": 0.0006012871103234644, "kendall": 0.0007863867326335994}, "kappa_score": 0.10234575835475568, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.03240543852046967, "spearman": -0.032405438520469704, "kendall": -0.032405438520469704}, "p_value": {"pearson": 0.6928432952009275, "spearman": 0.692843295200928, "kendall": 0.6914530430299879}, "kappa_score": -0.027040477770404747, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.21552462474039702, "spearman": 0.21552462474039705, "kendall": 0.21552462474039707}, "p_value": {"pearson": 0.007867295263720712, "spearman": 0.007867295263720774, "kendall": 0.008299737123616247}, "kappa_score": 0.11801707353601909, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6908637073067024, "spearman": 0.6572185654014067, "kendall": 0.5695575449732126}, "p_value": {"pearson": 9.602756274569836e-23, "spearman": 4.963480940329275e-20, "kendall": 1.6767279655716608e-16}, "kappa_score": 0.1611111111111111, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3144486348435638, "spearman": 0.3151723663461358, "kendall": 0.3030398440848849}, "p_value": {"pearson": 8.420071872544389e-05, "spearman": 8.092026420805657e-05, "kendall": 0.00012114805020352}, "kappa_score": 0.1629711751662971, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.4209045370710484, "spearman": 0.4209045370710478, "kendall": 0.4209045370710478}, "p_value": {"pearson": 7.394954475085697e-08, "spearman": 7.394954475086134e-08, "kendall": 2.53621818525025e-07}, "kappa_score": 0.3293147208121826, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.33356350314644434, "spearman": 0.33356350314644456, "kendall": 0.3335635031464446}, "p_value": {"pearson": 2.8473433176908663e-05, "spearman": 2.8473433176908304e-05, "kendall": 4.4019543954016934e-05}, "kappa_score": 0.24462231115557775, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4520522193850887, "spearman": 0.4015848454280884, "kendall": 0.36931386655246623}, "p_value": {"pearson": 5.657332336295416e-09, "spearman": 3.2123069045603654e-07, "kendall": 9.087687334095193e-07}, "kappa_score": 0.09505386132605076, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.17983331540809233, "spearman": 0.22836304147862413, "kendall": 0.22097979179351845}, "p_value": {"pearson": 0.027139128594152892, "spearman": 0.004799106782856009, "kendall": 0.005339348230718041}, "kappa_score": 0.09651404786680551, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.02197370229467554, "spearman": 0.02197370229467553, "kendall": 0.02197370229467553}, "p_value": {"pearson": 0.788848720797765, "spearman": 0.7888487207977658, "kendall": 0.7878359613475221}, "kappa_score": 0.018735758291838933, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.17260273972602697, "spearman": 0.17260273972602735, "kendall": 0.1726027397260274}, "p_value": {"pearson": 0.034066347723831124, "spearman": 0.0340663477238307, "kendall": 0.03452011868332339}, "kappa_score": 0.17260273972602747, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5455835392410747, "spearman": 0.49499853348386835, "kendall": 0.43990950422188535}, "p_value": {"pearson": 4.354427848278345e-13, "spearman": 1.0413524104812475e-10, "kendall": 4.382453335932003e-10}, "kappa_score": -0.0014417531718571297, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.24011505903459593, "spearman": 0.2031675225262975, "kendall": 0.18939074967926733}, "p_value": {"pearson": 0.002981535104119835, "spearman": 0.012350468298032713, "kendall": 0.013630538270685307}, "kappa_score": 0.008752735229759168, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.12649497541743226, "spearman": -0.12649497541743251, "kendall": -0.12649497541743251}, "p_value": {"pearson": 0.1216937591819525, "spearman": 0.12169375918195198, "kendall": 0.12132386317541934}, "kappa_score": -0.021825275864171045, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.28537079737790827, "spearman": 0.2853707973779085, "kendall": 0.28537079737790844}, "p_value": {"pearson": 0.00038274731860743846, "spearman": 0.00038274731860743385, "kendall": 0.0004739477294111772}, "kappa_score": 0.2335025380710659, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5690065524144399, "spearman": 0.5076762992969556, "kendall": 0.47025132625756383}, "p_value": {"pearson": 2.487683088380388e-14, "spearman": 2.8690618071397327e-11, "kendall": 2.8711082370139076e-10}, "kappa_score": 0.12271503471730216, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.27221045338744576, "spearman": 0.2604800134850941, "kendall": 0.25039635676841343}, "p_value": {"pearson": 0.000721530843682306, "spearman": 0.0012371138448887234, "kendall": 0.0013862742690287017}, "kappa_score": 0.1596622529265016, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.05186585586671168, "spearman": 0.051865855866711615, "kendall": 0.051865855866711615}, "p_value": {"pearson": 0.5270811010075467, "spearman": 0.5270811010075465, "kendall": 0.5252820653767516}, "kappa_score": 0.04422314119334969, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.31587758314269754, "spearman": 0.3158775831426982, "kendall": 0.3158775831426981}, "p_value": {"pearson": 7.783908480522115e-05, "spearman": 7.783908480521855e-05, "kendall": 0.00010941963464904355}, "kappa_score": 0.2238317757009345, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.2286414707999312, "spearman": 0.1452644033499861, "kendall": 0.12317669343565388}, "p_value": {"pearson": 0.004746535147437677, "spearman": 0.07513201060056703, "kendall": 0.08203883528515825}, "kappa_score": 0.03532506576475014, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.05374136515599837, "spearman": 0.025621257032295987, "kendall": 0.024534601959975155}, "p_value": {"pearson": 0.5122288585567205, "spearman": 0.7548320807046629, "kendall": 0.7521107702145193}, "kappa_score": 0.010792723159581574, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.1897694407994068, "spearman": 0.18976944079940627, "kendall": 0.18976944079940627}, "p_value": {"pearson": 0.01960639209924237, "spearman": 0.01960639209924275, "kendall": 0.020115233014989662}, "kappa_score": 0.06952125138252496, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}