{"Mistral-7B-Instruct-v0.2 (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.5373573985287362, "spearman": 0.5373573985287485, "kendall": 0.5373573985287484}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 0.0}, "kappa_score": 0.49991918348263, "total_responses": 5654, "valid_responses": 5624, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.32192317603476905, "spearman": 0.3219231760347766, "kendall": 0.32192317603477655}, "p_value": {"pearson": 1.7391937134187434e-136, "spearman": 1.739193713391717e-136, "kendall": 2.0066262339258678e-129}, "kappa_score": 0.3060833809193294, "total_responses": 5654, "valid_responses": 5651, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.3550559564545347, "spearman": 0.3550559564545124, "kendall": 0.3550559564545123}, "p_value": {"pearson": 1.2456528372218993e-167, "spearman": 1.2456528372856528e-167, "kendall": 5.3239385498506195e-157}, "kappa_score": 0.3443338376037215, "total_responses": 5654, "valid_responses": 4738, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.09409391673111742, "spearman": 0.0940939167311132, "kendall": 0.0940939167311132}, "p_value": {"pearson": 1.3471396845994733e-12, "spearman": 1.3471396846025803e-12, "kendall": 1.4989542274659266e-12}, "kappa_score": 0.05142428626239515, "total_responses": 5654, "valid_responses": 5602, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.5317234620743982, "spearman": 0.5317234620743703, "kendall": 0.5317234620743703}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 0.0}, "kappa_score": 0.5286945508100147, "total_responses": 5654, "valid_responses": 5618, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.1261272539547136, "spearman": 0.12612725395470903, "kendall": 0.12612725395470906}, "p_value": {"pearson": 1.7344806272393256e-21, "spearman": 1.7344806272451903e-21, "kendall": 2.4693678365204014e-21}, "kappa_score": 0.038245510020886275, "total_responses": 5654, "valid_responses": 5590, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.6920010028357961, "spearman": 0.6920010028357911, "kendall": 0.6920010028357911}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 0.0}, "kappa_score": 0.6919976874080904, "total_responses": 5654, "valid_responses": 5583, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.3141227704094022, "spearman": 0.3141227704094091, "kendall": 0.3141227704094091}, "p_value": {"pearson": 1.0604093537535686e-129, "spearman": 1.0604093537393373e-129, "kendall": 2.53154960473904e-123}, "kappa_score": 0.20108979240524116, "total_responses": 5654, "valid_responses": 5579, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.6545290798929333, "spearman": 0.6545290798928866, "kendall": 0.6545290798928866}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 0.0}, "kappa_score": 0.64529539977943, "total_responses": 5654, "valid_responses": 5651, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.37953635718472606, "spearman": 0.3795363571847244, "kendall": 0.37953635718472445}, "p_value": {"pearson": 3.5348170367915377e-193, "spearman": 3.534817036806945e-193, "kendall": 4.192562537490454e-179}, "kappa_score": 0.2564949271997795, "total_responses": 5654, "valid_responses": 5654, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "OLMo-7B-Instruct (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.027553128317510237, "spearman": 0.027553128317507867, "kendall": 0.027553128317507863}, "p_value": {"pearson": 0.03828970197708004, "spearman": 0.038289701977097336, "kendall": 0.03830075421572034}, "kappa_score": 0.023973075925819542, "total_responses": 5654, "valid_responses": 2793, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": -0.04795245807281874, "spearman": -0.0479524580728172, "kendall": -0.0479524580728172}, "p_value": {"pearson": 0.0003097923474475287, "spearman": 0.00030979234744766214, "kendall": 0.00031170325579584835}, "kappa_score": -0.024202391491984887, "total_responses": 5654, "valid_responses": 3171, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.4495941478920249, "spearman": 0.4495941478919826, "kendall": 0.44959414789198254}, "p_value": {"pearson": 1.6802672120622152e-279, "spearman": 1.6802672122881941e-279, "kendall": 1.7590240562379818e-250}, "kappa_score": 0.4488599639630614, "total_responses": 5654, "valid_responses": 5201, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.3625804828431093, "spearman": 0.36258048284309696, "kendall": 0.36258048284309696}, "p_value": {"pearson": 3.0160852222141865e-175, "spearman": 3.016085222301962e-175, "kendall": 1.2263782475333452e-163}, "kappa_score": 0.27566932259953847, "total_responses": 5654, "valid_responses": 5649, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "Meta-Llama-3-70B-Instruct (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.5401028038882125, "spearman": 0.5401028038881548, "kendall": 0.5401028038881549}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 0.0}, "kappa_score": 0.4980444090732682, "total_responses": 5654, "valid_responses": 5643, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.4003731990594469, "spearman": 0.40037319905943375, "kendall": 0.40037319905943386}, "p_value": {"pearson": 9.993382036786606e-217, "spearman": 9.993382037140468e-217, "kendall": 4.475676858151673e-199}, "kappa_score": 0.3109795940948926, "total_responses": 5654, "valid_responses": 5632, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "gpt-4o (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.7395797744023942, "spearman": 0.7395797744024001, "kendall": 0.7395797744024}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 0.0}, "kappa_score": 0.7387577364876226, "total_responses": 5654, "valid_responses": 5647, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.36192074500922666, "spearman": 0.36192074500921584, "kendall": 0.36192074500921584}, "p_value": {"pearson": 1.4304585443434947e-174, "spearman": 1.4304585443801599e-174, "kendall": 4.744066053119717e-163}, "kappa_score": 0.23500887531349568, "total_responses": 5654, "valid_responses": 5654, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.4694817621131784, "spearman": 0.46948176211314946, "kendall": 0.46948176211314946}, "p_value": {"pearson": 5.795087202365482e-308, "spearman": 5.79508720293617e-308, "kendall": 6.157035274055427e-273}, "kappa_score": 0.4476953300301513, "total_responses": 5654, "valid_responses": 4971, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.18829031205729402, "spearman": 0.18829031205729443, "kendall": 0.18829031205729443}, "p_value": {"pearson": 2.795968575696913e-46, "spearman": 2.7959685756958978e-46, "kendall": 1.6935400498088967e-45}, "kappa_score": 0.08375751657157382, "total_responses": 5654, "valid_responses": 4796, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}, "Meta-Llama-3-8B-Instruct (SP: None, AP: 1)": {"toxicity": {"corr_coeff": {"pearson": 0.5963631427808845, "spearman": 0.5963631427808656, "kendall": 0.5963631427808656}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 0.0}, "kappa_score": 0.5861675409492371, "total_responses": 5654, "valid_responses": 5590, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}, "jailbreaking": {"corr_coeff": {"pearson": 0.31216991282579526, "spearman": 0.3121699128257995, "kendall": 0.3121699128257995}, "p_value": {"pearson": 4.925572392439526e-128, "spearman": 4.925572392400895e-128, "kendall": 8.080394908933325e-122}, "kappa_score": 0.21062240066357052, "total_responses": 5654, "valid_responses": 5615, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Toxicity \\ Safety"}}}