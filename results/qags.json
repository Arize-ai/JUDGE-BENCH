{"Meta-Llama-3-8B-Instruct (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.5565332513564312, "spearman": 0.5565332513564306, "kendall": 0.5565332513564306}, "p_value": {"pearson": 1.3182267532345585e-78, "spearman": 1.3182267532351443e-78, "kendall": 4.336553036125883e-66}, "kappa_score": 0.5188941590537661, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Mistral-7B-Instruct-v0.2 (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.31759524725016497, "spearman": 0.31759524725016636, "kendall": 0.3175952472501664}, "p_value": {"pearson": 8.917267071463228e-24, "spearman": 8.917267071459719e-24, "kendall": 1.1343401800141425e-22}, "kappa_score": 0.20822039090643718, "total_responses": 953, "valid_responses": 935, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.02129255898554531, "spearman": 0.02129255898554536, "kendall": 0.021292558985545364}, "p_value": {"pearson": 0.5114845213344005, "spearman": 0.5114845213343966, "kendall": 0.5111994333483417}, "kappa_score": 0.015122001908198679, "total_responses": 953, "valid_responses": 692, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.3656904957299366, "spearman": 0.3656904957299374, "kendall": 0.36569049572993745}, "p_value": {"pearson": 1.5884019076692069e-31, "spearman": 1.5884019076685075e-31, "kendall": 1.588666739389157e-29}, "kappa_score": 0.3265965525430786, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Meta-Llama-3-70B-Instruct (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.6912169741746439, "spearman": 0.6912169741746437, "kendall": 0.6912169741746437}, "p_value": {"pearson": 2.5799184972222323e-136, "spearman": 2.579918497222989e-136, "kendall": 6.356160358168495e-101}, "kappa_score": 0.6897994823016393, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "OLMo-7B-Instruct (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.3311814756460889, "spearman": 0.3311814756460874, "kendall": 0.3311814756460874}, "p_value": {"pearson": 7.906041539719756e-26, "spearman": 7.906041539724406e-26, "kendall": 1.6396166034928027e-24}, "kappa_score": 0.3311192261135806, "total_responses": 953, "valid_responses": 887, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.6418776155956281, "spearman": 0.6418776155956282, "kendall": 0.6418776155956283}, "p_value": {"pearson": 8.732528806373552e-112, "spearman": 8.73252880637299e-112, "kendall": 2.7057567490794418e-87}, "kappa_score": 0.6405613048892012, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.652708130448279, "spearman": 0.6527081304482758, "kendall": 0.6527081304482758}, "p_value": {"pearson": 8.911905501254289e-117, "spearman": 8.911905501284435e-117, "kendall": 3.361801623517165e-90}, "kappa_score": 0.6466163422063302, "total_responses": 953, "valid_responses": 928, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "gpt-4o (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.7226986322816906, "spearman": 0.7226986322816897, "kendall": 0.7226986322816897}, "p_value": {"pearson": 9.87575946476747e-155, "spearman": 9.87575946478099e-155, "kendall": 3.8206904029417285e-110}, "kappa_score": 0.7222781768450114, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.6845758605075761, "spearman": 0.6845758605075736, "kendall": 0.6845758605075736}, "p_value": {"pearson": 9.944985247181988e-133, "spearman": 9.944985247213085e-133, "kendall": 4.9678213658789246e-99}, "kappa_score": 0.6815089058657045, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.6664493639916144, "spearman": 0.6664493639916134, "kendall": 0.6664493639916135}, "p_value": {"pearson": 2.060521256224052e-123, "spearman": 2.0605212562261128e-123, "kendall": 5.892624912636534e-94}, "kappa_score": 0.6625893978772676, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.2511985490372143, "spearman": 0.2511985490372155, "kendall": 0.2511985490372155}, "p_value": {"pearson": 3.5170241483935413e-15, "spearman": 3.5170241483924787e-15, "kendall": 9.145580439990903e-15}, "kappa_score": 0.13398423466260911, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}}